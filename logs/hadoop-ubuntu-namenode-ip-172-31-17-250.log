2016-05-25 08:00:16,163 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-25 08:00:16,171 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-25 08:00:16,182 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-25 08:00:16,620 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-25 08:00:16,754 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-25 08:00:16,754 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-25 08:00:16,756 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-25 08:00:16,758 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020 to access this namenode/service.
2016-05-25 08:00:17,311 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-25 08:00:17,427 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-25 08:00:17,448 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-25 08:00:17,461 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-25 08:00:17,467 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-25 08:00:17,470 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-25 08:00:17,471 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-25 08:00:17,471 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-25 08:00:17,530 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-25 08:00:17,531 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-25 08:00:17,559 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-25 08:00:17,560 INFO org.mortbay.log: jetty-6.1.26
2016-05-25 08:00:17,844 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-25 08:00:17,909 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-25 08:00:17,909 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-25 08:00:17,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-25 08:00:17,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-25 08:00:18,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-25 08:00:18,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-25 08:00:18,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-25 08:00:18,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 25 08:00:18
2016-05-25 08:00:18,022 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-25 08:00:18,022 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 08:00:18,026 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-25 08:00:18,026 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-25 08:00:18,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-25 08:00:18,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2016-05-25 08:00:18,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-25 08:00:18,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-25 08:00:18,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-25 08:00:18,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-25 08:00:18,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-25 08:00:18,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-25 08:00:18,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-25 08:00:18,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-25 08:00:18,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-25 08:00:18,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-25 08:00:18,069 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-25 08:00:18,116 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-25 08:00:18,116 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 08:00:18,116 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-25 08:00:18,116 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-25 08:00:18,118 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-25 08:00:18,118 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-25 08:00:18,118 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-25 08:00:18,118 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-25 08:00:18,135 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-25 08:00:18,135 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 08:00:18,135 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-25 08:00:18,135 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-25 08:00:18,136 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-25 08:00:18,136 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-25 08:00:18,136 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-25 08:00:18,139 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-25 08:00:18,139 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-25 08:00:18,139 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-25 08:00:18,140 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-25 08:00:18,140 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-25 08:00:18,142 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-25 08:00:18,142 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 08:00:18,142 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-25 08:00:18,142 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-25 08:00:18,159 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 24976@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-25 08:00:18,367 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-25 08:00:18,374 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2016-05-25 08:00:18,481 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-25 08:00:18,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-25 08:00:18,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000
2016-05-25 08:00:18,578 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-25 08:00:18,581 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2016-05-25 08:00:18,672 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-25 08:00:18,672 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 527 msecs
2016-05-25 08:00:18,901 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-25 08:00:18,908 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-25 08:00:18,924 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-25 08:00:18,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-25 08:00:19,006 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-25 08:00:19,006 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-25 08:00:19,006 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-25 08:00:19,006 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2016-05-25 08:00:19,006 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-25 08:00:19,006 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-25 08:00:19,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 08:00:19,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-25 08:00:19,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-25 08:00:19,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-25 08:00:19,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-25 08:00:19,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-25 08:00:19,020 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2016-05-25 08:00:19,061 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-25 08:00:19,062 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-25 08:00:19,065 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com/172.31.17.250:8020
2016-05-25 08:00:19,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-25 08:00:19,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-25 08:00:23,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage fb016542-f026-40fc-944f-40f753a95f67
2016-05-25 08:00:23,772 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 08:00:23,772 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.173:50010
2016-05-25 08:00:23,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 08:00:23,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-02866f87-61ec-46f2-8259-f04703868a93 for DN 172.31.16.173:50010
2016-05-25 08:00:23,924 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2016-05-25 08:01:28,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 08:01:28,620 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 08:01:28,620 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2016-05-25 08:01:28,620 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 12 
2016-05-25 08:01:28,621 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 13 
2016-05-25 08:01:28,621 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000002
2016-05-25 08:01:28,624 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2016-05-25 08:01:30,102 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 08:01:30,102 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 353 bytes.
2016-05-25 08:01:30,107 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2016-05-25 09:01:30,416 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 09:01:30,416 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 09:01:30,416 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3
2016-05-25 09:01:30,416 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 11 
2016-05-25 09:01:30,417 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 12 
2016-05-25 09:01:30,418 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000003 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000003-0000000000000000004
2016-05-25 09:01:30,418 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5
2016-05-25 09:01:30,480 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 09:01:30,480 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000004 size 353 bytes.
2016-05-25 09:01:30,485 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2016-05-25 09:01:30,486 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2016-05-25 09:58:25,243 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage c8fad825-9d8a-418d-94a0-a541b2ca3ab6
2016-05-25 09:58:25,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 09:58:25,243 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.212:50010
2016-05-25 09:58:25,333 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 09:58:25,333 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-41695162-6240-430e-b24c-97015ec84ec8 for DN 172.31.16.212:50010
2016-05-25 09:58:25,355 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-25 10:00:35,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 10:00:35,399 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 10:00:35,399 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5
2016-05-25 10:00:35,399 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 10 
2016-05-25 10:00:35,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 11 
2016-05-25 10:00:35,400 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000005 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000005-0000000000000000006
2016-05-25 10:00:35,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 7
2016-05-25 10:00:36,095 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 10:00:36,095 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000006 size 353 bytes.
2016-05-25 10:00:36,099 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4
2016-05-25 10:00:36,099 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2016-05-25 10:00:47,308 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-25 10:00:47,310 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-25 10:01:42,254 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-25 10:01:42,262 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-25 10:01:42,273 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-25 10:01:42,732 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-25 10:01:42,844 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-25 10:01:42,844 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-25 10:01:42,846 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-25 10:01:42,848 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020 to access this namenode/service.
2016-05-25 10:01:43,400 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-25 10:01:43,526 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-25 10:01:43,543 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-25 10:01:43,552 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-25 10:01:43,565 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-25 10:01:43,570 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-25 10:01:43,570 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-25 10:01:43,570 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-25 10:01:43,627 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-25 10:01:43,629 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-25 10:01:43,652 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-25 10:01:43,652 INFO org.mortbay.log: jetty-6.1.26
2016-05-25 10:01:43,938 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-25 10:01:44,001 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-25 10:01:44,001 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-25 10:01:44,080 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-25 10:01:44,080 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-25 10:01:44,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-25 10:01:44,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-25 10:01:44,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-25 10:01:44,121 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 25 10:01:44
2016-05-25 10:01:44,122 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-25 10:01:44,122 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 10:01:44,124 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-25 10:01:44,124 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-25 10:01:44,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-25 10:01:44,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2016-05-25 10:01:44,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-25 10:01:44,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-25 10:01:44,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-25 10:01:44,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-25 10:01:44,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-25 10:01:44,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-25 10:01:44,170 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-25 10:01:44,170 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-25 10:01:44,170 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-25 10:01:44,170 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-25 10:01:44,171 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-25 10:01:44,218 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-25 10:01:44,218 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 10:01:44,219 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-25 10:01:44,219 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-25 10:01:44,220 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-25 10:01:44,220 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-25 10:01:44,220 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-25 10:01:44,221 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-25 10:01:44,235 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-25 10:01:44,235 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 10:01:44,235 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-25 10:01:44,235 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-25 10:01:44,236 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-25 10:01:44,236 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-25 10:01:44,236 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-25 10:01:44,239 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-25 10:01:44,239 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-25 10:01:44,239 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-25 10:01:44,240 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-25 10:01:44,240 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-25 10:01:44,242 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-25 10:01:44,242 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 10:01:44,242 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-25 10:01:44,242 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-25 10:01:44,256 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 27091@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-25 10:01:44,479 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-25 10:01:44,634 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000007 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000007-0000000000000000007
2016-05-25 10:01:44,734 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-25 10:01:44,789 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-25 10:01:44,793 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 6 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000006
2016-05-25 10:01:44,793 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@328e1f66 expecting start txid #7
2016-05-25 10:01:44,793 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000007-0000000000000000007
2016-05-25 10:01:44,795 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000007-0000000000000000007' to transaction ID 7
2016-05-25 10:01:44,801 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000007-0000000000000000007 of size 1048576 edits # 1 loaded in 0 seconds
2016-05-25 10:01:44,809 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-25 10:01:44,810 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 8
2016-05-25 10:01:44,863 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-25 10:01:44,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 618 msecs
2016-05-25 10:01:45,024 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-25 10:01:45,030 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-25 10:01:45,040 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-25 10:01:45,105 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-25 10:01:45,111 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-25 10:01:45,111 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-25 10:01:45,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-25 10:01:45,112 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2016-05-25 10:01:45,112 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-25 10:01:45,112 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-25 10:01:45,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 10:01:45,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-25 10:01:45,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-25 10:01:45,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-25 10:01:45,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-25 10:01:45,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-25 10:01:45,125 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2016-05-25 10:01:45,162 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-25 10:01:45,163 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-25 10:01:45,164 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com/172.31.17.250:8020
2016-05-25 10:01:45,164 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-25 10:01:45,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-25 10:01:49,959 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage fb016542-f026-40fc-944f-40f753a95f67
2016-05-25 10:01:49,962 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 10:01:49,962 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.173:50010
2016-05-25 10:01:50,042 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 10:01:50,042 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-02866f87-61ec-46f2-8259-f04703868a93 for DN 172.31.16.173:50010
2016-05-25 10:01:50,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage c8fad825-9d8a-418d-94a0-a541b2ca3ab6
2016-05-25 10:01:50,062 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 10:01:50,062 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.212:50010
2016-05-25 10:01:50,089 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 8 msecs
2016-05-25 10:01:50,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 10:01:50,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-41695162-6240-430e-b24c-97015ec84ec8 for DN 172.31.16.212:50010
2016-05-25 10:01:50,182 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-25 10:02:55,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 10:02:55,001 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 10:02:55,001 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 8
2016-05-25 10:02:55,001 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-05-25 10:02:55,002 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2016-05-25 10:02:55,003 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000008 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000008-0000000000000000009
2016-05-25 10:02:55,003 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 10
2016-05-25 10:02:56,101 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 10:02:56,101 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000009 size 353 bytes.
2016-05-25 10:02:56,105 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 6
2016-05-25 10:02:56,106 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000004, cpktTxId=0000000000000000004)
2016-05-25 10:27:46,277 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-25 10:27:46,279 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-25 10:28:20,615 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-25 10:28:20,622 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-25 10:28:20,633 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-25 10:28:21,082 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-25 10:28:21,195 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-25 10:28:21,195 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-25 10:28:21,198 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-25 10:28:21,200 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020 to access this namenode/service.
2016-05-25 10:28:21,801 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-25 10:28:21,925 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-25 10:28:21,949 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-25 10:28:21,960 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-25 10:28:21,968 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-25 10:28:21,980 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-25 10:28:21,980 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-25 10:28:21,980 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-25 10:28:22,051 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-25 10:28:22,053 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-25 10:28:22,103 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-25 10:28:22,103 INFO org.mortbay.log: jetty-6.1.26
2016-05-25 10:28:22,425 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-25 10:28:22,493 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-25 10:28:22,493 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-25 10:28:22,571 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-25 10:28:22,571 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-25 10:28:22,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-25 10:28:22,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-25 10:28:22,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-25 10:28:22,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 25 10:28:22
2016-05-25 10:28:22,611 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-25 10:28:22,611 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 10:28:22,615 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-25 10:28:22,615 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-25 10:28:22,649 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-25 10:28:22,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2016-05-25 10:28:22,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-25 10:28:22,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-25 10:28:22,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-25 10:28:22,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-25 10:28:22,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-25 10:28:22,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-25 10:28:22,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-25 10:28:22,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-25 10:28:22,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-25 10:28:22,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-25 10:28:22,659 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-25 10:28:22,701 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-25 10:28:22,701 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 10:28:22,702 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-25 10:28:22,702 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-25 10:28:22,703 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-25 10:28:22,704 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-25 10:28:22,704 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-25 10:28:22,704 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-25 10:28:22,720 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-25 10:28:22,720 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 10:28:22,720 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-25 10:28:22,720 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-25 10:28:22,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-25 10:28:22,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-25 10:28:22,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-25 10:28:22,724 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-25 10:28:22,724 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-25 10:28:22,724 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-25 10:28:22,725 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-25 10:28:22,725 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-25 10:28:22,727 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-25 10:28:22,727 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-25 10:28:22,727 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-25 10:28:22,727 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-25 10:28:22,741 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 28812@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-25 10:28:22,947 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-25 10:28:23,109 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000010 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000010-0000000000000000010
2016-05-25 10:28:23,211 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-25 10:28:23,274 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-25 10:28:23,274 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 9 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000009
2016-05-25 10:28:23,275 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@328e1f66 expecting start txid #10
2016-05-25 10:28:23,275 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000010-0000000000000000010
2016-05-25 10:28:23,276 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000010-0000000000000000010' to transaction ID 10
2016-05-25 10:28:23,278 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000010-0000000000000000010 of size 1048576 edits # 1 loaded in 0 seconds
2016-05-25 10:28:23,287 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-25 10:28:23,290 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 11
2016-05-25 10:28:23,365 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-25 10:28:23,365 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 635 msecs
2016-05-25 10:28:23,553 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-25 10:28:23,559 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-25 10:28:23,570 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-25 10:28:23,639 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-25 10:28:23,646 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-25 10:28:23,646 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-25 10:28:23,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-25 10:28:23,647 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2016-05-25 10:28:23,647 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-25 10:28:23,647 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-25 10:28:23,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 10:28:23,661 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-25 10:28:23,661 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-25 10:28:23,661 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-25 10:28:23,661 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-25 10:28:23,661 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-25 10:28:23,661 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2016-05-25 10:28:23,700 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-25 10:28:23,701 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-25 10:28:23,702 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com/172.31.17.250:8020
2016-05-25 10:28:23,702 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-25 10:28:23,706 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-25 10:28:28,180 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage fb016542-f026-40fc-944f-40f753a95f67
2016-05-25 10:28:28,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 10:28:28,181 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.173:50010
2016-05-25 10:28:28,200 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage c8fad825-9d8a-418d-94a0-a541b2ca3ab6
2016-05-25 10:28:28,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 10:28:28,201 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.212:50010
2016-05-25 10:28:28,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 10:28:28,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-41695162-6240-430e-b24c-97015ec84ec8 for DN 172.31.16.212:50010
2016-05-25 10:28:28,269 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-25 10:28:28,269 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-02866f87-61ec-46f2-8259-f04703868a93 for DN 172.31.16.173:50010
2016-05-25 10:28:28,310 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-25 10:28:28,317 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 10 msecs
2016-05-25 10:29:33,315 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 10:29:33,315 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 10:29:33,315 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 11
2016-05-25 10:29:33,315 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 13 
2016-05-25 10:29:33,316 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 13 
2016-05-25 10:29:33,317 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000011 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000011-0000000000000000012
2016-05-25 10:29:33,317 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 13
2016-05-25 10:29:34,428 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 10:29:34,428 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000012 size 353 bytes.
2016-05-25 10:29:34,434 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 9
2016-05-25 10:29:34,435 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000006, cpktTxId=0000000000000000006)
2016-05-25 10:31:10,663 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-05-25 11:29:34,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 11:29:34,748 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 11:29:34,748 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 13
2016-05-25 11:29:34,748 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 12 
2016-05-25 11:29:34,749 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 12 
2016-05-25 11:29:34,749 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000013 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000013-0000000000000000019
2016-05-25 11:29:34,749 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 20
2016-05-25 11:29:34,825 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 11:29:34,825 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000019 size 675 bytes.
2016-05-25 11:29:34,829 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 12
2016-05-25 11:29:34,829 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000009, cpktTxId=0000000000000000009)
2016-05-25 12:22:19,510 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 2 msecs
2016-05-25 12:29:35,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 12:29:35,132 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 12:29:35,132 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 20
2016-05-25 12:29:35,132 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-25 12:29:35,133 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2016-05-25 12:29:35,133 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000020 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000020-0000000000000000021
2016-05-25 12:29:35,133 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 22
2016-05-25 12:29:35,179 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 12:29:35,179 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000021 size 675 bytes.
2016-05-25 12:29:35,185 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 19
2016-05-25 12:29:35,185 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2016-05-25 13:29:35,478 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 13:29:35,478 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 13:29:35,478 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 22
2016-05-25 13:29:35,478 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 16 
2016-05-25 13:29:35,479 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 17 
2016-05-25 13:29:35,480 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000022 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000022-0000000000000000023
2016-05-25 13:29:35,480 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 24
2016-05-25 13:29:35,521 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 13:29:35,521 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000023 size 675 bytes.
2016-05-25 13:29:35,528 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 21
2016-05-25 13:29:35,528 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000019, cpktTxId=0000000000000000019)
2016-05-25 14:29:35,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 14:29:35,833 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 14:29:35,833 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 24
2016-05-25 14:29:35,834 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-05-25 14:29:35,834 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2016-05-25 14:29:35,835 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000024 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000024-0000000000000000025
2016-05-25 14:29:35,835 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 26
2016-05-25 14:29:35,874 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 14:29:35,874 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000025 size 675 bytes.
2016-05-25 14:29:35,878 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 23
2016-05-25 14:29:35,878 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000021, cpktTxId=0000000000000000021)
2016-05-25 14:46:23,089 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-25 15:29:36,170 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 15:29:36,170 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 15:29:36,170 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 26
2016-05-25 15:29:36,170 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-05-25 15:29:36,171 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2016-05-25 15:29:36,172 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000026 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000026-0000000000000000027
2016-05-25 15:29:36,172 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 28
2016-05-25 15:29:36,214 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 15:29:36,214 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000027 size 675 bytes.
2016-05-25 15:29:36,218 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 25
2016-05-25 15:29:36,218 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000023, cpktTxId=0000000000000000023)
2016-05-25 16:29:36,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 16:29:36,512 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 16:29:36,512 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 28
2016-05-25 16:29:36,512 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-25 16:29:36,513 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-25 16:29:36,513 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000028 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000028-0000000000000000029
2016-05-25 16:29:36,513 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 30
2016-05-25 16:29:36,552 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 16:29:36,552 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000029 size 675 bytes.
2016-05-25 16:29:36,556 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 27
2016-05-25 16:29:36,556 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000025, cpktTxId=0000000000000000025)
2016-05-25 17:29:36,852 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 17:29:36,852 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 17:29:36,852 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 30
2016-05-25 17:29:36,853 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-05-25 17:29:36,853 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2016-05-25 17:29:36,854 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000030 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000030-0000000000000000031
2016-05-25 17:29:36,854 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 32
2016-05-25 17:29:36,899 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 17:29:36,899 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000031 size 675 bytes.
2016-05-25 17:29:36,902 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 29
2016-05-25 17:29:36,903 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000027, cpktTxId=0000000000000000027)
2016-05-25 18:22:20,367 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-25 18:29:37,208 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 18:29:37,208 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 18:29:37,208 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 32
2016-05-25 18:29:37,208 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 12 
2016-05-25 18:29:37,209 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 13 
2016-05-25 18:29:37,210 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000032 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000032-0000000000000000033
2016-05-25 18:29:37,210 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 34
2016-05-25 18:29:37,255 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 18:29:37,255 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000033 size 675 bytes.
2016-05-25 18:29:37,259 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 31
2016-05-25 18:29:37,259 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000029, cpktTxId=0000000000000000029)
2016-05-25 19:29:37,548 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 19:29:37,548 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 19:29:37,548 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 34
2016-05-25 19:29:37,548 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-05-25 19:29:37,549 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2016-05-25 19:29:37,549 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000034 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000034-0000000000000000035
2016-05-25 19:29:37,549 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 36
2016-05-25 19:29:37,595 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2016-05-25 19:29:37,595 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000035 size 675 bytes.
2016-05-25 19:29:37,598 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 33
2016-05-25 19:29:37,599 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2016-05-25 20:29:37,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 20:29:37,894 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 20:29:37,894 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 36
2016-05-25 20:29:37,894 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-25 20:29:37,895 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-25 20:29:37,896 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000036 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000036-0000000000000000037
2016-05-25 20:29:37,896 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 38
2016-05-25 20:29:37,941 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 20:29:37,941 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000037 size 675 bytes.
2016-05-25 20:29:37,944 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 35
2016-05-25 20:29:37,944 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000033, cpktTxId=0000000000000000033)
2016-05-25 20:46:24,362 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-25 21:29:38,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 21:29:38,244 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 21:29:38,245 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 38
2016-05-25 21:29:38,245 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2016-05-25 21:29:38,245 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2016-05-25 21:29:38,246 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000038 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000038-0000000000000000039
2016-05-25 21:29:38,246 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 40
2016-05-25 21:29:38,283 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 21:29:38,283 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000039 size 675 bytes.
2016-05-25 21:29:38,290 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 37
2016-05-25 21:29:38,290 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000035, cpktTxId=0000000000000000035)
2016-05-25 22:29:38,591 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 22:29:38,591 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 22:29:38,591 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 40
2016-05-25 22:29:38,591 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-25 22:29:38,592 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-25 22:29:38,592 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000040 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000040-0000000000000000041
2016-05-25 22:29:38,592 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 42
2016-05-25 22:29:38,648 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 22:29:38,648 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000041 size 675 bytes.
2016-05-25 22:29:38,651 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 39
2016-05-25 22:29:38,651 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000037, cpktTxId=0000000000000000037)
2016-05-25 23:29:38,943 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-25 23:29:38,943 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-25 23:29:38,943 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 42
2016-05-25 23:29:38,943 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 12 
2016-05-25 23:29:38,944 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 13 
2016-05-25 23:29:38,944 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000042 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000042-0000000000000000043
2016-05-25 23:29:38,945 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 44
2016-05-25 23:29:38,981 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-25 23:29:38,981 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000043 size 675 bytes.
2016-05-25 23:29:38,985 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 41
2016-05-25 23:29:38,985 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000039, cpktTxId=0000000000000000039)
2016-05-26 00:22:18,216 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-26 00:29:39,275 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 00:29:39,275 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 00:29:39,275 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 44
2016-05-26 00:29:39,275 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-26 00:29:39,276 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-26 00:29:39,276 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000044 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000044-0000000000000000045
2016-05-26 00:29:39,276 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 46
2016-05-26 00:29:39,320 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 00:29:39,320 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000045 size 675 bytes.
2016-05-26 00:29:39,324 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 43
2016-05-26 00:29:39,324 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000041, cpktTxId=0000000000000000041)
2016-05-26 01:29:39,615 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 01:29:39,615 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 01:29:39,615 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 46
2016-05-26 01:29:39,616 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 10 
2016-05-26 01:29:39,616 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 11 
2016-05-26 01:29:39,617 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000046 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000046-0000000000000000047
2016-05-26 01:29:39,617 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 48
2016-05-26 01:29:39,654 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 01:29:39,654 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000047 size 675 bytes.
2016-05-26 01:29:39,657 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 45
2016-05-26 01:29:39,657 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000043, cpktTxId=0000000000000000043)
2016-05-26 02:29:39,950 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 02:29:39,950 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 02:29:39,950 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 48
2016-05-26 02:29:39,950 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-26 02:29:39,951 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-26 02:29:39,951 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000048 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000048-0000000000000000049
2016-05-26 02:29:39,951 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 50
2016-05-26 02:29:39,989 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 02:29:39,989 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000049 size 675 bytes.
2016-05-26 02:29:39,993 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 47
2016-05-26 02:29:39,993 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000045, cpktTxId=0000000000000000045)
2016-05-26 02:46:25,670 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-26 03:29:40,281 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 03:29:40,281 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 03:29:40,281 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 50
2016-05-26 03:29:40,281 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-05-26 03:29:40,282 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2016-05-26 03:29:40,283 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000050 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000050-0000000000000000051
2016-05-26 03:29:40,283 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 52
2016-05-26 03:29:40,320 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 03:29:40,320 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000051 size 675 bytes.
2016-05-26 03:29:40,324 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 49
2016-05-26 03:29:40,324 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000047, cpktTxId=0000000000000000047)
2016-05-26 04:29:40,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 04:29:40,612 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 04:29:40,612 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 52
2016-05-26 04:29:40,612 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-05-26 04:29:40,613 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2016-05-26 04:29:40,613 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000052 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000052-0000000000000000053
2016-05-26 04:29:40,613 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 54
2016-05-26 04:29:40,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 04:29:40,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000053 size 675 bytes.
2016-05-26 04:29:40,655 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 51
2016-05-26 04:29:40,655 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000049, cpktTxId=0000000000000000049)
2016-05-26 05:29:40,946 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 05:29:40,946 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 05:29:40,946 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 54
2016-05-26 05:29:40,946 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-05-26 05:29:40,947 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2016-05-26 05:29:40,948 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000054 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000054-0000000000000000055
2016-05-26 05:29:40,948 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 56
2016-05-26 05:29:40,987 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 05:29:40,987 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000055 size 675 bytes.
2016-05-26 05:29:40,991 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 53
2016-05-26 05:29:40,991 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000051, cpktTxId=0000000000000000051)
2016-05-26 06:22:19,021 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-26 06:29:41,280 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 06:29:41,280 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 06:29:41,280 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 56
2016-05-26 06:29:41,280 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-26 06:29:41,281 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2016-05-26 06:29:41,282 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000056 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000056-0000000000000000057
2016-05-26 06:29:41,282 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 58
2016-05-26 06:29:41,320 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 06:29:41,320 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000057 size 675 bytes.
2016-05-26 06:29:41,324 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 55
2016-05-26 06:29:41,324 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000053, cpktTxId=0000000000000000053)
2016-05-26 07:29:41,618 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 07:29:41,618 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 07:29:41,618 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 58
2016-05-26 07:29:41,618 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 10 
2016-05-26 07:29:41,619 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 11 
2016-05-26 07:29:41,620 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000058 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000058-0000000000000000059
2016-05-26 07:29:41,620 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 60
2016-05-26 07:29:41,664 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 07:29:41,664 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000059 size 675 bytes.
2016-05-26 07:29:41,667 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 57
2016-05-26 07:29:41,667 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000055, cpktTxId=0000000000000000055)
2016-05-26 08:29:41,958 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 08:29:41,958 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 08:29:41,958 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 60
2016-05-26 08:29:41,958 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-26 08:29:41,959 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-26 08:29:41,959 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000060 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000060-0000000000000000061
2016-05-26 08:29:41,959 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 62
2016-05-26 08:29:42,003 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 08:29:42,003 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000061 size 675 bytes.
2016-05-26 08:29:42,008 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 59
2016-05-26 08:29:42,008 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000057, cpktTxId=0000000000000000057)
2016-05-26 08:46:23,854 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-26 09:29:42,297 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 09:29:42,297 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 09:29:42,297 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 62
2016-05-26 09:29:42,297 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 13 
2016-05-26 09:29:42,298 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 13 
2016-05-26 09:29:42,298 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000062 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000062-0000000000000000063
2016-05-26 09:29:42,298 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 64
2016-05-26 09:29:42,339 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 09:29:42,340 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000063 size 675 bytes.
2016-05-26 09:29:42,343 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 61
2016-05-26 09:29:42,343 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000059, cpktTxId=0000000000000000059)
2016-05-26 10:29:42,631 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 10:29:42,631 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 10:29:42,632 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 64
2016-05-26 10:29:42,632 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-26 10:29:42,633 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-26 10:29:42,633 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000064 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000064-0000000000000000065
2016-05-26 10:29:42,633 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 66
2016-05-26 10:29:42,685 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 10:29:42,685 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000065 size 675 bytes.
2016-05-26 10:29:42,688 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 63
2016-05-26 10:29:42,689 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000061, cpktTxId=0000000000000000061)
2016-05-26 11:29:42,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 11:29:42,977 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 11:29:42,977 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 66
2016-05-26 11:29:42,977 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-26 11:29:42,978 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2016-05-26 11:29:42,978 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000066 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000066-0000000000000000067
2016-05-26 11:29:42,978 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 68
2016-05-26 11:29:43,023 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 11:29:43,023 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000067 size 675 bytes.
2016-05-26 11:29:43,026 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 65
2016-05-26 11:29:43,026 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000063, cpktTxId=0000000000000000063)
2016-05-26 12:22:16,821 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-26 12:29:43,313 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 12:29:43,314 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 12:29:43,314 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 68
2016-05-26 12:29:43,314 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 11 
2016-05-26 12:29:43,314 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 12 
2016-05-26 12:29:43,315 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000068 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000068-0000000000000000069
2016-05-26 12:29:43,315 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 70
2016-05-26 12:29:43,357 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 12:29:43,357 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000069 size 675 bytes.
2016-05-26 12:29:43,361 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 67
2016-05-26 12:29:43,361 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000065, cpktTxId=0000000000000000065)
2016-05-26 13:29:43,659 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 13:29:43,659 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 13:29:43,659 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 70
2016-05-26 13:29:43,659 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-26 13:29:43,660 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2016-05-26 13:29:43,661 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000070 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000070-0000000000000000071
2016-05-26 13:29:43,661 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 72
2016-05-26 13:29:43,698 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 13:29:43,699 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000071 size 675 bytes.
2016-05-26 13:29:43,702 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 69
2016-05-26 13:29:43,703 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000067, cpktTxId=0000000000000000067)
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 14:20:45,129 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 14:29:43,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 14:29:43,995 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 14:29:43,995 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 72
2016-05-26 14:29:43,995 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-26 14:29:43,996 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2016-05-26 14:29:43,997 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000072 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000072-0000000000000000073
2016-05-26 14:29:43,997 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 74
2016-05-26 14:29:44,049 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 14:29:44,049 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000073 size 675 bytes.
2016-05-26 14:29:44,053 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 71
2016-05-26 14:29:44,053 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000069, cpktTxId=0000000000000000069)
2016-05-26 14:29:54,060 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 14:29:54,060 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 14:29:54,060 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-26 14:29:54,060 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 14:29:54,060 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 14:29:54,060 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 14:29:54,061 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-26 14:29:54,061 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 14:29:54,061 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 14:29:54,061 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 14:29:54,061 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-26 14:29:54,061 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 14:46:24,970 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-26 15:29:44,344 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 15:29:44,344 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 15:29:44,344 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 74
2016-05-26 15:29:44,344 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-26 15:29:44,345 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-26 15:29:44,346 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000074 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000074-0000000000000000075
2016-05-26 15:29:44,346 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 76
2016-05-26 15:29:44,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 15:29:44,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000075 size 675 bytes.
2016-05-26 15:29:44,397 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 73
2016-05-26 15:29:44,398 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000071, cpktTxId=0000000000000000071)
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 16:26:45,226 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 16:26:46,610 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 16:29:44,687 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 16:29:44,687 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 16:29:44,687 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 76
2016-05-26 16:29:44,688 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-26 16:29:44,688 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2016-05-26 16:29:44,689 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000076 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000076-0000000000000000077
2016-05-26 16:29:44,689 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 78
2016-05-26 16:29:44,735 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 16:29:44,735 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000077 size 675 bytes.
2016-05-26 16:29:44,739 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 75
2016-05-26 16:29:44,739 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000073, cpktTxId=0000000000000000073)
2016-05-26 16:48:00,956 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 16:48:00,956 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 16:48:00,956 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 16:48:00,956 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 16:48:00,956 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 16:48:00,956 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 16:48:00,957 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 16:48:00,957 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 16:48:00,958 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 16:48:00,958 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 16:48:00,958 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 16:48:00,958 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 17:29:45,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 17:29:45,025 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 17:29:45,025 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 78
2016-05-26 17:29:45,026 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-26 17:29:45,027 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-26 17:29:45,027 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000078 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000078-0000000000000000079
2016-05-26 17:29:45,028 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 80
2016-05-26 17:29:45,073 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-26 17:29:45,073 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000079 size 675 bytes.
2016-05-26 17:29:45,077 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 77
2016-05-26 17:29:45,077 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000075, cpktTxId=0000000000000000075)
2016-05-26 17:57:31,923 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 17:57:31,923 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 17:57:31,923 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 17:57:31,923 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 17:57:31,923 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 17:57:31,924 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 17:57:31,924 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-26 17:57:31,924 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 17:57:31,924 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 17:57:31,924 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 17:57:31,924 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 17:57:31,924 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 18:01:24,659 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-26 18:01:24,700 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/input._COPYING_
2016-05-26 18:01:25,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/webapp1/input._COPYING_
2016-05-26 18:01:25,241 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 200126
2016-05-26 18:01:25,242 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741825_1001 size 200126
2016-05-26 18:01:25,639 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/input._COPYING_ is closed by DFSClient_NONMAPREDUCE_-673380294_1
2016-05-26 18:04:02,820 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 8 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 1 Number of syncs: 6 SyncTimes(ms): 10 
2016-05-26 18:04:02,821 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741825_1001 172.31.16.173:50010 172.31.16.212:50010 
2016-05-26 18:04:04,797 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.212:50010 to delete [blk_1073741825_1001]
2016-05-26 18:04:07,797 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.173:50010 to delete [blk_1073741825_1001]
2016-05-26 18:05:06,297 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 9 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 1 Number of syncs: 7 SyncTimes(ms): 10 
2016-05-26 18:05:41,457 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/input/pg6574.txt._COPYING_
2016-05-26 18:05:41,736 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-26 18:05:41,737 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-26 18:05:41,740 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/input/pg6574.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1023087596_1
2016-05-26 18:06:26,942 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 19 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 1 Number of syncs: 13 SyncTimes(ms): 17 
2016-05-26 18:06:29,020 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/output/_temporary/0/_temporary/attempt_local142158282_0001_r_000000_0/part-r-00000
2016-05-26 18:06:29,208 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-26 18:06:29,210 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-26 18:06:29,213 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/output/_temporary/0/_temporary/attempt_local142158282_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_1196790097_1
2016-05-26 18:06:29,258 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1196790097_1
2016-05-26 18:08:09,990 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-26 18:08:09,990 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-26 18:08:09,990 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-26 18:08:09,990 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 18:08:09,990 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-26 18:08:09,990 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-26 18:08:09,990 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-26 18:08:09,990 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 18:08:09,991 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-26 18:08:10,600 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2016-05-26 18:08:10,601 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:08:10,601 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:08:10,601 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-26 18:08:10,601 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:08:10,601 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 18:08:10,601 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-26 18:08:10,601 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:08:10,601 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 18:08:10,601 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 2
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 18:12:57,113 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-26 18:12:57,114 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:12:57,114 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 18:12:57,114 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:12:58,497 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 2
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 18:12:58,498 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:13:55,766 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 2
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 2
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:13:55,767 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 18:13:55,768 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:13:56,738 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:13:56,738 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-26 18:13:56,738 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:13:56,738 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 18:13:56,738 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-26 18:13:56,738 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:13:56,738 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 18:13:56,738 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:13:56,738 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 2
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 2
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 18:13:56,739 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-26 18:22:17,566 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 2, hasStaleStorage: false, processing time: 0 msecs
2016-05-26 18:23:25,847 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 32 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 1 Number of syncs: 22 SyncTimes(ms): 23 
2016-05-26 18:23:25,872 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/input/test.txt._COPYING_
2016-05-26 18:23:26,110 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-26 18:23:26,111 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-26 18:23:26,115 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/input/test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-983722265_1
2016-05-26 18:27:37,941 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 38 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 1 Number of syncs: 26 SyncTimes(ms): 25 
2016-05-26 18:29:45,349 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 18:29:45,349 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 18:29:45,349 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 80
2016-05-26 18:29:45,349 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 39 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 1 Number of syncs: 27 SyncTimes(ms): 25 
2016-05-26 18:29:45,350 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 39 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 1 Number of syncs: 28 SyncTimes(ms): 25 
2016-05-26 18:29:45,350 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000080 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000080-0000000000000000118
2016-05-26 18:29:45,351 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 119
2016-05-26 18:29:45,418 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 333.33 KB/s
2016-05-26 18:29:45,418 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000118 size 1129 bytes.
2016-05-26 18:29:45,422 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 79
2016-05-26 18:29:45,422 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000077, cpktTxId=0000000000000000077)
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 2
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 2
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 2
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-26 18:31:23,536 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-26 18:31:23,537 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-26 18:31:23,537 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-26 18:31:23,537 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-26 19:29:45,691 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 19:29:45,691 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 19:29:45,691 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 119
2016-05-26 19:29:45,692 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-26 19:29:45,692 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2016-05-26 19:29:45,693 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000119 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000119-0000000000000000120
2016-05-26 19:29:45,693 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 121
2016-05-26 19:29:45,757 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 333.33 KB/s
2016-05-26 19:29:45,757 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000120 size 1129 bytes.
2016-05-26 19:29:45,770 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 118
2016-05-26 19:29:45,770 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000079, cpktTxId=0000000000000000079)
2016-05-26 20:02:11,494 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 13 
2016-05-26 20:02:34,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/input2/input1.txt._COPYING_
2016-05-26 20:02:35,101 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-26 20:02:35,102 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-26 20:02:35,106 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/input2/input1.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1835716238_1
2016-05-26 20:03:20,118 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 16 
2016-05-26 20:03:20,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/output2/_temporary/0/_temporary/attempt_local1160564454_0001_r_000000_0/part-r-00000
2016-05-26 20:03:20,738 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-26 20:03:20,739 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-26 20:03:20,743 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/output2/_temporary/0/_temporary/attempt_local1160564454_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_-895664382_1
2016-05-26 20:03:20,779 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/output2/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-895664382_1
2016-05-26 20:05:32,890 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 24 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 16 SyncTimes(ms): 22 
2016-05-26 20:05:32,892 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741827_1003 172.31.16.173:50010 172.31.16.212:50010 
2016-05-26 20:05:35,288 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.212:50010 to delete [blk_1073741827_1003]
2016-05-26 20:05:38,288 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.173:50010 to delete [blk_1073741827_1003]
2016-05-26 20:05:40,847 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741830_1006 172.31.16.212:50010 172.31.16.173:50010 
2016-05-26 20:05:41,288 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.212:50010 to delete [blk_1073741830_1006]
2016-05-26 20:05:44,289 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.173:50010 to delete [blk_1073741830_1006]
2016-05-26 20:29:46,056 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 20:29:46,056 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 20:29:46,056 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 121
2016-05-26 20:29:46,056 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 26 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 18 SyncTimes(ms): 25 
2016-05-26 20:29:46,061 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 26 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 19 SyncTimes(ms): 30 
2016-05-26 20:29:46,062 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000121 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000121-0000000000000000146
2016-05-26 20:29:46,062 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 147
2016-05-26 20:29:46,172 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 90.91 KB/s
2016-05-26 20:29:46,172 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000146 size 1072 bytes.
2016-05-26 20:29:46,184 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 120
2016-05-26 20:29:46,184 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000118, cpktTxId=0000000000000000118)
2016-05-26 20:46:23,036 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 3, hasStaleStorage: false, processing time: 0 msecs
2016-05-26 21:29:46,478 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 21:29:46,478 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 21:29:46,478 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 147
2016-05-26 21:29:46,478 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 18 
2016-05-26 21:29:46,479 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 19 
2016-05-26 21:29:46,479 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000147 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000147-0000000000000000148
2016-05-26 21:29:46,480 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 149
2016-05-26 21:29:46,522 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 333.33 KB/s
2016-05-26 21:29:46,522 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000148 size 1072 bytes.
2016-05-26 21:29:46,525 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 146
2016-05-26 21:29:46,526 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000120, cpktTxId=0000000000000000120)
2016-05-26 22:29:46,795 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 22:29:46,795 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 22:29:46,795 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 149
2016-05-26 22:29:46,795 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 10 
2016-05-26 22:29:46,796 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 11 
2016-05-26 22:29:46,796 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000149 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000149-0000000000000000150
2016-05-26 22:29:46,796 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 151
2016-05-26 22:29:46,840 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 333.33 KB/s
2016-05-26 22:29:46,840 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000150 size 1072 bytes.
2016-05-26 22:29:46,843 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 148
2016-05-26 22:29:46,843 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000146, cpktTxId=0000000000000000146)
2016-05-26 23:24:22,605 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-26 23:24:22,608 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-26 23:24:57,548 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-26 23:24:57,555 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-26 23:24:57,566 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-26 23:24:58,013 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-26 23:24:58,125 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-26 23:24:58,125 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-26 23:24:58,128 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-26 23:24:58,130 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020 to access this namenode/service.
2016-05-26 23:24:58,746 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-26 23:24:58,867 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-26 23:24:58,892 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-26 23:24:58,907 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-26 23:24:58,916 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-26 23:24:58,925 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-26 23:24:58,925 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-26 23:24:58,925 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-26 23:24:58,978 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-26 23:24:58,980 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-26 23:24:59,006 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-26 23:24:59,006 INFO org.mortbay.log: jetty-6.1.26
2016-05-26 23:24:59,310 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-26 23:24:59,381 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-26 23:24:59,381 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-26 23:24:59,469 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-26 23:24:59,469 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-26 23:24:59,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-26 23:24:59,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-26 23:24:59,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-26 23:24:59,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 26 23:24:59
2016-05-26 23:24:59,514 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-26 23:24:59,514 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-26 23:24:59,515 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-26 23:24:59,515 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-26 23:24:59,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-26 23:24:59,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2016-05-26 23:24:59,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-26 23:24:59,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-26 23:24:59,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-26 23:24:59,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-26 23:24:59,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-26 23:24:59,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-26 23:24:59,556 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-26 23:24:59,556 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-26 23:24:59,556 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-26 23:24:59,556 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-26 23:24:59,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-26 23:24:59,603 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-26 23:24:59,604 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-26 23:24:59,604 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-26 23:24:59,604 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-26 23:24:59,606 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-26 23:24:59,606 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-26 23:24:59,606 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-26 23:24:59,606 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-26 23:24:59,623 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-26 23:24:59,623 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-26 23:24:59,624 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-26 23:24:59,624 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-26 23:24:59,625 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-26 23:24:59,625 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-26 23:24:59,625 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-26 23:24:59,627 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-26 23:24:59,627 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-26 23:24:59,628 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-26 23:24:59,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-26 23:24:59,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-26 23:24:59,631 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-26 23:24:59,631 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-26 23:24:59,631 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-26 23:24:59,631 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-26 23:24:59,645 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 31670@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-26 23:24:59,867 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-26 23:25:00,029 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000151 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000151-0000000000000000151
2016-05-26 23:25:00,158 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 12 INodes.
2016-05-26 23:25:00,255 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-26 23:25:00,255 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 150 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000150
2016-05-26 23:25:00,255 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@328e1f66 expecting start txid #151
2016-05-26 23:25:00,255 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000151-0000000000000000151
2016-05-26 23:25:00,257 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000151-0000000000000000151' to transaction ID 151
2016-05-26 23:25:00,259 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000151-0000000000000000151 of size 1048576 edits # 1 loaded in 0 seconds
2016-05-26 23:25:00,264 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-26 23:25:00,278 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 152
2016-05-26 23:25:00,320 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-26 23:25:00,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 686 msecs
2016-05-26 23:25:00,481 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-26 23:25:00,487 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-26 23:25:00,500 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-26 23:25:00,607 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-26 23:25:00,618 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-26 23:25:00,618 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-26 23:25:00,618 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 3 blocks to reach the threshold 0.9990 of total blocks 3.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2016-05-26 23:25:00,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-26 23:25:00,662 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-26 23:25:00,663 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-26 23:25:00,664 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com/172.31.17.250:8020
2016-05-26 23:25:00,664 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-26 23:25:00,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-26 23:25:05,132 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage fb016542-f026-40fc-944f-40f753a95f67
2016-05-26 23:25:05,132 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-26 23:25:05,133 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.173:50010
2016-05-26 23:25:05,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-26 23:25:05,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-02866f87-61ec-46f2-8259-f04703868a93 for DN 172.31.16.173:50010
2016-05-26 23:25:05,228 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage c8fad825-9d8a-418d-94a0-a541b2ca3ab6
2016-05-26 23:25:05,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-26 23:25:05,229 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.212:50010
2016-05-26 23:25:05,261 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 2 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 2 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2016-05-26 23:25:05,261 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-26 23:25:05,263 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 3, hasStaleStorage: false, processing time: 7 msecs
2016-05-26 23:25:05,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 3
2016-05-26 23:25:05,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-26 23:25:05,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 2
2016-05-26 23:25:05,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-26 23:25:05,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-26 23:25:05,331 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 66 msec
2016-05-26 23:25:05,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-26 23:25:05,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-41695162-6240-430e-b24c-97015ec84ec8 for DN 172.31.16.212:50010
2016-05-26 23:25:05,357 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 3, hasStaleStorage: false, processing time: 0 msecs
2016-05-26 23:25:25,268 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 3 has reached the threshold 0.9990 of total blocks 3. The number of live datanodes 2 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2016-05-26 23:25:35,271 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2016-05-26 23:25:35,271 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2016-05-26 23:25:35,271 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 2 datanodes
2016-05-26 23:25:35,271 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-26 23:25:35,279 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: AuthenticationToken ignored: org.apache.hadoop.security.authentication.util.SignerException: Invalid signature
2016-05-26 23:25:43,836 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: AuthenticationToken ignored: org.apache.hadoop.security.authentication.util.SignerException: Invalid signature
2016-05-26 23:25:50,031 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: AuthenticationToken ignored: org.apache.hadoop.security.authentication.util.SignerException: Invalid signature
2016-05-26 23:26:02,208 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: AuthenticationToken ignored: org.apache.hadoop.security.authentication.util.SignerException: Invalid signature
2016-05-26 23:26:10,289 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-26 23:26:10,289 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-26 23:26:10,289 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 152
2016-05-26 23:26:10,289 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-26 23:26:10,290 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2016-05-26 23:26:10,295 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000152 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000152-0000000000000000154
2016-05-26 23:26:10,295 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 155
2016-05-26 23:26:11,555 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 500.00 KB/s
2016-05-26 23:26:11,555 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000154 size 1072 bytes.
2016-05-26 23:26:11,559 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 150
2016-05-26 23:26:11,559 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000148, cpktTxId=0000000000000000148)
2016-05-27 00:26:11,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 00:26:11,881 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 00:26:11,881 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 155
2016-05-27 00:26:11,881 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-27 00:26:11,882 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 00:26:11,882 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000155 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000155-0000000000000000156
2016-05-27 00:26:11,882 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 157
2016-05-27 00:26:11,951 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 500.00 KB/s
2016-05-27 00:26:11,951 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000156 size 1072 bytes.
2016-05-27 00:26:11,955 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 154
2016-05-27 00:26:11,955 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000150, cpktTxId=0000000000000000150)
2016-05-27 00:32:17,677 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-05-27 00:32:17,678 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741826_1002 172.31.16.173:50010 172.31.16.212:50010 
2016-05-27 00:32:17,678 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741828_1004 172.31.16.173:50010 172.31.16.212:50010 
2016-05-27 00:32:17,686 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741829_1005 172.31.16.173:50010 172.31.16.212:50010 
2016-05-27 00:32:18,954 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.173:50010 to delete [blk_1073741826_1002, blk_1073741828_1004, blk_1073741829_1005]
2016-05-27 00:32:21,954 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.212:50010 to delete [blk_1073741826_1002, blk_1073741828_1004, blk_1073741829_1005]
2016-05-27 00:33:01,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10001.txt._COPYING_
2016-05-27 00:33:02,332 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,332 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,337 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10001.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,385 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10002-8.txt._COPYING_
2016-05-27 00:33:02,410 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,411 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,413 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10002-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,426 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10002.txt._COPYING_
2016-05-27 00:33:02,446 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,450 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,452 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10002.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,467 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10003.txt._COPYING_
2016-05-27 00:33:02,486 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,488 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,492 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10003.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,514 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10004-8.txt._COPYING_
2016-05-27 00:33:02,540 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,541 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,543 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10004-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,556 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10004.txt._COPYING_
2016-05-27 00:33:02,573 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,574 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,576 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10004.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,589 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10005-8.txt._COPYING_
2016-05-27 00:33:02,611 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,612 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,614 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10005-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,627 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10005.txt._COPYING_
2016-05-27 00:33:02,646 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,647 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,649 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10005.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,663 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10006-8.txt._COPYING_
2016-05-27 00:33:02,688 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,689 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,692 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10006-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10006.txt._COPYING_
2016-05-27 00:33:02,722 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,723 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,725 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10006.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10007-8.txt._COPYING_
2016-05-27 00:33:02,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,752 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,754 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10007-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10007.txt._COPYING_
2016-05-27 00:33:02,779 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,780 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,782 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10007.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,796 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10008-8.txt._COPYING_
2016-05-27 00:33:02,818 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,819 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,821 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10008-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,833 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10008.txt._COPYING_
2016-05-27 00:33:02,853 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,857 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,859 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10008.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10009.txt._COPYING_
2016-05-27 00:33:02,909 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,910 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:02,912 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10009.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,927 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10010.txt._COPYING_
2016-05-27 00:33:02,940 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,941 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,945 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10010.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,962 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10011-8.txt._COPYING_
2016-05-27 00:33:02,982 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,983 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:02,985 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10011-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:02,994 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10011.txt._COPYING_
2016-05-27 00:33:03,011 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,012 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,014 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10011.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,024 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10012-8.txt._COPYING_
2016-05-27 00:33:03,046 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,048 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,050 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10012-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10012.txt._COPYING_
2016-05-27 00:33:03,083 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,085 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,086 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10012.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,095 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10013-8.txt._COPYING_
2016-05-27 00:33:03,110 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,111 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,112 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10013-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10013.txt._COPYING_
2016-05-27 00:33:03,136 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,138 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,141 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10013.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10014-8.txt._COPYING_
2016-05-27 00:33:03,166 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,167 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,169 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10014-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,178 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10014.txt._COPYING_
2016-05-27 00:33:03,193 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,194 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,196 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10014.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,206 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10015.txt._COPYING_
2016-05-27 00:33:03,220 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,222 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,226 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10015.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,235 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10016-8.txt._COPYING_
2016-05-27 00:33:03,255 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,256 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,258 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10016-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10016.txt._COPYING_
2016-05-27 00:33:03,283 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,285 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,286 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10016.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,295 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10017-8.txt._COPYING_
2016-05-27 00:33:03,310 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,311 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,314 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10017-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,326 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10017.txt._COPYING_
2016-05-27 00:33:03,342 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,343 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10017.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,356 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10018-8.txt._COPYING_
2016-05-27 00:33:03,370 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,371 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,375 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10018-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,384 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10018.txt._COPYING_
2016-05-27 00:33:03,400 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,401 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,403 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10018.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,412 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10019-8.txt._COPYING_
2016-05-27 00:33:03,426 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,427 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,429 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10019-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10019.txt._COPYING_
2016-05-27 00:33:03,454 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,455 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,457 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10019.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,468 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10020-8.txt._COPYING_
2016-05-27 00:33:03,487 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,488 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,490 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10020-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,500 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10020.txt._COPYING_
2016-05-27 00:33:03,521 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,522 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,525 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10020.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,541 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10021-8.txt._COPYING_
2016-05-27 00:33:03,562 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,562 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,564 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10021-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10021.txt._COPYING_
2016-05-27 00:33:03,596 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,597 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,601 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10021.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10022.txt._COPYING_
2016-05-27 00:33:03,629 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,630 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,632 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10022.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10023.txt._COPYING_
2016-05-27 00:33:03,662 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,663 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,664 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10023.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10024-8.txt._COPYING_
2016-05-27 00:33:03,693 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,694 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,696 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10024-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,705 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10024.txt._COPYING_
2016-05-27 00:33:03,726 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,728 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,731 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10024.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,742 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10025-8.txt._COPYING_
2016-05-27 00:33:03,761 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,762 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,764 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10025-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10025.txt._COPYING_
2016-05-27 00:33:03,796 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,798 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,800 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10025.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,810 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10026-8.txt._COPYING_
2016-05-27 00:33:03,822 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,823 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,824 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10026-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10026.txt._COPYING_
2016-05-27 00:33:03,846 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,847 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,849 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10026.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,858 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10027.txt._COPYING_
2016-05-27 00:33:03,878 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,879 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,881 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10027.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,890 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10028.txt._COPYING_
2016-05-27 00:33:03,907 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,908 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,910 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10028.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,923 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10029-8.txt._COPYING_
2016-05-27 00:33:03,942 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,943 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:03,950 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10029-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,961 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10029.txt._COPYING_
2016-05-27 00:33:03,979 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,980 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:03,982 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10029.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:03,993 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10030-8.txt._COPYING_
2016-05-27 00:33:04,016 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,020 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,022 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10030-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,037 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10030.txt._COPYING_
2016-05-27 00:33:04,060 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,061 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,063 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10030.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10031-8.txt._COPYING_
2016-05-27 00:33:04,096 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,098 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,099 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10031-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,110 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10031.txt._COPYING_
2016-05-27 00:33:04,134 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,135 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,137 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10031.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10032-8.txt._COPYING_
2016-05-27 00:33:04,162 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,163 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,165 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10032-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,173 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10032.txt._COPYING_
2016-05-27 00:33:04,190 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,191 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,193 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10032.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,202 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10033-8.txt._COPYING_
2016-05-27 00:33:04,216 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,217 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,219 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10033-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,234 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10033.txt._COPYING_
2016-05-27 00:33:04,250 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,251 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,253 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10033.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,265 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10034-8.txt._COPYING_
2016-05-27 00:33:04,278 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,281 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,283 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10034-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,292 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10034.txt._COPYING_
2016-05-27 00:33:04,308 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,309 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,311 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10034.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10035-8.txt._COPYING_
2016-05-27 00:33:04,333 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,334 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,336 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10035-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10035.txt._COPYING_
2016-05-27 00:33:04,366 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,368 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,370 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10035.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10036-8.txt._COPYING_
2016-05-27 00:33:04,391 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,392 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,394 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10036-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,404 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10036.txt._COPYING_
2016-05-27 00:33:04,417 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,419 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10036.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,433 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10037-8.txt._COPYING_
2016-05-27 00:33:04,460 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,461 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,464 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10037-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10037.txt._COPYING_
2016-05-27 00:33:04,499 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741895_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,500 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741895_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,502 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10037.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10038-8.txt._COPYING_
2016-05-27 00:33:04,549 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741896_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,550 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741896_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,552 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10038-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,565 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10038.txt._COPYING_
2016-05-27 00:33:04,600 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741897_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,601 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741897_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,603 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10038.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,614 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10039-8.txt._COPYING_
2016-05-27 00:33:04,654 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741898_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,655 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741898_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,657 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10039-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,675 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10039.txt._COPYING_
2016-05-27 00:33:04,706 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741899_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,707 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741899_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,709 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10039.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10040.txt._COPYING_
2016-05-27 00:33:04,730 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741900_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,733 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741900_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,735 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10040.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,748 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10041-8.txt._COPYING_
2016-05-27 00:33:04,770 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741901_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,771 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741901_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,776 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10041-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,785 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10041.txt._COPYING_
2016-05-27 00:33:04,805 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741902_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,806 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741902_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,811 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10041.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,823 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10042-8.txt._COPYING_
2016-05-27 00:33:04,841 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741903_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,842 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741903_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,844 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10042-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10042.txt._COPYING_
2016-05-27 00:33:04,877 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741904_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,878 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741904_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,879 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10042.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10043-8.txt._COPYING_
2016-05-27 00:33:04,907 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741905_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,908 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741905_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:04,910 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10043-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,918 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10043.txt._COPYING_
2016-05-27 00:33:04,931 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741906_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,932 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741906_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,934 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10043.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10044.txt._COPYING_
2016-05-27 00:33:04,964 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741907_1083{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,968 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741907_1083{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,970 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10044.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:04,979 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10045.txt._COPYING_
2016-05-27 00:33:04,995 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741908_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,996 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741908_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:04,999 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10045.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10046.txt._COPYING_
2016-05-27 00:33:05,033 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741909_1085{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,034 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741909_1085{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,036 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10046.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,046 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10047-8.txt._COPYING_
2016-05-27 00:33:05,070 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741910_1086{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,071 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741910_1086{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,073 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10047-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10047.txt._COPYING_
2016-05-27 00:33:05,105 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741911_1087{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,106 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741911_1087{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,108 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10047.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10048.txt._COPYING_
2016-05-27 00:33:05,131 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741912_1088{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,133 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741912_1088{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,134 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10048.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,143 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10049.txt._COPYING_
2016-05-27 00:33:05,157 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741913_1089{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,158 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741913_1089{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,162 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10049.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,172 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10050.txt._COPYING_
2016-05-27 00:33:05,185 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741914_1090{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,186 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741914_1090{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,188 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10050.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10051.txt._COPYING_
2016-05-27 00:33:05,214 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741915_1091{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,215 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741915_1091{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,216 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10051.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,225 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10052-8.txt._COPYING_
2016-05-27 00:33:05,239 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741916_1092{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,240 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741916_1092{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,242 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10052-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10052.txt._COPYING_
2016-05-27 00:33:05,266 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741917_1093{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,266 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741917_1093{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,268 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10052.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10056-8.txt._COPYING_
2016-05-27 00:33:05,301 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741918_1094{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,302 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741918_1094{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,304 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10056-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10056.txt._COPYING_
2016-05-27 00:33:05,337 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741919_1095{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,344 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741919_1095{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,346 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10056.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,355 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10057.txt._COPYING_
2016-05-27 00:33:05,378 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741920_1096{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,379 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741920_1096{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,382 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10057.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10058.txt._COPYING_
2016-05-27 00:33:05,418 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741921_1097{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,419 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741921_1097{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,421 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10058.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,429 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10059.txt._COPYING_
2016-05-27 00:33:05,446 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741922_1098{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,447 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741922_1098{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,449 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10059.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,458 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10060-8.txt._COPYING_
2016-05-27 00:33:05,481 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741923_1099{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,482 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741923_1099{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,485 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10060-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,494 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10060.txt._COPYING_
2016-05-27 00:33:05,518 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741924_1100{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,519 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741924_1100{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,522 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10060.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,531 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10062-8.txt._COPYING_
2016-05-27 00:33:05,559 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741925_1101{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,560 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741925_1101{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,562 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10062-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,575 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10062.txt._COPYING_
2016-05-27 00:33:05,605 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741926_1102{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,608 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741926_1102{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,612 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10062.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,620 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10063.txt._COPYING_
2016-05-27 00:33:05,638 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741927_1103{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,639 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741927_1103{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,641 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10063.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,659 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10064-8.txt._COPYING_
2016-05-27 00:33:05,695 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741928_1104{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,701 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741928_1104{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,708 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10064-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,718 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10064.txt._COPYING_
2016-05-27 00:33:05,817 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741929_1105{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,819 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741929_1105{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,821 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10064.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10065-8.txt._COPYING_
2016-05-27 00:33:05,845 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741930_1106{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,846 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741930_1106{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,848 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10065-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,856 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10065.txt._COPYING_
2016-05-27 00:33:05,871 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741931_1107{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,872 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741931_1107{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:05,874 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10065.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10066-8.txt._COPYING_
2016-05-27 00:33:05,903 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741932_1108{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,904 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741932_1108{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10066-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,918 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10066.txt._COPYING_
2016-05-27 00:33:05,948 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741933_1109{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,949 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741933_1109{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,951 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10066.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:05,961 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10067-8.txt._COPYING_
2016-05-27 00:33:05,990 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741934_1110{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,990 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741934_1110{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:05,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10067-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10067.txt._COPYING_
2016-05-27 00:33:06,021 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741935_1111{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,022 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741935_1111{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,024 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10067.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,035 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10068-8.txt._COPYING_
2016-05-27 00:33:06,062 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741936_1112{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,063 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741936_1112{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,065 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10068-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,076 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10068.txt._COPYING_
2016-05-27 00:33:06,098 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741937_1113{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,099 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741937_1113{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,100 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10068.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,126 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10069-8.txt._COPYING_
2016-05-27 00:33:06,142 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741938_1114{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,143 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741938_1114{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,147 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10069-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,159 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10069.txt._COPYING_
2016-05-27 00:33:06,173 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741939_1115{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,174 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741939_1115{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,179 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10069.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,191 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10070.txt._COPYING_
2016-05-27 00:33:06,208 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741940_1116{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,252 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741940_1116{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,255 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10070.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,264 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10071-8.txt._COPYING_
2016-05-27 00:33:06,281 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741941_1117{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,283 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741941_1117{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,285 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10071-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10071.txt._COPYING_
2016-05-27 00:33:06,323 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741942_1118{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,324 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741942_1118{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,325 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10071.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10072.txt._COPYING_
2016-05-27 00:33:06,354 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741943_1119{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,355 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741943_1119{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,357 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10072.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10073-8.txt._COPYING_
2016-05-27 00:33:06,393 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741944_1120{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,394 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741944_1120{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,396 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10073-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,405 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10073.txt._COPYING_
2016-05-27 00:33:06,429 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741945_1121{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,430 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741945_1121{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,431 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10073.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10074-8.txt._COPYING_
2016-05-27 00:33:06,459 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741946_1122{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,460 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741946_1122{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,462 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10074-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10074.txt._COPYING_
2016-05-27 00:33:06,488 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741947_1123{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,489 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741947_1123{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,490 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10074.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10075.txt._COPYING_
2016-05-27 00:33:06,510 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741948_1124{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,512 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741948_1124{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,515 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10075.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,526 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10076-8.txt._COPYING_
2016-05-27 00:33:06,546 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741949_1125{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,547 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741949_1125{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,548 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10076-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10076.txt._COPYING_
2016-05-27 00:33:06,585 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741950_1126{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,586 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741950_1126{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,588 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10076.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,596 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10077-8.txt._COPYING_
2016-05-27 00:33:06,617 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741951_1127{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,618 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741951_1127{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,620 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10077-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10077.txt._COPYING_
2016-05-27 00:33:06,654 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741952_1128{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,655 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741952_1128{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,656 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10077.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10078-8.txt._COPYING_
2016-05-27 00:33:06,677 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741953_1129{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,678 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741953_1129{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,681 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10078-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,689 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10078.txt._COPYING_
2016-05-27 00:33:06,700 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741954_1130{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,702 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741954_1130{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,704 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10078.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10079-8.txt._COPYING_
2016-05-27 00:33:06,742 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741955_1131{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,745 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741955_1131 size 570420
2016-05-27 00:33:06,745 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10079-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10079.txt._COPYING_
2016-05-27 00:33:06,780 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741956_1132{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,781 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741956_1132{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,783 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10079.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10080-8.txt._COPYING_
2016-05-27 00:33:06,805 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741957_1133{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,806 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741957_1133{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,808 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10080-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,816 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10080.txt._COPYING_
2016-05-27 00:33:06,834 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741958_1134{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,835 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741958_1134{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,836 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10080.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,850 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10081.txt._COPYING_
2016-05-27 00:33:06,867 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741959_1135{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,868 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741959_1135{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,870 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10081.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10082-8.txt._COPYING_
2016-05-27 00:33:06,903 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741960_1136{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,904 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741960_1136{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:06,910 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10082-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10082.txt._COPYING_
2016-05-27 00:33:06,947 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741961_1137{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,948 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741961_1137{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,950 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10082.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,959 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10083.txt._COPYING_
2016-05-27 00:33:06,983 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741962_1138{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,986 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741962_1138{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:06,988 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10083.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:06,998 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1139{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10084-8.txt._COPYING_
2016-05-27 00:33:07,015 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741963_1139{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,017 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741963_1139{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,018 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10084-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,029 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1140{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10084.txt._COPYING_
2016-05-27 00:33:07,049 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741964_1140{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,050 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741964_1140{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,052 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10084.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,067 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1141{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10085-8.txt._COPYING_
2016-05-27 00:33:07,089 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741965_1141{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,091 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741965_1141{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,093 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10085-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,107 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1142{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10085.txt._COPYING_
2016-05-27 00:33:07,128 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741966_1142{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,133 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741966_1142{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,135 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10085.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,143 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1143{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10086-8.txt._COPYING_
2016-05-27 00:33:07,168 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741967_1143{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,173 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741967_1143{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,175 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10086-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1144{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10086.txt._COPYING_
2016-05-27 00:33:07,205 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741968_1144{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,206 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741968_1144{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,207 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10086.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,215 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1145{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10087.txt._COPYING_
2016-05-27 00:33:07,230 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741969_1145{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,230 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741969_1145{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,232 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10087.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,242 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1146{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10088-8.txt._COPYING_
2016-05-27 00:33:07,263 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741970_1146{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,264 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741970_1146{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,266 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10088-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,282 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1147{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10088.txt._COPYING_
2016-05-27 00:33:07,303 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741971_1147{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,304 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741971_1147{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,306 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10088.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,317 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1148{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10089-8.txt._COPYING_
2016-05-27 00:33:07,331 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741972_1148{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,331 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741972_1148{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,333 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10089-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1149{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10089.txt._COPYING_
2016-05-27 00:33:07,356 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741973_1149{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,357 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741973_1149{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,358 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10089.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1150{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10090-8.txt._COPYING_
2016-05-27 00:33:07,388 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741974_1150{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,388 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741974_1150{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,390 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10090-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,401 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1151{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10090.txt._COPYING_
2016-05-27 00:33:07,419 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741975_1151{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,422 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741975_1151{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,424 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10090.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,435 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1152{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10091-8.txt._COPYING_
2016-05-27 00:33:07,448 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741976_1152{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,449 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741976_1152{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,451 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10091-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,460 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1153{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10091.txt._COPYING_
2016-05-27 00:33:07,475 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741977_1153{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/webapp1/data/10091.txt._COPYING_
2016-05-27 00:33:07,475 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741977_1153{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 144592
2016-05-27 00:33:07,475 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741977_1153 size 144592
2016-05-27 00:33:07,877 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10091.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1154{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10092-8.txt._COPYING_
2016-05-27 00:33:07,899 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741978_1154{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,900 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741978_1154{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,901 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10092-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,909 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1155{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10092.txt._COPYING_
2016-05-27 00:33:07,925 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741979_1155{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,926 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741979_1155{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,928 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10092.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,936 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1156{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10093.txt._COPYING_
2016-05-27 00:33:07,955 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741980_1156{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:07,959 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741980_1156 size 310297
2016-05-27 00:33:07,961 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10093.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:07,969 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1157{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10094-8.txt._COPYING_
2016-05-27 00:33:07,995 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741981_1157{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,996 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741981_1157{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:07,997 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10094-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,006 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1158{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10094.txt._COPYING_
2016-05-27 00:33:08,027 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741982_1158{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,028 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741982_1158{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,030 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10094.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,037 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1159{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10095-8.txt._COPYING_
2016-05-27 00:33:08,059 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741983_1159{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,060 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741983_1159{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,064 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10095-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1160{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10095.txt._COPYING_
2016-05-27 00:33:08,108 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741984_1160{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,109 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741984_1160{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,111 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10095.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1161{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10096-8.txt._COPYING_
2016-05-27 00:33:08,146 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741985_1161{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,147 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741985_1161{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,149 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10096-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,159 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1162{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10096.txt._COPYING_
2016-05-27 00:33:08,174 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741986_1162{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,175 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741986_1162{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,177 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10096.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,189 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1163{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10097-8.txt._COPYING_
2016-05-27 00:33:08,209 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741987_1163{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,210 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741987_1163{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,213 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10097-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,222 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1164{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10097.txt._COPYING_
2016-05-27 00:33:08,246 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741988_1164{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,248 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741988_1164 size 326651
2016-05-27 00:33:08,248 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10097.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1165{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10098-8.txt._COPYING_
2016-05-27 00:33:08,281 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741989_1165{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,282 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741989_1165{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,285 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10098-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,298 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1166{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10098.txt._COPYING_
2016-05-27 00:33:08,318 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741990_1166{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,319 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741990_1166{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,321 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10098.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,329 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1167{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10099-8.txt._COPYING_
2016-05-27 00:33:08,349 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741991_1167{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,350 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741991_1167{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,351 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10099-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1168{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10099.txt._COPYING_
2016-05-27 00:33:08,379 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741992_1168{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,380 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741992_1168{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,381 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10099.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1169{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10100-8.txt._COPYING_
2016-05-27 00:33:08,412 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741993_1169{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,412 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741993_1169{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,413 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10100-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,427 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741994_1170{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10100.txt._COPYING_
2016-05-27 00:33:08,451 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741994_1170{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,452 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741994_1170 size 438790
2016-05-27 00:33:08,452 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10100.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,460 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741995_1171{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10101.txt._COPYING_
2016-05-27 00:33:08,487 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741995_1171{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,489 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741995_1171{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,492 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10101.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741996_1172{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10102-8.txt._COPYING_
2016-05-27 00:33:08,522 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741996_1172{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,524 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741996_1172{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,525 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10102-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741997_1173{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10102.txt._COPYING_
2016-05-27 00:33:08,556 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741997_1173{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,557 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741997_1173{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,561 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10102.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741998_1174{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10103-8.txt._COPYING_
2016-05-27 00:33:08,601 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741998_1174{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,602 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741998_1174{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,604 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10103-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,612 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741999_1175{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10103.txt._COPYING_
2016-05-27 00:33:08,642 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741999_1175{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,643 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741999_1175{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,646 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10103.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,654 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742000_1176{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10104-8.txt._COPYING_
2016-05-27 00:33:08,667 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742000_1176{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,668 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742000_1176{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,669 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10104-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,676 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742001_1177{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10104.txt._COPYING_
2016-05-27 00:33:08,688 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742001_1177{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,689 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742001_1177{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,691 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10104.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,705 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742002_1178{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10105-8.txt._COPYING_
2016-05-27 00:33:08,718 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742002_1178{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,719 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742002_1178{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,720 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10105-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742003_1179{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10105.txt._COPYING_
2016-05-27 00:33:08,744 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742003_1179{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,745 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742003_1179{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,747 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10105.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742004_1180{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10106-8.txt._COPYING_
2016-05-27 00:33:08,766 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742004_1180{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,767 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742004_1180{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,769 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10106-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742005_1181{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10106.txt._COPYING_
2016-05-27 00:33:08,789 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742005_1181{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,790 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742005_1181{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,792 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10106.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,799 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742006_1182{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10107-8.txt._COPYING_
2016-05-27 00:33:08,822 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742006_1182{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,823 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742006_1182{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,825 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10107-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,832 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742007_1183{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10107.txt._COPYING_
2016-05-27 00:33:08,851 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742007_1183{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,852 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742007_1183{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,854 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10107.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742008_1184{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10108.txt._COPYING_
2016-05-27 00:33:08,875 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742008_1184{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,876 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742008_1184{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,877 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10108.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742009_1185{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10109.txt._COPYING_
2016-05-27 00:33:08,900 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742009_1185{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,901 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742009_1185{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10109.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742010_1186{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10110-8.txt._COPYING_
2016-05-27 00:33:08,943 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742010_1186{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,944 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742010_1186{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:08,946 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10110-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:08,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742011_1187{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10110.txt._COPYING_
2016-05-27 00:33:08,988 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742011_1187{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,989 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742011_1187{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:08,991 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10110.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,003 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742012_1188{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10111-8.txt._COPYING_
2016-05-27 00:33:09,028 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742012_1188{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,029 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742012_1188{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,031 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10111-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,043 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742013_1189{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10111.txt._COPYING_
2016-05-27 00:33:09,065 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742013_1189{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,066 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742013_1189{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,068 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10111.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,075 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742014_1190{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10112-8.txt._COPYING_
2016-05-27 00:33:09,090 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742014_1190{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,091 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742014_1190{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,098 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10112-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742015_1191{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10112.txt._COPYING_
2016-05-27 00:33:09,120 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742015_1191{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,123 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742015_1191{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,127 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10112.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,138 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742016_1192{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10114-8.txt._COPYING_
2016-05-27 00:33:09,170 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742016_1192{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,171 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742016_1192{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,186 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10114-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742017_1193{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10114.txt._COPYING_
2016-05-27 00:33:09,226 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742017_1193{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,227 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742017_1193{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,228 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10114.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,236 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742018_1194{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10116.txt._COPYING_
2016-05-27 00:33:09,258 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742018_1194{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,259 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742018_1194{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,261 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10116.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742019_1195{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10118-8.txt._COPYING_
2016-05-27 00:33:09,293 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742019_1195{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,293 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742019_1195{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,295 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10118-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,303 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742020_1196{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10118.txt._COPYING_
2016-05-27 00:33:09,327 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742020_1196{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,328 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742020_1196{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,330 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10118.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742021_1197{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10119-8.txt._COPYING_
2016-05-27 00:33:09,354 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742021_1197{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,355 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742021_1197{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,357 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10119-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,367 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742022_1198{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10119.txt._COPYING_
2016-05-27 00:33:09,386 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742022_1198{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,387 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742022_1198{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,389 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10119.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742023_1199{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10120-8.txt._COPYING_
2016-05-27 00:33:09,418 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742023_1199{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,423 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742023_1199{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,424 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10120-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742024_1200{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10120.txt._COPYING_
2016-05-27 00:33:09,452 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742024_1200{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,453 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742024_1200{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,455 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10120.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,464 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742025_1201{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10121-8.txt._COPYING_
2016-05-27 00:33:09,480 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742025_1201{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,481 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742025_1201{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,483 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10121-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,490 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742026_1202{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10121.txt._COPYING_
2016-05-27 00:33:09,507 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742026_1202{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,508 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742026_1202{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,511 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10121.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,518 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742027_1203{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10122-8.txt._COPYING_
2016-05-27 00:33:09,528 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742027_1203{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,529 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742027_1203{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,531 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10122-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,542 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742028_1204{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10122.txt._COPYING_
2016-05-27 00:33:09,555 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742028_1204{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,556 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742028_1204{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,557 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10122.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,566 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742029_1205{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10123.txt._COPYING_
2016-05-27 00:33:09,582 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742029_1205{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,583 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742029_1205{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,584 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10123.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742030_1206{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10124-8.txt._COPYING_
2016-05-27 00:33:09,613 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742030_1206{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,614 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742030_1206{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,616 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10124-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,627 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742031_1207{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10124.txt._COPYING_
2016-05-27 00:33:09,641 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742031_1207{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,642 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742031_1207{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10124.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,651 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742032_1208{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10125-8.txt._COPYING_
2016-05-27 00:33:09,672 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742032_1208{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,673 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742032_1208{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,675 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10125-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742033_1209{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10125.txt._COPYING_
2016-05-27 00:33:09,703 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742033_1209{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,704 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742033_1209{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:09,705 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10125.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742034_1210{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10126.txt._COPYING_
2016-05-27 00:33:09,742 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742034_1210{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,743 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742034_1210{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,744 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10126.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,756 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742035_1211{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10127-8.txt._COPYING_
2016-05-27 00:33:09,770 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742035_1211{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,772 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742035_1211{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,773 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10127-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,781 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742036_1212{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10127.txt._COPYING_
2016-05-27 00:33:09,795 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742036_1212{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,795 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742036_1212{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,797 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10127.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742037_1213{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10128-8.txt._COPYING_
2016-05-27 00:33:09,833 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742037_1213{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,834 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742037_1213{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,836 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10128-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,843 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742038_1214{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10128.txt._COPYING_
2016-05-27 00:33:09,869 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742038_1214{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,870 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742038_1214{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,873 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10128.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742039_1215{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10129-8.txt._COPYING_
2016-05-27 00:33:09,936 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742039_1215{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,937 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742039_1215{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,939 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10129-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,951 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742040_1216{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10129.txt._COPYING_
2016-05-27 00:33:09,973 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742040_1216{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,974 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742040_1216{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:09,975 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10129.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:09,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742041_1217{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10130-8.txt._COPYING_
2016-05-27 00:33:10,017 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742041_1217{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,018 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742041_1217{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,019 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10130-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742042_1218{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10130.txt._COPYING_
2016-05-27 00:33:10,065 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742042_1218{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,066 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742042_1218 size 1254140
2016-05-27 00:33:10,067 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10130.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,074 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742043_1219{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10131.txt._COPYING_
2016-05-27 00:33:10,087 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742043_1219{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,092 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742043_1219{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,094 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10131.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,106 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742044_1220{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10132-8.txt._COPYING_
2016-05-27 00:33:10,130 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742044_1220{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,131 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742044_1220{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,132 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10132-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,143 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742045_1221{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10132.txt._COPYING_
2016-05-27 00:33:10,166 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742045_1221{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,167 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742045_1221{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,169 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10132.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742046_1222{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10133-8.txt._COPYING_
2016-05-27 00:33:10,188 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742046_1222{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,189 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742046_1222{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,191 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10133-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,199 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742047_1223{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10133.txt._COPYING_
2016-05-27 00:33:10,210 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742047_1223{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,211 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742047_1223{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,212 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10133.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742048_1224{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10134.txt._COPYING_
2016-05-27 00:33:10,239 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742048_1224{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,240 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742048_1224{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,243 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10134.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,251 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742049_1225{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10135-8.txt._COPYING_
2016-05-27 00:33:10,274 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742049_1225{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,275 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742049_1225{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,276 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10135-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,286 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742050_1226{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10135.txt._COPYING_
2016-05-27 00:33:10,305 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742050_1226{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,306 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742050_1226{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,308 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10135.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,318 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742051_1227{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10136-8.txt._COPYING_
2016-05-27 00:33:10,391 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742051_1227{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,391 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742051_1227{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,393 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10136-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,405 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742052_1228{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10136.txt._COPYING_
2016-05-27 00:33:10,477 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742052_1228{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,478 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742052_1228{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,480 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10136.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,493 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742053_1229{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10138-8.txt._COPYING_
2016-05-27 00:33:10,517 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742053_1229{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,518 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742053_1229{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,519 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10138-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,527 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742054_1230{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10138.txt._COPYING_
2016-05-27 00:33:10,546 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742054_1230{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,547 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742054_1230{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,552 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10138.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742055_1231{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10139-8.txt._COPYING_
2016-05-27 00:33:10,581 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742055_1231{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,582 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742055_1231{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,584 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10139-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742056_1232{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10139.txt._COPYING_
2016-05-27 00:33:10,616 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742056_1232{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,616 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742056_1232{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,618 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10139.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742057_1233{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10140-0.txt._COPYING_
2016-05-27 00:33:10,645 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742057_1233{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,646 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742057_1233{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,647 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10140-0.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742058_1234{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10141.txt._COPYING_
2016-05-27 00:33:10,673 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742058_1234{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,674 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742058_1234{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,676 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10141.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,684 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742059_1235{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10142-8.txt._COPYING_
2016-05-27 00:33:10,703 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742059_1235{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,704 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742059_1235{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,706 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10142-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,713 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742060_1236{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10142.txt._COPYING_
2016-05-27 00:33:10,733 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742060_1236{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,734 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742060_1236{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,735 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10142.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,742 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742061_1237{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10143-8.txt._COPYING_
2016-05-27 00:33:10,796 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742061_1237{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,796 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742061_1237{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,798 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10143-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742062_1238{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10143.txt._COPYING_
2016-05-27 00:33:10,817 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742062_1238{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,818 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742062_1238{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,822 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10143.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742063_1239{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10144-8.txt._COPYING_
2016-05-27 00:33:10,848 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742063_1239{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,849 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742063_1239{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,854 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10144-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,863 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742064_1240{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10144.txt._COPYING_
2016-05-27 00:33:10,876 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742064_1240{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,877 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742064_1240{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,878 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10144.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742065_1241{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10145-8.txt._COPYING_
2016-05-27 00:33:10,899 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742065_1241{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,900 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742065_1241{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,901 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10145-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742066_1242{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10145.txt._COPYING_
2016-05-27 00:33:10,923 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742066_1242{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,924 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742066_1242{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:10,925 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10145.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,932 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742067_1243{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10146.txt._COPYING_
2016-05-27 00:33:10,949 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742067_1243{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,950 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742067_1243{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:10,952 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10146.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:10,961 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742068_1244{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10147-8.txt._COPYING_
2016-05-27 00:33:10,999 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742068_1244{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,000 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742068_1244{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,002 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10147-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,010 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742069_1245{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10147.txt._COPYING_
2016-05-27 00:33:11,115 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742069_1245{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,116 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742069_1245{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,118 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10147.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,125 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742070_1246{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10148.txt._COPYING_
2016-05-27 00:33:11,151 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742070_1246{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,152 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742070_1246{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,153 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10148.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,164 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742071_1247{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10149-8.txt._COPYING_
2016-05-27 00:33:11,191 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742071_1247{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,192 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742071_1247{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10149-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,202 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742072_1248{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10149.txt._COPYING_
2016-05-27 00:33:11,232 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742072_1248{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,234 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742072_1248 size 1001173
2016-05-27 00:33:11,234 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10149.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,242 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742073_1249{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10150-8.txt._COPYING_
2016-05-27 00:33:11,260 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742073_1249{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,262 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742073_1249{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,263 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10150-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742074_1250{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10150.txt._COPYING_
2016-05-27 00:33:11,293 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742074_1250{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,295 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742074_1250{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,296 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10150.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,307 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742075_1251{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10151-8.txt._COPYING_
2016-05-27 00:33:11,335 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742075_1251{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,336 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742075_1251{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,338 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10151-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742076_1252{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10151.txt._COPYING_
2016-05-27 00:33:11,374 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742076_1252{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,374 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742076_1252{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,379 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10151.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742077_1253{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10159-8.txt._COPYING_
2016-05-27 00:33:11,402 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742077_1253{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,403 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742077_1253{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,404 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10159-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,411 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742078_1254{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10159.txt._COPYING_
2016-05-27 00:33:11,425 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742078_1254{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,426 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742078_1254{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,428 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10159.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,434 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742079_1255{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10161-8.txt._COPYING_
2016-05-27 00:33:11,456 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742079_1255{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,457 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742079_1255{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,458 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10161-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742080_1256{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10161.txt._COPYING_
2016-05-27 00:33:11,495 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742080_1256{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,496 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742080_1256{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,499 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10161.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,508 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742081_1257{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10162-8.txt._COPYING_
2016-05-27 00:33:11,528 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742081_1257{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,529 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742081_1257{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,530 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10162-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,547 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742082_1258{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10162.txt._COPYING_
2016-05-27 00:33:11,582 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742082_1258{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,583 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742082_1258{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,585 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10162.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742083_1259{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/10163-8.txt._COPYING_
2016-05-27 00:33:11,615 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742083_1259{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,616 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742083_1259{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,617 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10163-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742084_1260{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10163.txt._COPYING_
2016-05-27 00:33:11,642 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742084_1260{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,642 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742084_1260{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10163.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,651 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742085_1261{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/10164-8.txt._COPYING_
2016-05-27 00:33:11,666 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742085_1261{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,670 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742085_1261{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,671 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10164-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,682 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742086_1262{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/12370-8.txt._COPYING_
2016-05-27 00:33:11,704 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742086_1262{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,705 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742086_1262{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,706 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12370-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742087_1263{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12370.txt._COPYING_
2016-05-27 00:33:11,738 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742087_1263{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,738 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742087_1263{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,740 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12370.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,747 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742088_1264{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12372-8.txt._COPYING_
2016-05-27 00:33:11,771 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742088_1264{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,772 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742088_1264{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,773 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12372-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,781 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742089_1265{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/12372.txt._COPYING_
2016-05-27 00:33:11,804 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742089_1265{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,807 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742089_1265{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,809 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12372.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,815 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742090_1266{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/12373-8.txt._COPYING_
2016-05-27 00:33:11,836 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742090_1266{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,837 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742090_1266{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,839 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12373-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,845 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742091_1267{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12373.txt._COPYING_
2016-05-27 00:33:11,869 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742091_1267{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,870 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742091_1267{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,871 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12373.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742092_1268{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12374-8.txt._COPYING_
2016-05-27 00:33:11,901 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742092_1268{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12374-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,907 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742092_1268 size 546501
2016-05-27 00:33:11,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742093_1269{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12374.txt._COPYING_
2016-05-27 00:33:11,933 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742093_1269{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,934 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742093_1269{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,936 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12374.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,943 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742094_1270{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/12375-8.txt._COPYING_
2016-05-27 00:33:11,965 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742094_1270{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,966 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742094_1270{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:11,967 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12375-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:11,974 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742095_1271{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12375.txt._COPYING_
2016-05-27 00:33:11,991 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742095_1271{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,992 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742095_1271{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:11,997 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12375.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742096_1272{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12376-8.txt._COPYING_
2016-05-27 00:33:12,025 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742096_1272{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,026 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742096_1272{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,027 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12376-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742097_1273{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/12376.txt._COPYING_
2016-05-27 00:33:12,055 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742097_1273{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,056 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742097_1273{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,057 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12376.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742098_1274{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12377.txt._COPYING_
2016-05-27 00:33:12,077 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742098_1274{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,078 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742098_1274{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,079 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12377.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742099_1275{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/12378-8.txt._COPYING_
2016-05-27 00:33:12,099 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742099_1275{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,100 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742099_1275{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,105 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12378-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742100_1276{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/12378.txt._COPYING_
2016-05-27 00:33:12,128 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742100_1276{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,129 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742100_1276{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,130 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12378.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,137 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742101_1277{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/12380-8.txt._COPYING_
2016-05-27 00:33:12,156 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742101_1277{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,156 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742101_1277{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,158 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12380-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,170 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742102_1278{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12380.txt._COPYING_
2016-05-27 00:33:12,190 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742102_1278{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,190 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742102_1278{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,192 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12380.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,201 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742103_1279{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12381.txt._COPYING_
2016-05-27 00:33:12,225 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742103_1279{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,226 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742103_1279{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,228 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12381.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,235 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742104_1280{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12383-8.txt._COPYING_
2016-05-27 00:33:12,263 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742104_1280{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,264 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742104_1280{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,265 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12383-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742105_1281{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12383.txt._COPYING_
2016-05-27 00:33:12,300 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742105_1281{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,301 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742105_1281{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,302 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12383.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742106_1282{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12384-8.txt._COPYING_
2016-05-27 00:33:12,328 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742106_1282{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,330 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742106_1282{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,331 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12384-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742107_1283{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12384.txt._COPYING_
2016-05-27 00:33:12,352 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742107_1283{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,354 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742107_1283{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,355 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12384.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,371 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742108_1284{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/12385-8.txt._COPYING_
2016-05-27 00:33:12,401 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742108_1284{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,402 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742108_1284{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,403 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12385-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,413 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742109_1285{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12385.txt._COPYING_
2016-05-27 00:33:12,438 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742109_1285{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,440 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742109_1285{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,442 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12385.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742110_1286{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/12386.txt._COPYING_
2016-05-27 00:33:12,471 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742110_1286{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,472 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742110_1286{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,474 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12386.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,483 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742111_1287{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/2babb10.txt._COPYING_
2016-05-27 00:33:12,498 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742111_1287{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,499 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742111_1287{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,504 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/2babb10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,511 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742112_1288{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/3babb10.txt._COPYING_
2016-05-27 00:33:12,526 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742112_1288{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,527 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742112_1288{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,529 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/3babb10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742113_1289{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/50bab10.txt._COPYING_
2016-05-27 00:33:12,549 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742113_1289{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,550 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742113_1289{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,552 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/50bab10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742114_1290{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/Common-README._COPYING_
2016-05-27 00:33:12,566 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742114_1290{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,567 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742114_1290{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,569 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/Common-README._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,587 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742115_1291{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/G-1_Corinthians.txt._COPYING_
2016-05-27 00:33:12,603 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742115_1291{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,604 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742115_1291{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,607 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-1_Corinthians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,623 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742116_1292{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/G-1_John.txt._COPYING_
2016-05-27 00:33:12,648 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742116_1292{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,651 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742116_1292{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,653 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-1_John.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742117_1293{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-1_Peter.txt._COPYING_
2016-05-27 00:33:12,677 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742117_1293{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,677 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742117_1293{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,679 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-1_Peter.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,691 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742118_1294{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-1_Thessalonians.txt._COPYING_
2016-05-27 00:33:12,699 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742118_1294{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,700 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742118_1294{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,701 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-1_Thessalonians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,707 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742119_1295{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/G-1_Timothy.txt._COPYING_
2016-05-27 00:33:12,717 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742119_1295{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,718 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742119_1295{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,720 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-1_Timothy.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742120_1296{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-2_Corinthians.txt._COPYING_
2016-05-27 00:33:12,735 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742120_1296{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,736 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742120_1296{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,737 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-2_Corinthians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,743 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742121_1297{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-2_John.txt._COPYING_
2016-05-27 00:33:12,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742121_1297{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742121_1297{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,753 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-2_John.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,759 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742122_1298{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-2_Peter.txt._COPYING_
2016-05-27 00:33:12,769 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742122_1298{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,770 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742122_1298{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,771 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-2_Peter.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742123_1299{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-2_Thessalonians.txt._COPYING_
2016-05-27 00:33:12,786 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742123_1299{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,787 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742123_1299{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,788 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-2_Thessalonians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,795 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742124_1300{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-2_Timothy.txt._COPYING_
2016-05-27 00:33:12,803 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742124_1300{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,804 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742124_1300{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,805 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-2_Timothy.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,811 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742125_1301{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-3_John.txt._COPYING_
2016-05-27 00:33:12,825 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742125_1301{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,826 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742125_1301{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,828 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-3_John.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,839 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742126_1302{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-Acts.txt._COPYING_
2016-05-27 00:33:12,851 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742126_1302{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,852 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742126_1302{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,853 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Acts.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,859 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742127_1303{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-Colossians.txt._COPYING_
2016-05-27 00:33:12,870 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742127_1303{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,871 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742127_1303{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,872 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Colossians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742128_1304{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-Ephesians.txt._COPYING_
2016-05-27 00:33:12,898 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742128_1304{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,899 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742128_1304{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,901 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Ephesians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742129_1305{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-Galatians.txt._COPYING_
2016-05-27 00:33:12,916 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742129_1305{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,917 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742129_1305{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,918 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Galatians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,928 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742130_1306{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-Hebrews.txt._COPYING_
2016-05-27 00:33:12,937 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742130_1306{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,939 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742130_1306{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,940 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Hebrews.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,946 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742131_1307{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/G-James.txt._COPYING_
2016-05-27 00:33:12,954 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742131_1307{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,955 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742131_1307{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:12,956 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-James.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742132_1308{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-John.txt._COPYING_
2016-05-27 00:33:12,976 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742132_1308{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,977 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742132_1308{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:12,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-John.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:12,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742133_1309{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/G-Jude.txt._COPYING_
2016-05-27 00:33:13,002 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742133_1309{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,003 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742133_1309{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,005 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Jude.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,013 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742134_1310{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/G-Luke.txt._COPYING_
2016-05-27 00:33:13,027 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742134_1310{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,028 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742134_1310{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,030 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Luke.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,036 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742135_1311{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/G-Mark.txt._COPYING_
2016-05-27 00:33:13,047 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742135_1311{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,048 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742135_1311{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,049 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Mark.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,055 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742136_1312{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-Matthew.txt._COPYING_
2016-05-27 00:33:13,066 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742136_1312{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,067 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742136_1312{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,069 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Matthew.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,075 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742137_1313{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-Philemon.txt._COPYING_
2016-05-27 00:33:13,084 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742137_1313{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,085 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742137_1313{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,086 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Philemon.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,092 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742138_1314{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-Philippians.txt._COPYING_
2016-05-27 00:33:13,107 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742138_1314{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,108 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742138_1314{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,109 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Philippians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742139_1315{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-Revelation.txt._COPYING_
2016-05-27 00:33:13,126 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742139_1315{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,128 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742139_1315{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,129 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Revelation.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,137 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742140_1316{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/G-Romans.txt._COPYING_
2016-05-27 00:33:13,147 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742140_1316{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,150 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742140_1316{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,152 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Romans.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,158 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742141_1317{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/G-Titus.txt._COPYING_
2016-05-27 00:33:13,167 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742141_1317{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,168 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742141_1317{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,169 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Titus.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,175 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742142_1318{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/Introduction_and_Copyright.txt._COPYING_
2016-05-27 00:33:13,183 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742142_1318{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,184 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742142_1318{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,185 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/Introduction_and_Copyright.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,191 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742143_1319{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/ajtl10.txt._COPYING_
2016-05-27 00:33:13,206 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742143_1319{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,207 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742143_1319{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,208 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/ajtl10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742144_1320{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/allyr10.txt._COPYING_
2016-05-27 00:33:13,228 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742144_1320{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,229 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742144_1320{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,231 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/allyr10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,238 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742145_1321{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/alpsn10.txt._COPYING_
2016-05-27 00:33:13,263 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742145_1321{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,263 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742145_1321{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,265 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/alpsn10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742146_1322{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/balen10.txt._COPYING_
2016-05-27 00:33:13,283 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742146_1322{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,284 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742146_1322{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,285 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/balen10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,291 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742147_1323{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/baleng2.txt._COPYING_
2016-05-27 00:33:13,308 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742147_1323{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,309 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742147_1323{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,311 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/baleng2.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,317 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742148_1324{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/batlf10.txt._COPYING_
2016-05-27 00:33:13,329 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742148_1324{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,330 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742148_1324{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,331 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/batlf10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742149_1325{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/bgopr10.txt._COPYING_
2016-05-27 00:33:13,354 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742149_1325{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,355 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742149_1325{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,357 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/bgopr10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742150_1326{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/brnte10.txt._COPYING_
2016-05-27 00:33:13,379 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742150_1326{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,380 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742150_1326{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,381 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/brnte10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742151_1327{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/bstjg10.txt._COPYING_
2016-05-27 00:33:13,399 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742151_1327{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,400 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742151_1327{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,401 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/bstjg10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742152_1328{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/cambp10.txt._COPYING_
2016-05-27 00:33:13,421 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742152_1328{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,423 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742152_1328{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,424 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/cambp10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,430 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742153_1329{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/canbe10.txt._COPYING_
2016-05-27 00:33:13,448 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742153_1329{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,449 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742153_1329{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,451 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/canbe10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,457 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742154_1330{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/cantp10.txt._COPYING_
2016-05-27 00:33:13,468 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742154_1330{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,469 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742154_1330{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,474 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/cantp10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742155_1331{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/cfrz10.txt._COPYING_
2016-05-27 00:33:13,502 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742155_1331{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,503 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742155_1331{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,504 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/cfrz10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,511 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742156_1332{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/crsnk10.txt._COPYING_
2016-05-27 00:33:13,531 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742156_1332{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,532 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742156_1332{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,535 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/crsnk10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,550 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742157_1333{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/esbio10.txt._COPYING_
2016-05-27 00:33:13,562 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742157_1333{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,564 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742157_1333{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,565 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/esbio10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742158_1334{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/grybr10.txt._COPYING_
2016-05-27 00:33:13,582 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742158_1334{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,585 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742158_1334{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,586 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/grybr10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742159_1335{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/mklmt10.txt._COPYING_
2016-05-27 00:33:13,614 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742159_1335{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,614 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742159_1335{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,616 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/mklmt10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742160_1336{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/morem10.txt._COPYING_
2016-05-27 00:33:13,632 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742160_1336{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,634 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742160_1336{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,637 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/morem10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742161_1337{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/mspcd10.txt._COPYING_
2016-05-27 00:33:13,655 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742161_1337{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,657 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742161_1337{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,658 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/mspcd10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742162_1338{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/penbr10.txt._COPYING_
2016-05-27 00:33:13,679 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742162_1338{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,681 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742162_1338{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,682 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/penbr10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742163_1339{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/pgjr10.txt._COPYING_
2016-05-27 00:33:13,714 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742163_1339{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,715 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742163_1339 size 346412
2016-05-27 00:33:13,716 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/pgjr10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742164_1340{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/pntvw10.txt._COPYING_
2016-05-27 00:33:13,748 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742164_1340{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742164_1340{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,753 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/pntvw10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742165_1341{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/prcpg10.txt._COPYING_
2016-05-27 00:33:13,788 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742165_1341{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,792 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742165_1341{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,794 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/prcpg10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,800 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742166_1342{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/prhg10.txt._COPYING_
2016-05-27 00:33:13,811 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742166_1342{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,812 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742166_1342{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,814 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/prhg10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,822 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742167_1343{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/prhsb10.txt._COPYING_
2016-05-27 00:33:13,836 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742167_1343{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,837 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742167_1343{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,839 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/prhsb10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742168_1344{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/rmlav10.txt._COPYING_
2016-05-27 00:33:13,861 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742168_1344{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,862 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742168_1344{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,864 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/rmlav10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,870 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742169_1345{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/sesli10.txt._COPYING_
2016-05-27 00:33:13,885 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742169_1345{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,886 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742169_1345{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,887 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/sesli10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,893 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742170_1346{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/data/svyrd10.txt._COPYING_
2016-05-27 00:33:13,905 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742170_1346{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,906 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742170_1346{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:33:13,907 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/svyrd10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,917 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742171_1347{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/tecom10.txt._COPYING_
2016-05-27 00:33:13,932 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742171_1347{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,933 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742171_1347{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,935 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/tecom10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,941 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742172_1348{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/utrkj10.txt._COPYING_
2016-05-27 00:33:13,964 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742172_1348{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,965 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742172_1348{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,966 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/utrkj10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,972 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742173_1349{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/wldsp10.txt._COPYING_
2016-05-27 00:33:13,985 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742173_1349{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,986 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742173_1349{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:13,988 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/wldsp10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:33:13,994 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742174_1350{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/data/wtrbs10.txt._COPYING_
2016-05-27 00:33:14,014 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742174_1350{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:14,015 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742174_1350{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:33:14,017 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/wtrbs10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_44774453_1
2016-05-27 00:38:06,073 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2069 Total time for transactions(ms): 84 Number of transactions batched in Syncs: 1 Number of syncs: 1381 SyncTimes(ms): 1047 
2016-05-27 00:38:06,098 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742175_1351{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/input.txt._COPYING_
2016-05-27 00:38:06,345 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742175_1351{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:38:06,346 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742175_1351{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:38:06,349 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/input.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_2130210325_1
2016-05-27 00:38:52,702 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742176_1352{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp763082671/tmp1558108115/pig-0.15.0-core-h2.jar
2016-05-27 00:38:52,985 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742176_1352{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:38:52,992 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742176_1352{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:38:52,993 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp763082671/tmp1558108115/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_2124215142_1
2016-05-27 00:38:53,005 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742177_1353{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp763082671/tmp395271976/automaton-1.11-8.jar
2016-05-27 00:38:53,021 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742177_1353{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:38:53,021 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742177_1353{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:38:53,023 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp763082671/tmp395271976/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_2124215142_1
2016-05-27 00:38:53,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742178_1354{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp763082671/tmp2044402830/antlr-runtime-3.4.jar
2016-05-27 00:38:53,053 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742178_1354{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:38:53,054 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742178_1354{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:38:53,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp763082671/tmp2044402830/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_2124215142_1
2016-05-27 00:38:53,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742179_1355{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp763082671/tmp-2028522739/joda-time-2.5.jar
2016-05-27 00:38:53,097 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742179_1355{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:38:53,098 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742179_1355{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:38:53,100 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp763082671/tmp-2028522739/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_2124215142_1
2016-05-27 00:39:13,810 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2105 Total time for transactions(ms): 89 Number of transactions batched in Syncs: 1 Number of syncs: 1400 SyncTimes(ms): 1064 
2016-05-27 00:41:09,561 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 00:41:09,563 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 00:41:43,507 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 00:41:43,515 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 00:41:43,526 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 00:41:43,965 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 00:41:44,103 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 00:41:44,104 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 00:41:44,106 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 00:41:44,108 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020 to access this namenode/service.
2016-05-27 00:41:44,727 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 00:41:44,852 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 00:41:44,875 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 00:41:44,893 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 00:41:44,898 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 00:41:44,902 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 00:41:44,902 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 00:41:44,903 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 00:41:44,969 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 00:41:44,972 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 00:41:45,004 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 00:41:45,004 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 00:41:45,311 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 00:41:45,385 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 00:41:45,385 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 00:41:45,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 00:41:45,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 00:41:45,522 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 00:41:45,522 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 00:41:45,523 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 00:41:45,524 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 00:41:45
2016-05-27 00:41:45,526 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 00:41:45,526 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 00:41:45,531 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 00:41:45,531 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 00:41:45,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 00:41:45,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2016-05-27 00:41:45,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 00:41:45,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 00:41:45,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 00:41:45,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 00:41:45,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 00:41:45,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 00:41:45,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 00:41:45,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 00:41:45,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 00:41:45,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 00:41:45,578 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 00:41:45,637 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 00:41:45,637 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 00:41:45,637 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 00:41:45,637 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 00:41:45,639 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 00:41:45,639 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 00:41:45,639 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 00:41:45,640 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 00:41:45,659 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 00:41:45,659 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 00:41:45,660 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 00:41:45,660 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 00:41:45,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 00:41:45,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 00:41:45,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 00:41:45,665 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 00:41:45,665 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 00:41:45,665 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 00:41:45,666 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 00:41:45,666 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 00:41:45,671 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 00:41:45,671 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 00:41:45,671 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 00:41:45,671 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 00:41:45,691 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 2637@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 00:41:45,916 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 00:41:46,428 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000157 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000157-0000000000000002261
2016-05-27 00:41:46,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 12 INodes.
2016-05-27 00:41:46,511 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 00:41:46,511 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 156 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000156
2016-05-27 00:41:46,511 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3a9d23c0 expecting start txid #157
2016-05-27 00:41:46,511 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000157-0000000000000002261
2016-05-27 00:41:46,513 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000157-0000000000000002261' to transaction ID 157
2016-05-27 00:41:46,880 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000157-0000000000000002261 of size 1048576 edits # 2105 loaded in 0 seconds
2016-05-27 00:41:46,887 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 00:41:46,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2262
2016-05-27 00:41:46,968 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 00:41:46,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1294 msecs
2016-05-27 00:41:47,253 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 00:41:47,263 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 00:41:47,275 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 00:41:47,370 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 00:41:47,379 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 00:41:47,379 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 00:41:47,379 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 349 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2016-05-27 00:41:47,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 00:41:47,423 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com/172.31.17.250:8020
2016-05-27 00:41:47,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 00:41:47,421 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 00:41:47,422 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 00:41:47,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 00:41:51,321 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage fb016542-f026-40fc-944f-40f753a95f67
2016-05-27 00:41:51,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 00:41:51,322 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.173:50010
2016-05-27 00:41:51,326 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage c8fad825-9d8a-418d-94a0-a541b2ca3ab6
2016-05-27 00:41:51,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 00:41:51,326 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.212:50010
2016-05-27 00:41:51,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 00:41:51,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-41695162-6240-430e-b24c-97015ec84ec8 for DN 172.31.16.212:50010
2016-05-27 00:41:51,541 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 00:41:51,541 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-02866f87-61ec-46f2-8259-f04703868a93 for DN 172.31.16.173:50010
2016-05-27 00:41:51,620 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 348 has reached the threshold 0.9990 of total blocks 349. The number of live datanodes 2 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2016-05-27 00:41:51,620 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 00:41:51,628 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 349, hasStaleStorage: false, processing time: 29 msecs
2016-05-27 00:41:51,693 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 349, hasStaleStorage: false, processing time: 58 msecs
2016-05-27 00:41:51,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 349
2016-05-27 00:41:51,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 00:41:51,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-27 00:41:51,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 00:41:51,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 00:41:51,717 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 75 msec
2016-05-27 00:42:11,684 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 349 has reached the threshold 0.9990 of total blocks 349. The number of live datanodes 2 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2016-05-27 00:42:21,686 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 36 secs
2016-05-27 00:42:21,686 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2016-05-27 00:42:21,686 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 2 datanodes
2016-05-27 00:42:21,686 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 00:42:37,368 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-27 00:42:37,371 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 00:42:37,371 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-27 00:42:37,371 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 00:42:37,371 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-27 00:42:37,371 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 00:42:38,211 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-27 00:42:38,211 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 00:42:38,212 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-27 00:42:38,212 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 00:42:38,212 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-27 00:42:38,212 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 00:42:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 00:42:56,365 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 00:42:56,365 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 2262
2016-05-27 00:42:56,365 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 00:42:56,366 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 00:42:56,366 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000002262 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000002262-0000000000000002263
2016-05-27 00:42:56,367 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2264
2016-05-27 00:42:58,131 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 2777.78 KB/s
2016-05-27 00:42:58,131 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000002263 size 26228 bytes.
2016-05-27 00:42:58,135 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 156
2016-05-27 00:42:58,136 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000154, cpktTxId=0000000000000000154)
2016-05-27 00:43:25,083 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742180_1356{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp687144847/tmp1736449657/pig-0.15.0-core-h2.jar
2016-05-27 00:43:25,621 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742180_1356{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:43:25,622 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742180_1356 size 4321305
2016-05-27 00:43:25,623 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp687144847/tmp1736449657/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_-1801949641_1
2016-05-27 00:43:25,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742181_1357{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp687144847/tmp-679493947/automaton-1.11-8.jar
2016-05-27 00:43:25,655 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742181_1357{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:43:25,656 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742181_1357{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:43:25,659 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp687144847/tmp-679493947/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_-1801949641_1
2016-05-27 00:43:25,682 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742182_1358{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp687144847/tmp-859479719/antlr-runtime-3.4.jar
2016-05-27 00:43:25,718 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742182_1358{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:43:25,719 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742182_1358{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:43:25,721 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp687144847/tmp-859479719/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_-1801949641_1
2016-05-27 00:43:25,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742183_1359{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp687144847/tmp719954716/joda-time-2.5.jar
2016-05-27 00:43:25,770 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742183_1359{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:43:25,773 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742183_1359{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:43:25,775 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp687144847/tmp719954716/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_-1801949641_1
2016-05-27 00:43:48,346 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742181_1357 172.31.16.212:50010 172.31.16.173:50010 
2016-05-27 00:43:48,347 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742182_1358 172.31.16.173:50010 172.31.16.212:50010 
2016-05-27 00:43:48,347 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742180_1356 172.31.16.212:50010 172.31.16.173:50010 
2016-05-27 00:43:48,347 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742183_1359 172.31.16.212:50010 172.31.16.173:50010 
2016-05-27 00:43:50,404 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.212:50010 to delete [blk_1073742180_1356, blk_1073742181_1357, blk_1073742182_1358, blk_1073742183_1359]
2016-05-27 00:43:53,404 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.173:50010 to delete [blk_1073742180_1356, blk_1073742181_1357, blk_1073742182_1358, blk_1073742183_1359]
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-27 00:45:30,544 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-27 00:45:30,545 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 00:45:30,545 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-27 00:45:30,545 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-27 00:45:30,545 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-27 00:45:30,545 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-05-27 00:45:30,545 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-27 00:45:30,545 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-27 00:45:30,545 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-27 00:45:30,545 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-27 00:47:26,026 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 00:47:26,027 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 00:48:46,099 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 00:48:46,106 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 00:48:46,117 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 00:48:46,567 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 00:48:46,693 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 00:48:46,693 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 00:48:46,696 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 00:48:46,698 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020 to access this namenode/service.
2016-05-27 00:48:47,305 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 00:48:47,425 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 00:48:47,451 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 00:48:47,464 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 00:48:47,475 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 00:48:47,479 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 00:48:47,479 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 00:48:47,479 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 00:48:47,530 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 00:48:47,534 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 00:48:47,562 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 00:48:47,562 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 00:48:47,870 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 00:48:47,937 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 00:48:47,937 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 00:48:48,012 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 00:48:48,012 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 00:48:48,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 00:48:48,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 00:48:48,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 00:48:48,055 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 00:48:48
2016-05-27 00:48:48,056 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 00:48:48,056 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 00:48:48,058 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 00:48:48,058 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 00:48:48,096 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 00:48:48,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2016-05-27 00:48:48,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 00:48:48,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 00:48:48,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 00:48:48,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 00:48:48,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 00:48:48,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 00:48:48,103 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 00:48:48,103 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 00:48:48,103 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 00:48:48,103 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 00:48:48,105 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 00:48:48,154 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 00:48:48,154 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 00:48:48,154 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 00:48:48,154 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 00:48:48,156 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 00:48:48,156 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 00:48:48,156 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 00:48:48,156 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 00:48:48,173 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 00:48:48,173 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 00:48:48,173 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 00:48:48,173 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 00:48:48,174 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 00:48:48,174 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 00:48:48,175 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 00:48:48,177 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 00:48:48,177 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 00:48:48,177 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 00:48:48,178 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 00:48:48,178 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 00:48:48,180 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 00:48:48,180 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 00:48:48,180 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 00:48:48,181 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 00:48:48,195 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 4350@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 00:48:48,416 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 00:48:48,641 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000002264 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000002264-0000000000000002297
2016-05-27 00:48:48,736 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 364 INodes.
2016-05-27 00:48:48,831 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 00:48:48,831 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2263 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000002263
2016-05-27 00:48:48,832 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3a9d23c0 expecting start txid #2264
2016-05-27 00:48:48,832 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000002264-0000000000000002297
2016-05-27 00:48:48,833 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000002264-0000000000000002297' to transaction ID 2264
2016-05-27 00:48:48,870 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000002264-0000000000000002297 of size 1048576 edits # 34 loaded in 0 seconds
2016-05-27 00:48:48,872 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 00:48:48,888 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2298
2016-05-27 00:48:48,930 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 00:48:48,930 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 746 msecs
2016-05-27 00:48:49,090 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 00:48:49,095 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 00:48:49,108 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 00:48:49,190 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 00:48:49,198 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 00:48:49,198 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 00:48:49,198 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 349 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2016-05-27 00:48:49,203 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 00:48:49,245 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 00:48:49,246 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 00:48:49,248 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com/172.31.17.250:8020
2016-05-27 00:48:49,248 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 00:48:49,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 00:48:53,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage fb016542-f026-40fc-944f-40f753a95f67
2016-05-27 00:48:53,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 00:48:53,680 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.173:50010
2016-05-27 00:48:53,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 00:48:53,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-02866f87-61ec-46f2-8259-f04703868a93 for DN 172.31.16.173:50010
2016-05-27 00:48:53,860 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 348 has reached the threshold 0.9990 of total blocks 349. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2016-05-27 00:48:53,860 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 00:48:53,861 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 349, hasStaleStorage: false, processing time: 11 msecs
2016-05-27 00:48:53,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 349
2016-05-27 00:48:53,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 00:48:53,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 348
2016-05-27 00:48:53,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 00:48:53,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 00:48:53,885 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2016-05-27 00:48:53,924 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage c8fad825-9d8a-418d-94a0-a541b2ca3ab6
2016-05-27 00:48:53,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 00:48:53,924 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.212:50010
2016-05-27 00:48:53,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 00:48:53,963 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-41695162-6240-430e-b24c-97015ec84ec8 for DN 172.31.16.212:50010
2016-05-27 00:48:54,013 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 349, hasStaleStorage: false, processing time: 16 msecs
2016-05-27 00:49:13,865 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 349 has reached the threshold 0.9990 of total blocks 349. The number of live datanodes 2 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2016-05-27 00:49:23,867 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2016-05-27 00:49:23,868 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2016-05-27 00:49:23,868 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 2 datanodes
2016-05-27 00:49:23,868 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 00:49:35,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742184_1360{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-118020379/tmp-1844408843/pig-0.15.0-core-h2.jar
2016-05-27 00:49:36,153 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742184_1360{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /tmp/temp-118020379/tmp-1844408843/pig-0.15.0-core-h2.jar
2016-05-27 00:49:36,157 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2016-05-27 00:49:36,169 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742184_1360{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 4321305
2016-05-27 00:49:36,169 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742184_1360 size 4321305
2016-05-27 00:49:36,574 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-118020379/tmp-1844408843/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_1554721050_1
2016-05-27 00:49:36,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742185_1361{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-118020379/tmp889907443/automaton-1.11-8.jar
2016-05-27 00:49:36,600 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742185_1361{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:49:36,600 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742185_1361{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:49:36,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-118020379/tmp889907443/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_1554721050_1
2016-05-27 00:49:36,614 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742186_1362{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp-118020379/tmp-2035153944/antlr-runtime-3.4.jar
2016-05-27 00:49:36,644 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742186_1362{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:49:36,645 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742186_1362{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:49:36,647 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-118020379/tmp-2035153944/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_1554721050_1
2016-05-27 00:49:36,666 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742187_1363{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp-118020379/tmp-49170877/joda-time-2.5.jar
2016-05-27 00:49:36,693 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742187_1363{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:49:36,695 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742187_1363{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:49:36,697 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-118020379/tmp-49170877/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_1554721050_1
2016-05-27 00:49:55,987 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 31 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 18 SyncTimes(ms): 21 
2016-05-27 00:49:58,933 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 00:49:58,933 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 00:49:58,933 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 2298
2016-05-27 00:49:58,934 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 32 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 20 SyncTimes(ms): 24 
2016-05-27 00:49:58,935 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000002298 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000002298-0000000000000002329
2016-05-27 00:49:58,935 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2330
2016-05-27 00:49:59,382 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742184_1360 172.31.16.212:50010 172.31.16.173:50010 
2016-05-27 00:49:59,382 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742186_1362 172.31.16.212:50010 172.31.16.173:50010 
2016-05-27 00:49:59,382 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742187_1363 172.31.16.212:50010 172.31.16.173:50010 
2016-05-27 00:49:59,382 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742185_1361 172.31.16.173:50010 172.31.16.212:50010 
2016-05-27 00:50:00,695 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 4333.33 KB/s
2016-05-27 00:50:00,695 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000002329 size 26914 bytes.
2016-05-27 00:50:00,700 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2263
2016-05-27 00:50:00,700 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000156, cpktTxId=0000000000000000156)
2016-05-27 00:50:01,218 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.212:50010 to delete [blk_1073742184_1360, blk_1073742185_1361, blk_1073742186_1362, blk_1073742187_1363]
2016-05-27 00:50:04,218 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.173:50010 to delete [blk_1073742184_1360, blk_1073742185_1361, blk_1073742186_1362, blk_1073742187_1363]
2016-05-27 00:52:59,520 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 9 
2016-05-27 00:52:59,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742188_1364{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp-519155366/tmp-495625764/pig-0.15.0-core-h2.jar
2016-05-27 00:52:59,871 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742188_1364{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:52:59,871 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742188_1364{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 00:52:59,875 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-519155366/tmp-495625764/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_1760033494_1
2016-05-27 00:52:59,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742189_1365{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-519155366/tmp-363779889/automaton-1.11-8.jar
2016-05-27 00:52:59,900 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742189_1365{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:52:59,904 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742189_1365{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:52:59,906 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-519155366/tmp-363779889/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_1760033494_1
2016-05-27 00:52:59,918 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742190_1366{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-519155366/tmp1189626039/antlr-runtime-3.4.jar
2016-05-27 00:52:59,935 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742190_1366{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:52:59,937 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742190_1366{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:52:59,939 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-519155366/tmp1189626039/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_1760033494_1
2016-05-27 00:52:59,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742191_1367{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-519155366/tmp1377368915/joda-time-2.5.jar
2016-05-27 00:52:59,986 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742191_1367{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:52:59,987 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742191_1367{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 00:52:59,990 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-519155366/tmp1377368915/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_1760033494_1
2016-05-27 00:53:22,708 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742189_1365 172.31.16.173:50010 172.31.16.212:50010 
2016-05-27 00:53:22,709 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742188_1364 172.31.16.212:50010 172.31.16.173:50010 
2016-05-27 00:53:22,709 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742190_1366 172.31.16.173:50010 172.31.16.212:50010 
2016-05-27 00:53:22,709 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742191_1367 172.31.16.173:50010 172.31.16.212:50010 
2016-05-27 00:53:25,234 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.173:50010 to delete [blk_1073742188_1364, blk_1073742189_1365, blk_1073742190_1366, blk_1073742191_1367]
2016-05-27 00:53:28,235 INFO BlockStateChange: BLOCK* BlockManager: ask 172.31.16.212:50010 to delete [blk_1073742188_1364, blk_1073742189_1365, blk_1073742190_1366, blk_1073742191_1367]
2016-05-27 00:56:33,784 INFO logs: Aliases are enabled
2016-05-27 01:05:17,931 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 01:05:17,942 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 01:09:46,857 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 01:09:46,864 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 01:09:46,875 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 01:09:47,337 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 01:09:47,474 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 01:09:47,474 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 01:09:47,477 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 01:09:47,479 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020 to access this namenode/service.
2016-05-27 01:09:48,078 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 01:09:48,203 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 01:09:48,231 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 01:09:48,249 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 01:09:48,254 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 01:09:48,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 01:09:48,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 01:09:48,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 01:09:48,333 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 01:09:48,342 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 01:09:48,396 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 01:09:48,396 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 01:09:48,695 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 01:09:48,776 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 01:09:48,776 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 01:09:48,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 01:09:48,843 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 01:09:48,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 01:09:48,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 01:09:48,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 01:09:48,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 01:09:48
2016-05-27 01:09:48,894 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 01:09:48,894 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:09:48,896 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 01:09:48,897 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 01:09:48,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 01:09:48,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-05-27 01:09:48,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 01:09:48,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 01:09:48,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 01:09:48,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 01:09:48,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 01:09:48,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 01:09:48,938 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 01:09:48,938 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 01:09:48,938 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 01:09:48,938 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 01:09:48,940 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 01:09:48,998 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 01:09:48,998 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:09:48,998 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 01:09:48,998 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 01:09:49,002 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 01:09:49,002 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 01:09:49,002 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 01:09:49,002 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 01:09:49,014 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 01:09:49,015 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:09:49,015 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 01:09:49,015 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 01:09:49,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 01:09:49,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 01:09:49,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 01:09:49,019 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 01:09:49,019 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 01:09:49,019 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 01:09:49,020 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 01:09:49,020 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 01:09:49,024 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 01:09:49,024 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:09:49,024 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 01:09:49,024 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 01:09:49,042 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 6263@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 01:09:49,260 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 01:09:49,488 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000002330 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000002330-0000000000000002364
2016-05-27 01:09:49,584 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 373 INodes.
2016-05-27 01:09:49,717 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 01:09:49,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2329 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000002329
2016-05-27 01:09:49,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3a9d23c0 expecting start txid #2330
2016-05-27 01:09:49,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000002330-0000000000000002364
2016-05-27 01:09:49,719 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000002330-0000000000000002364' to transaction ID 2330
2016-05-27 01:09:49,786 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000002330-0000000000000002364 of size 1048576 edits # 35 loaded in 0 seconds
2016-05-27 01:09:49,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 01:09:49,801 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2365
2016-05-27 01:09:49,843 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 01:09:49,843 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 815 msecs
2016-05-27 01:09:50,013 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 01:09:50,020 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 01:09:50,032 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 01:09:50,122 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 01:09:50,130 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 01:09:50,130 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 01:09:50,131 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 349 blocks to reach the threshold 0.9990 of total blocks 349.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2016-05-27 01:09:50,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:09:50,181 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 01:09:50,182 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 01:09:50,183 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com/172.31.17.250:8020
2016-05-27 01:09:50,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 01:09:50,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 01:09:54,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.17.250:50010, datanodeUuid=f481e888-7ecc-48e0-b65d-a8506fa910d9, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage f481e888-7ecc-48e0-b65d-a8506fa910d9
2016-05-27 01:09:54,366 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:09:54,367 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.17.250:50010
2016-05-27 01:09:54,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:09:54,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-94d5b03e-820b-4514-83b0-16c18751386d for DN 172.31.17.250:50010
2016-05-27 01:09:54,572 INFO BlockStateChange: BLOCK* processReport: from storage DS-94d5b03e-820b-4514-83b0-16c18751386d node DatanodeRegistration(172.31.17.250:50010, datanodeUuid=f481e888-7ecc-48e0-b65d-a8506fa910d9, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-27 01:09:54,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage fb016542-f026-40fc-944f-40f753a95f67
2016-05-27 01:09:54,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:09:54,585 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.173:50010
2016-05-27 01:09:54,620 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:09:54,620 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-02866f87-61ec-46f2-8259-f04703868a93 for DN 172.31.16.173:50010
2016-05-27 01:09:54,651 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 348 has reached the threshold 0.9990 of total blocks 349. The number of live datanodes 2 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2016-05-27 01:09:54,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 01:09:54,652 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 349, hasStaleStorage: false, processing time: 11 msecs
2016-05-27 01:09:54,666 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 349
2016-05-27 01:09:54,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 01:09:54,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 348
2016-05-27 01:09:54,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 01:09:54,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 01:09:54,667 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 12 msec
2016-05-27 01:09:54,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0) storage c8fad825-9d8a-418d-94a0-a541b2ca3ab6
2016-05-27 01:09:54,694 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:09:54,695 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.212:50010
2016-05-27 01:09:54,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:09:54,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-41695162-6240-430e-b24c-97015ec84ec8 for DN 172.31.16.212:50010
2016-05-27 01:09:54,782 INFO BlockStateChange: BLOCK* processReport: from storage DS-41695162-6240-430e-b24c-97015ec84ec8 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=c8fad825-9d8a-418d-94a0-a541b2ca3ab6, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 349, hasStaleStorage: false, processing time: 23 msecs
2016-05-27 01:10:14,658 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 349 has reached the threshold 0.9990 of total blocks 349. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2016-05-27 01:10:24,659 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2016-05-27 01:10:24,659 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2016-05-27 01:10:24,659 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2016-05-27 01:10:24,659 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 01:10:59,616 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:10:59,616 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:10:59,616 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 2365
2016-05-27 01:10:59,616 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2016-05-27 01:10:59,617 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2016-05-27 01:10:59,618 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000002365 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000002365-0000000000000002366
2016-05-27 01:10:59,618 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2367
2016-05-27 01:11:00,925 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 3571.43 KB/s
2016-05-27 01:11:00,926 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000002366 size 26159 bytes.
2016-05-27 01:11:00,934 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2329
2016-05-27 01:11:00,934 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000002263, cpktTxId=0000000000000002263)
2016-05-27 01:12:23,226 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 01:12:23,316 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742192_1368{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp2042896531/tmp1241584558/pig-0.15.0-core-h2.jar
2016-05-27 01:12:24,056 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742192_1368{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /tmp/temp2042896531/tmp1241584558/pig-0.15.0-core-h2.jar
2016-05-27 01:12:24,056 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2016-05-27 01:12:24,072 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742192_1368{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 4321305
2016-05-27 01:12:24,072 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742192_1368 size 4321305
2016-05-27 01:12:24,077 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742192_1368 size 4321305
2016-05-27 01:12:24,467 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp2042896531/tmp1241584558/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_1326815236_1
2016-05-27 01:12:24,476 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742193_1369{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp2042896531/tmp-458894181/automaton-1.11-8.jar
2016-05-27 01:12:24,514 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742193_1369{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:12:24,515 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742193_1369{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:12:24,517 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742193_1369{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:12:24,519 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp2042896531/tmp-458894181/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_1326815236_1
2016-05-27 01:12:24,531 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742194_1370{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp2042896531/tmp716924663/antlr-runtime-3.4.jar
2016-05-27 01:12:24,558 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742194_1370{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:12:24,559 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742194_1370{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:12:24,561 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742194_1370{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:12:24,564 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp2042896531/tmp716924663/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_1326815236_1
2016-05-27 01:12:24,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742195_1371{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp2042896531/tmp-52961515/joda-time-2.5.jar
2016-05-27 01:12:24,618 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073742195_1371{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:12:24,619 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073742195_1371{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:12:24,620 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742195_1371{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-94d5b03e-820b-4514-83b0-16c18751386d:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-02866f87-61ec-46f2-8259-f04703868a93:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-41695162-6240-430e-b24c-97015ec84ec8:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:12:24,623 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp2042896531/tmp-52961515/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_1326815236_1
2016-05-27 01:12:44,898 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-27 01:12:44,908 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-27 01:12:44,909 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2016-05-27 01:12:44,909 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2016-05-27 01:12:44,909 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-27 01:12:44,909 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2016-05-27 01:12:44,909 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 01:12:44,909 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-27 01:12:44,909 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-27 01:12:44,909 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2016-05-27 01:12:44,917 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2016-05-27 01:12:44,917 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-27 01:12:44,917 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2016-05-27 01:12:44,917 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 01:12:44,917 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-27 01:12:44,917 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-27 01:12:44,917 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2016-05-27 01:12:44,918 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2016-05-27 01:12:44,918 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-27 01:12:44,918 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2016-05-27 01:12:44,918 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 01:13:02,760 INFO logs: Aliases are enabled
2016-05-27 01:21:03,639 INFO BlockStateChange: BLOCK* processReport: from storage DS-02866f87-61ec-46f2-8259-f04703868a93 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=fb016542-f026-40fc-944f-40f753a95f67, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d78c489b-471d-46fa-95f9-e593a3dc48e0;nsid=653742559;c=0), blocks: 353, hasStaleStorage: false, processing time: 5 msecs
2016-05-27 01:21:50,173 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 01:21:50,177 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 01:24:20,999 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 01:24:21,007 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 01:24:21,018 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 01:24:21,459 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 01:24:21,590 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 01:24:21,590 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 01:24:21,593 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 01:24:21,595 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020 to access this namenode/service.
2016-05-27 01:24:22,221 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 01:24:22,352 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 01:24:22,377 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 01:24:22,388 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 01:24:22,397 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 01:24:22,401 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 01:24:22,401 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 01:24:22,401 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 01:24:22,456 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 01:24:22,457 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 01:24:22,493 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 01:24:22,493 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 01:24:22,791 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 01:24:22,860 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 01:24:22,860 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 01:24:22,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 01:24:22,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 01:24:22,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 01:24:22,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 01:24:22,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 01:24:22,977 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 01:24:22
2016-05-27 01:24:22,981 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 01:24:22,981 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:24:22,983 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 01:24:22,983 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 01:24:23,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 01:24:23,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-05-27 01:24:23,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 01:24:23,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 01:24:23,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 01:24:23,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 01:24:23,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 01:24:23,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 01:24:23,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 01:24:23,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 01:24:23,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 01:24:23,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 01:24:23,029 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 01:24:23,077 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 01:24:23,077 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:24:23,077 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 01:24:23,077 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 01:24:23,079 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 01:24:23,079 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 01:24:23,079 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 01:24:23,079 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 01:24:23,090 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 01:24:23,090 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:24:23,090 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 01:24:23,091 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 01:24:23,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 01:24:23,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 01:24:23,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 01:24:23,094 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 01:24:23,094 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 01:24:23,094 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 01:24:23,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 01:24:23,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 01:24:23,097 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 01:24:23,098 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:24:23,098 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 01:24:23,098 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 01:24:23,112 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 8515@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 01:24:23,328 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 01:24:23,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2016-05-27 01:24:23,440 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-27 01:24:23,524 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 01:24:23,525 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000
2016-05-27 01:24:23,537 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 01:24:23,545 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2016-05-27 01:24:23,640 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 01:24:23,640 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 539 msecs
2016-05-27 01:24:23,926 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 01:24:23,934 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 01:24:23,951 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 01:24:24,043 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 01:24:24,052 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 01:24:24,052 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 01:24:24,052 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 01:24:24,052 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2016-05-27 01:24:24,052 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-27 01:24:24,052 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 01:24:24,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:24:24,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-27 01:24:24,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 01:24:24,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-27 01:24:24,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 01:24:24,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 01:24:24,067 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2016-05-27 01:24:24,109 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 01:24:24,110 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 01:24:24,112 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com/172.31.17.250:8020
2016-05-27 01:24:24,112 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 01:24:24,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 01:25:33,680 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:25:33,680 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:25:33,680 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2016-05-27 01:25:33,681 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 14 
2016-05-27 01:25:33,681 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 15 
2016-05-27 01:25:33,682 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000002
2016-05-27 01:25:33,684 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2016-05-27 01:26:33,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:26:33,730 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:26:33,730 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3
2016-05-27 01:26:33,731 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2016-05-27 01:26:33,733 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2016-05-27 01:26:33,734 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000003 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000003-0000000000000000004
2016-05-27 01:26:33,734 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5
2016-05-27 01:27:33,750 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:27:33,750 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:27:33,750 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5
2016-05-27 01:27:33,750 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2016-05-27 01:27:33,751 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 6 
2016-05-27 01:27:33,751 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000005 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000005-0000000000000000006
2016-05-27 01:27:33,751 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 7
2016-05-27 01:28:33,773 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:28:33,773 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:28:33,773 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 7
2016-05-27 01:28:33,774 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 01:28:33,774 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 01:28:33,775 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000007 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000007-0000000000000000008
2016-05-27 01:28:33,775 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 9
2016-05-27 01:29:33,797 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:29:33,797 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:29:33,797 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 9
2016-05-27 01:29:33,797 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 01:29:33,798 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 01:29:33,799 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000009 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000009-0000000000000000010
2016-05-27 01:29:33,799 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 11
2016-05-27 01:30:33,814 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:30:33,815 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:30:33,815 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 11
2016-05-27 01:30:33,815 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2016-05-27 01:30:33,816 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2016-05-27 01:30:33,816 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000011 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000011-0000000000000000012
2016-05-27 01:30:33,816 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 13
2016-05-27 01:31:33,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:31:33,832 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:31:33,832 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 13
2016-05-27 01:31:33,832 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 01:31:33,833 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2016-05-27 01:31:33,833 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000013 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000013-0000000000000000014
2016-05-27 01:31:33,834 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 15
2016-05-27 01:32:33,849 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:32:33,849 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:32:33,849 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 15
2016-05-27 01:32:33,850 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 01:32:33,850 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 01:32:33,851 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000015 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000015-0000000000000000016
2016-05-27 01:32:33,851 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 17
2016-05-27 01:33:33,872 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:33:33,872 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:33:33,872 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 17
2016-05-27 01:33:33,872 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 01:33:33,873 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2016-05-27 01:33:33,873 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000017 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000017-0000000000000000018
2016-05-27 01:33:33,874 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 19
2016-05-27 01:34:33,893 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:34:33,893 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:34:33,893 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 19
2016-05-27 01:34:33,893 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 11 
2016-05-27 01:34:33,894 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 11 
2016-05-27 01:34:33,894 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000019 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000019-0000000000000000020
2016-05-27 01:34:33,894 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 21
2016-05-27 01:34:54,825 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 01:34:54,829 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 01:35:34,571 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 01:35:34,579 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 01:35:34,589 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 01:35:35,033 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 01:35:35,143 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 01:35:35,143 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 01:35:35,146 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 01:35:35,148 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020 to access this namenode/service.
2016-05-27 01:35:35,710 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 01:35:35,826 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 01:35:35,850 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 01:35:35,859 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 01:35:35,864 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 01:35:35,868 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 01:35:35,868 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 01:35:35,868 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 01:35:35,918 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 01:35:35,920 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 01:35:35,945 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 01:35:35,945 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 01:35:36,230 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 01:35:36,295 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 01:35:36,295 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 01:35:36,367 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 01:35:36,367 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 01:35:36,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 01:35:36,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 01:35:36,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 01:35:36,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 01:35:36
2016-05-27 01:35:36,412 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 01:35:36,412 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:35:36,414 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 01:35:36,414 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 01:35:36,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 01:35:36,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-05-27 01:35:36,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 01:35:36,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 01:35:36,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 01:35:36,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 01:35:36,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 01:35:36,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 01:35:36,456 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 01:35:36,456 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 01:35:36,456 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 01:35:36,457 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 01:35:36,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 01:35:36,510 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 01:35:36,510 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:35:36,510 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 01:35:36,510 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 01:35:36,512 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 01:35:36,512 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 01:35:36,513 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 01:35:36,513 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 01:35:36,524 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 01:35:36,524 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:35:36,524 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 01:35:36,524 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 01:35:36,525 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 01:35:36,525 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 01:35:36,525 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 01:35:36,527 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 01:35:36,527 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 01:35:36,528 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 01:35:36,529 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 01:35:36,529 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 01:35:36,531 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 01:35:36,531 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:35:36,531 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 01:35:36,531 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 01:35:36,544 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 10507@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 01:35:36,756 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 01:35:36,913 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000021 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000021-0000000000000000021
2016-05-27 01:35:37,021 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-27 01:35:37,076 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 01:35:37,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000
2016-05-27 01:35:37,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@38cf9a71 expecting start txid #1
2016-05-27 01:35:37,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000002
2016-05-27 01:35:37,083 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000002' to transaction ID 1
2016-05-27 01:35:37,084 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2016-05-27 01:35:37,084 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@45a48dda expecting start txid #3
2016-05-27 01:35:37,084 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000003-0000000000000000004
2016-05-27 01:35:37,085 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000003-0000000000000000004' to transaction ID 1
2016-05-27 01:35:37,085 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000003-0000000000000000004 of size 42 edits # 2 loaded in 0 seconds
2016-05-27 01:35:37,085 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@365d06ee expecting start txid #5
2016-05-27 01:35:37,085 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000005-0000000000000000006
2016-05-27 01:35:37,085 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000005-0000000000000000006' to transaction ID 1
2016-05-27 01:35:37,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000005-0000000000000000006 of size 42 edits # 2 loaded in 0 seconds
2016-05-27 01:35:37,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@15720f24 expecting start txid #7
2016-05-27 01:35:37,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000007-0000000000000000008
2016-05-27 01:35:37,089 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000007-0000000000000000008' to transaction ID 1
2016-05-27 01:35:37,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000007-0000000000000000008 of size 42 edits # 2 loaded in 0 seconds
2016-05-27 01:35:37,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@73400f7b expecting start txid #9
2016-05-27 01:35:37,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000009-0000000000000000010
2016-05-27 01:35:37,090 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000009-0000000000000000010' to transaction ID 1
2016-05-27 01:35:37,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000009-0000000000000000010 of size 42 edits # 2 loaded in 0 seconds
2016-05-27 01:35:37,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@72b88f59 expecting start txid #11
2016-05-27 01:35:37,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000011-0000000000000000012
2016-05-27 01:35:37,090 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000011-0000000000000000012' to transaction ID 1
2016-05-27 01:35:37,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000011-0000000000000000012 of size 42 edits # 2 loaded in 0 seconds
2016-05-27 01:35:37,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@32cb56e6 expecting start txid #13
2016-05-27 01:35:37,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000013-0000000000000000014
2016-05-27 01:35:37,091 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000013-0000000000000000014' to transaction ID 1
2016-05-27 01:35:37,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000013-0000000000000000014 of size 42 edits # 2 loaded in 0 seconds
2016-05-27 01:35:37,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@43b63017 expecting start txid #15
2016-05-27 01:35:37,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000015-0000000000000000016
2016-05-27 01:35:37,091 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000015-0000000000000000016' to transaction ID 1
2016-05-27 01:35:37,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000015-0000000000000000016 of size 42 edits # 2 loaded in 0 seconds
2016-05-27 01:35:37,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6e0f58bb expecting start txid #17
2016-05-27 01:35:37,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000017-0000000000000000018
2016-05-27 01:35:37,091 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000017-0000000000000000018' to transaction ID 1
2016-05-27 01:35:37,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000017-0000000000000000018 of size 42 edits # 2 loaded in 0 seconds
2016-05-27 01:35:37,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@318a9570 expecting start txid #19
2016-05-27 01:35:37,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000019-0000000000000000020
2016-05-27 01:35:37,092 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000019-0000000000000000020' to transaction ID 1
2016-05-27 01:35:37,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000019-0000000000000000020 of size 42 edits # 2 loaded in 0 seconds
2016-05-27 01:35:37,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1590579 expecting start txid #21
2016-05-27 01:35:37,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000021-0000000000000000021
2016-05-27 01:35:37,092 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000021-0000000000000000021' to transaction ID 1
2016-05-27 01:35:37,097 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000021-0000000000000000021 of size 1048576 edits # 1 loaded in 0 seconds
2016-05-27 01:35:37,105 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 01:35:37,108 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 22
2016-05-27 01:35:37,152 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 01:35:37,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 618 msecs
2016-05-27 01:35:37,312 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 01:35:37,318 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 01:35:37,329 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 01:35:37,395 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 01:35:37,401 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 01:35:37,401 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 01:35:37,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 01:35:37,401 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2016-05-27 01:35:37,402 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-27 01:35:37,402 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 01:35:37,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:35:37,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-27 01:35:37,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 01:35:37,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-27 01:35:37,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 01:35:37,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 01:35:37,416 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2016-05-27 01:35:37,454 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 01:35:37,455 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 01:35:37,456 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com/172.31.17.250:8020
2016-05-27 01:35:37,456 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 01:35:37,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 01:36:47,338 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:36:47,338 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:36:47,338 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 22
2016-05-27 01:36:47,338 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 01:36:47,339 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 01:36:47,340 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000022 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000022-0000000000000000023
2016-05-27 01:36:47,340 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 24
2016-05-27 01:37:47,391 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:37:47,392 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:37:47,392 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 24
2016-05-27 01:37:47,392 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 10 
2016-05-27 01:37:47,393 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 11 
2016-05-27 01:37:47,393 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000024 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000024-0000000000000000027
2016-05-27 01:37:47,393 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 28
2016-05-27 01:38:47,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:38:47,409 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:38:47,409 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 28
2016-05-27 01:38:47,409 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 01:38:47,410 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2016-05-27 01:38:47,410 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000028 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000028-0000000000000000029
2016-05-27 01:38:47,410 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 30
2016-05-27 01:39:47,434 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:39:47,434 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:39:47,434 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 30
2016-05-27 01:39:47,435 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 01:39:47,435 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 01:39:47,436 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000030 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000030-0000000000000000031
2016-05-27 01:39:47,436 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 32
2016-05-27 01:40:02,469 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume '/dev/disk/by-uuid/23a4139b-b0c3-4cb9-aa4c-620243691435' is 0, which is below the configured reserved amount 104857600
2016-05-27 01:40:02,469 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Entering safe mode.
2016-05-27 01:40:02,469 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ON. 
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2016-05-27 01:40:07,469 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume '/dev/disk/by-uuid/23a4139b-b0c3-4cb9-aa4c-620243691435' is 0, which is below the configured reserved amount 104857600
2016-05-27 01:40:07,469 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2016-05-27 01:40:07,469 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2016-05-27 01:40:12,470 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume '/dev/disk/by-uuid/23a4139b-b0c3-4cb9-aa4c-620243691435' is 0, which is below the configured reserved amount 104857600
2016-05-27 01:40:12,470 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2016-05-27 01:40:12,470 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2016-05-27 01:40:17,470 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume '/dev/disk/by-uuid/23a4139b-b0c3-4cb9-aa4c-620243691435' is 0, which is below the configured reserved amount 104857600
2016-05-27 01:40:17,470 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2016-05-27 01:40:17,470 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2016-05-27 01:40:22,470 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume '/dev/disk/by-uuid/23a4139b-b0c3-4cb9-aa4c-620243691435' is 0, which is below the configured reserved amount 104857600
2016-05-27 01:40:22,470 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2016-05-27 01:40:22,471 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2016-05-27 01:40:22,727 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 01:40:22,729 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 01:41:48,799 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 01:41:48,807 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 01:41:48,818 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 01:41:49,245 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 01:41:49,357 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 01:41:49,357 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 01:41:49,360 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 01:41:49,362 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020 to access this namenode/service.
2016-05-27 01:41:49,983 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 01:41:50,097 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 01:41:50,119 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 01:41:50,128 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 01:41:50,140 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 01:41:50,144 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 01:41:50,144 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 01:41:50,144 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 01:41:50,201 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 01:41:50,203 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 01:41:50,227 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 01:41:50,228 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 01:41:50,500 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 01:41:50,573 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 01:41:50,573 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 01:41:50,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 01:41:50,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 01:41:50,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 01:41:50,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 01:41:50,683 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 01:41:50,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 01:41:50
2016-05-27 01:41:50,688 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 01:41:50,688 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:41:50,689 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 01:41:50,690 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 01:41:50,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 01:41:50,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-05-27 01:41:50,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 01:41:50,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 01:41:50,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 01:41:50,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 01:41:50,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 01:41:50,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 01:41:50,732 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 01:41:50,732 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 01:41:50,732 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 01:41:50,732 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 01:41:50,734 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 01:41:50,781 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 01:41:50,781 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:41:50,781 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 01:41:50,781 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 01:41:50,783 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 01:41:50,783 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 01:41:50,783 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 01:41:50,783 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 01:41:50,795 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 01:41:50,795 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:41:50,795 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 01:41:50,795 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 01:41:50,796 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 01:41:50,796 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 01:41:50,797 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 01:41:50,799 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 01:41:50,799 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 01:41:50,799 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 01:41:50,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 01:41:50,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 01:41:50,802 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 01:41:50,802 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:41:50,802 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 01:41:50,802 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 01:41:50,817 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 12573@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 01:41:51,028 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 01:41:51,037 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2016-05-27 01:41:51,146 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-27 01:41:51,227 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 01:41:51,233 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000
2016-05-27 01:41:51,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 01:41:51,250 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2016-05-27 01:41:51,341 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 01:41:51,341 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 535 msecs
2016-05-27 01:41:51,518 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 01:41:51,524 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 01:41:51,539 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 01:41:51,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 01:41:51,608 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 01:41:51,608 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 01:41:51,608 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 01:41:51,608 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2016-05-27 01:41:51,608 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-27 01:41:51,608 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 01:41:51,616 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:41:51,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-27 01:41:51,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 01:41:51,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-27 01:41:51,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 01:41:51,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 01:41:51,621 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2016-05-27 01:41:51,662 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 01:41:51,663 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 01:41:51,664 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com/172.31.17.250:8020
2016-05-27 01:41:51,664 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 01:41:51,669 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 01:41:56,374 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.17.250:50010, datanodeUuid=922cc285-fb10-4a19-a13e-c226d5ae3622, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-1f515a7c-7fb7-4291-8036-6b6c83b5065c;nsid=920353514;c=0) storage 922cc285-fb10-4a19-a13e-c226d5ae3622
2016-05-27 01:41:56,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:41:56,374 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.17.250:50010
2016-05-27 01:41:56,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:41:56,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-9366b91c-0545-4c8b-b21d-af16d9816648 for DN 172.31.17.250:50010
2016-05-27 01:41:56,531 INFO BlockStateChange: BLOCK* processReport: from storage DS-9366b91c-0545-4c8b-b21d-af16d9816648 node DatanodeRegistration(172.31.17.250:50010, datanodeUuid=922cc285-fb10-4a19-a13e-c226d5ae3622, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-1f515a7c-7fb7-4291-8036-6b6c83b5065c;nsid=920353514;c=0), blocks: 0, hasStaleStorage: false, processing time: 2 msecs
2016-05-27 01:43:01,178 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:43:01,178 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:43:01,178 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2016-05-27 01:43:01,178 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 9 
2016-05-27 01:43:01,179 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 10 
2016-05-27 01:43:01,180 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000004
2016-05-27 01:43:01,182 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5
2016-05-27 01:43:02,681 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-27 01:43:02,681 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000004 size 496 bytes.
2016-05-27 01:43:02,686 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2016-05-27 01:43:18,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10001.txt._COPYING_
2016-05-27 01:43:18,893 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/webapp1/data/10001.txt._COPYING_
2016-05-27 01:43:18,958 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 57022
2016-05-27 01:43:19,314 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10001.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,340 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10002-8.txt._COPYING_
2016-05-27 01:43:19,351 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,355 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10002-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,370 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10002.txt._COPYING_
2016-05-27 01:43:19,379 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,382 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10002.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,402 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10003.txt._COPYING_
2016-05-27 01:43:19,413 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,417 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10003.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10004-8.txt._COPYING_
2016-05-27 01:43:19,462 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,464 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10004-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,476 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10004.txt._COPYING_
2016-05-27 01:43:19,486 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,489 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10004.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,500 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10005-8.txt._COPYING_
2016-05-27 01:43:19,513 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,515 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10005-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10005.txt._COPYING_
2016-05-27 01:43:19,546 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,549 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10005.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,569 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10006-8.txt._COPYING_
2016-05-27 01:43:19,575 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,577 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10006-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10006.txt._COPYING_
2016-05-27 01:43:19,603 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,605 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10006.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10007-8.txt._COPYING_
2016-05-27 01:43:19,633 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,635 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10007-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10007.txt._COPYING_
2016-05-27 01:43:19,653 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,656 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10007.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10008-8.txt._COPYING_
2016-05-27 01:43:19,681 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,686 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10008-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,701 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10008.txt._COPYING_
2016-05-27 01:43:19,712 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,715 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10008.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10009.txt._COPYING_
2016-05-27 01:43:19,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,756 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10009.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10010.txt._COPYING_
2016-05-27 01:43:19,777 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,780 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10010.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,800 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10011-8.txt._COPYING_
2016-05-27 01:43:19,812 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,816 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10011-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,829 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10011.txt._COPYING_
2016-05-27 01:43:19,839 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,842 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10011.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10012-8.txt._COPYING_
2016-05-27 01:43:19,867 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,872 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10012-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10012.txt._COPYING_
2016-05-27 01:43:19,898 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,901 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10012.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10013-8.txt._COPYING_
2016-05-27 01:43:19,924 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,926 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10013-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,940 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10013.txt._COPYING_
2016-05-27 01:43:19,947 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,950 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10013.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10014-8.txt._COPYING_
2016-05-27 01:43:19,968 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,970 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10014-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:19,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10014.txt._COPYING_
2016-05-27 01:43:19,994 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:19,996 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10014.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,007 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10015.txt._COPYING_
2016-05-27 01:43:20,013 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,016 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10015.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10016-8.txt._COPYING_
2016-05-27 01:43:20,032 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10016-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,048 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10016.txt._COPYING_
2016-05-27 01:43:20,054 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10016.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,067 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10017-8.txt._COPYING_
2016-05-27 01:43:20,076 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,079 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10017-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10017.txt._COPYING_
2016-05-27 01:43:20,097 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,099 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10017.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10018-8.txt._COPYING_
2016-05-27 01:43:20,117 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,119 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10018-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,129 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10018.txt._COPYING_
2016-05-27 01:43:20,138 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,142 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10018.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10019-8.txt._COPYING_
2016-05-27 01:43:20,161 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,163 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10019-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10019.txt._COPYING_
2016-05-27 01:43:20,183 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,184 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10019.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10020-8.txt._COPYING_
2016-05-27 01:43:20,203 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,209 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10020-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10020.txt._COPYING_
2016-05-27 01:43:20,229 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,231 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10020.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,243 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10021-8.txt._COPYING_
2016-05-27 01:43:20,255 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,257 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10021-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10021.txt._COPYING_
2016-05-27 01:43:20,277 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,279 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10021.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,291 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10022.txt._COPYING_
2016-05-27 01:43:20,297 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,300 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10022.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10023.txt._COPYING_
2016-05-27 01:43:20,318 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,320 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10023.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,332 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10024-8.txt._COPYING_
2016-05-27 01:43:20,342 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10024-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,359 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10024.txt._COPYING_
2016-05-27 01:43:20,367 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,368 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10024.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,380 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10025-8.txt._COPYING_
2016-05-27 01:43:20,388 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,393 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10025-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,413 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10025.txt._COPYING_
2016-05-27 01:43:20,422 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,425 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10025.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10026-8.txt._COPYING_
2016-05-27 01:43:20,445 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,448 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10026-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,463 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10026.txt._COPYING_
2016-05-27 01:43:20,468 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10026.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,482 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10027.txt._COPYING_
2016-05-27 01:43:20,491 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,493 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10027.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,504 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10028.txt._COPYING_
2016-05-27 01:43:20,511 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,513 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10028.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,524 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10029-8.txt._COPYING_
2016-05-27 01:43:20,532 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,533 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10029-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,544 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10029.txt._COPYING_
2016-05-27 01:43:20,551 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,556 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10029.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,567 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10030-8.txt._COPYING_
2016-05-27 01:43:20,577 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,583 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10030-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,596 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10030.txt._COPYING_
2016-05-27 01:43:20,610 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,612 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10030.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10031-8.txt._COPYING_
2016-05-27 01:43:20,631 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10031-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10031.txt._COPYING_
2016-05-27 01:43:20,652 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,654 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10031.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10032-8.txt._COPYING_
2016-05-27 01:43:20,671 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,673 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10032-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10032.txt._COPYING_
2016-05-27 01:43:20,701 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,702 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10032.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,713 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10033-8.txt._COPYING_
2016-05-27 01:43:20,720 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,721 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10033-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10033.txt._COPYING_
2016-05-27 01:43:20,739 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,741 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10033.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,752 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10034-8.txt._COPYING_
2016-05-27 01:43:20,759 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,763 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10034-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10034.txt._COPYING_
2016-05-27 01:43:20,780 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,781 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10034.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10035-8.txt._COPYING_
2016-05-27 01:43:20,800 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,803 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10035-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,815 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10035.txt._COPYING_
2016-05-27 01:43:20,821 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,823 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10035.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10036-8.txt._COPYING_
2016-05-27 01:43:20,841 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,843 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10036-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10036.txt._COPYING_
2016-05-27 01:43:20,863 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,868 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10036.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10037-8.txt._COPYING_
2016-05-27 01:43:20,888 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,891 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10037-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,902 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10037.txt._COPYING_
2016-05-27 01:43:20,910 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,913 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10037.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,924 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10038-8.txt._COPYING_
2016-05-27 01:43:20,938 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,940 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10038-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10038.txt._COPYING_
2016-05-27 01:43:20,976 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:20,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10038.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:20,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10039-8.txt._COPYING_
2016-05-27 01:43:21,003 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,006 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10039-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,019 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10039.txt._COPYING_
2016-05-27 01:43:21,038 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,109 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10039.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10040.txt._COPYING_
2016-05-27 01:43:21,142 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,144 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10040.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10041-8.txt._COPYING_
2016-05-27 01:43:21,164 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741895_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,170 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10041-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10041.txt._COPYING_
2016-05-27 01:43:21,197 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741896_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,198 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10041.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10042-8.txt._COPYING_
2016-05-27 01:43:21,224 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741897_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,225 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10042-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,235 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10042.txt._COPYING_
2016-05-27 01:43:21,244 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741898_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,246 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10042.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,259 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10043-8.txt._COPYING_
2016-05-27 01:43:21,265 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741899_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,268 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10043-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,279 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10043.txt._COPYING_
2016-05-27 01:43:21,290 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741900_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,291 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10043.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,304 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10044.txt._COPYING_
2016-05-27 01:43:21,311 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741901_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,313 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10044.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,326 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10045.txt._COPYING_
2016-05-27 01:43:21,335 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741902_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,338 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10045.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,350 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10046.txt._COPYING_
2016-05-27 01:43:21,359 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741903_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,361 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10046.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,371 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10047-8.txt._COPYING_
2016-05-27 01:43:21,377 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741904_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,380 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10047-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10047.txt._COPYING_
2016-05-27 01:43:21,398 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741905_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,400 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10047.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,412 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10048.txt._COPYING_
2016-05-27 01:43:21,418 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741906_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10048.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,435 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10049.txt._COPYING_
2016-05-27 01:43:21,440 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741907_1083{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,443 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10049.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10050.txt._COPYING_
2016-05-27 01:43:21,459 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741908_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,461 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10050.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,473 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10051.txt._COPYING_
2016-05-27 01:43:21,479 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741909_1085{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,481 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10051.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,496 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10052-8.txt._COPYING_
2016-05-27 01:43:21,501 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741910_1086{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,503 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10052-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,514 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10052.txt._COPYING_
2016-05-27 01:43:21,520 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741911_1087{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,522 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10052.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,537 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10056-8.txt._COPYING_
2016-05-27 01:43:21,548 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741912_1088{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10056-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,561 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10056.txt._COPYING_
2016-05-27 01:43:21,571 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741913_1089{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,573 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10056.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,587 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10057.txt._COPYING_
2016-05-27 01:43:21,594 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741914_1090{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,596 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10057.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10058.txt._COPYING_
2016-05-27 01:43:21,615 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741915_1091{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:21,618 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10058.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:21,628 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10059.txt._COPYING_
2016-05-27 01:43:21,684 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741916_1092{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/webapp1/data/10059.txt._COPYING_
2016-05-27 01:43:21,686 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741916_1092{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 345835
2016-05-27 01:43:22,086 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10059.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10060-8.txt._COPYING_
2016-05-27 01:43:22,108 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741917_1093{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,113 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10060-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,124 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10060.txt._COPYING_
2016-05-27 01:43:22,133 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741918_1094{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,135 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10060.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10062-8.txt._COPYING_
2016-05-27 01:43:22,160 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741919_1095{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,162 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10062-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,172 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10062.txt._COPYING_
2016-05-27 01:43:22,191 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741920_1096{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,193 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10062.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,205 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10063.txt._COPYING_
2016-05-27 01:43:22,213 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741921_1097{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,217 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10063.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,231 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10064-8.txt._COPYING_
2016-05-27 01:43:22,268 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741922_1098{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,271 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10064-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,285 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10064.txt._COPYING_
2016-05-27 01:43:22,298 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741923_1099{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,300 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10064.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10065-8.txt._COPYING_
2016-05-27 01:43:22,317 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741924_1100{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,321 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10065-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,331 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10065.txt._COPYING_
2016-05-27 01:43:22,337 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741925_1101{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,339 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10065.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,350 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10066-8.txt._COPYING_
2016-05-27 01:43:22,358 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741926_1102{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,360 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10066-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,371 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10066.txt._COPYING_
2016-05-27 01:43:22,381 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741927_1103{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,384 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10066.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10067-8.txt._COPYING_
2016-05-27 01:43:22,404 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741928_1104{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,406 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10067-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,418 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10067.txt._COPYING_
2016-05-27 01:43:22,426 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741929_1105{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,428 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10067.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10068-8.txt._COPYING_
2016-05-27 01:43:22,447 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741930_1106{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,451 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10068-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10068.txt._COPYING_
2016-05-27 01:43:22,478 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741931_1107{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,481 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10068.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,500 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10069-8.txt._COPYING_
2016-05-27 01:43:22,515 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741932_1108{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,517 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10069-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,534 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10069.txt._COPYING_
2016-05-27 01:43:22,544 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741933_1109{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,548 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10069.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10070.txt._COPYING_
2016-05-27 01:43:22,569 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741934_1110{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,571 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10070.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10071-8.txt._COPYING_
2016-05-27 01:43:22,591 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741935_1111{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,593 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10071-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10071.txt._COPYING_
2016-05-27 01:43:22,613 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741936_1112{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,617 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10071.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10072.txt._COPYING_
2016-05-27 01:43:22,642 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741937_1113{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10072.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,656 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10073-8.txt._COPYING_
2016-05-27 01:43:22,668 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741938_1114{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,671 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10073-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,682 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10073.txt._COPYING_
2016-05-27 01:43:22,691 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741939_1115{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,694 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10073.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,704 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10074-8.txt._COPYING_
2016-05-27 01:43:22,711 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741940_1116{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,712 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10074-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10074.txt._COPYING_
2016-05-27 01:43:22,730 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741941_1117{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,731 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10074.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,745 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10075.txt._COPYING_
2016-05-27 01:43:22,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741942_1118{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,752 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10075.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,763 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10076-8.txt._COPYING_
2016-05-27 01:43:22,775 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741943_1119{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,776 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10076-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,801 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10076.txt._COPYING_
2016-05-27 01:43:22,811 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741944_1120{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,812 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10076.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,822 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10077-8.txt._COPYING_
2016-05-27 01:43:22,831 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741945_1121{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,833 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10077-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,844 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10077.txt._COPYING_
2016-05-27 01:43:22,859 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741946_1122{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,863 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10077.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,956 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10078-8.txt._COPYING_
2016-05-27 01:43:22,964 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741947_1123{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,967 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10078-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,976 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10078.txt._COPYING_
2016-05-27 01:43:22,981 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741948_1124{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:22,984 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10078.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:22,994 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10079-8.txt._COPYING_
2016-05-27 01:43:23,006 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741949_1125{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,008 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10079-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,018 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10079.txt._COPYING_
2016-05-27 01:43:23,030 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741950_1126{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,033 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10079.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10080-8.txt._COPYING_
2016-05-27 01:43:23,054 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741951_1127{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10080-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10080.txt._COPYING_
2016-05-27 01:43:23,073 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741952_1128{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,075 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10080.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10081.txt._COPYING_
2016-05-27 01:43:23,092 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741953_1129{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,094 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10081.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,106 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10082-8.txt._COPYING_
2016-05-27 01:43:23,119 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741954_1130{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,121 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10082-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,131 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10082.txt._COPYING_
2016-05-27 01:43:23,141 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741955_1131{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,143 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10082.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10083.txt._COPYING_
2016-05-27 01:43:23,168 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741956_1132{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,170 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10083.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,184 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10084-8.txt._COPYING_
2016-05-27 01:43:23,194 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741957_1133{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,196 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10084-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,207 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10084.txt._COPYING_
2016-05-27 01:43:23,214 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741958_1134{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,216 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10084.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,226 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10085-8.txt._COPYING_
2016-05-27 01:43:23,236 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741959_1135{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,238 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10085-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,248 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10085.txt._COPYING_
2016-05-27 01:43:23,257 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741960_1136{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,260 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10085.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10086-8.txt._COPYING_
2016-05-27 01:43:23,280 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741961_1137{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,289 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10086-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,299 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10086.txt._COPYING_
2016-05-27 01:43:23,307 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741962_1138{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,310 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10086.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,324 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1139{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10087.txt._COPYING_
2016-05-27 01:43:23,331 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741963_1139{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,332 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10087.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,341 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1140{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10088-8.txt._COPYING_
2016-05-27 01:43:23,350 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741964_1140{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,352 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10088-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1141{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10088.txt._COPYING_
2016-05-27 01:43:23,375 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741965_1141{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,379 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10088.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,389 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1142{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10089-8.txt._COPYING_
2016-05-27 01:43:23,398 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741966_1142{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,399 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10089-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,410 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1143{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10089.txt._COPYING_
2016-05-27 01:43:23,416 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741967_1143{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10089.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1144{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10090-8.txt._COPYING_
2016-05-27 01:43:23,437 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741968_1144{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,439 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10090-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1145{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10090.txt._COPYING_
2016-05-27 01:43:23,457 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741969_1145{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,462 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10090.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,474 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1146{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10091-8.txt._COPYING_
2016-05-27 01:43:23,480 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741970_1146{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,482 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10091-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,492 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1147{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10091.txt._COPYING_
2016-05-27 01:43:23,500 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741971_1147{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,502 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10091.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,512 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1148{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10092-8.txt._COPYING_
2016-05-27 01:43:23,517 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741972_1148{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,519 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10092-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1149{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10092.txt._COPYING_
2016-05-27 01:43:23,535 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741973_1149{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,537 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10092.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,547 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1150{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10093.txt._COPYING_
2016-05-27 01:43:23,553 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741974_1150{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,555 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10093.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,564 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1151{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10094-8.txt._COPYING_
2016-05-27 01:43:23,574 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741975_1151{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,576 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10094-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1152{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10094.txt._COPYING_
2016-05-27 01:43:23,596 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741976_1152{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,599 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10094.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,608 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1153{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10095-8.txt._COPYING_
2016-05-27 01:43:23,620 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741977_1153{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,622 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10095-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,636 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1154{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10095.txt._COPYING_
2016-05-27 01:43:23,653 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741978_1154{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,654 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10095.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,664 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1155{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10096-8.txt._COPYING_
2016-05-27 01:43:23,671 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741979_1155{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,672 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10096-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1156{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10096.txt._COPYING_
2016-05-27 01:43:23,690 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741980_1156{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,691 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10096.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,701 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1157{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10097-8.txt._COPYING_
2016-05-27 01:43:23,708 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741981_1157{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,710 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10097-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1158{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10097.txt._COPYING_
2016-05-27 01:43:23,727 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741982_1158{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,728 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10097.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,740 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1159{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10098-8.txt._COPYING_
2016-05-27 01:43:23,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741983_1159{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,753 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10098-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,762 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1160{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10098.txt._COPYING_
2016-05-27 01:43:23,771 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741984_1160{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,774 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10098.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1161{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10099-8.txt._COPYING_
2016-05-27 01:43:23,790 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741985_1161{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,793 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10099-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1162{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10099.txt._COPYING_
2016-05-27 01:43:23,817 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741986_1162{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,819 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10099.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,829 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1163{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10100-8.txt._COPYING_
2016-05-27 01:43:23,837 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741987_1163{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,838 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10100-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,848 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1164{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10100.txt._COPYING_
2016-05-27 01:43:23,856 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741988_1164{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,857 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10100.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1165{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10101.txt._COPYING_
2016-05-27 01:43:23,874 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741989_1165{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,878 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10101.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,888 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1166{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10102-8.txt._COPYING_
2016-05-27 01:43:23,898 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741990_1166{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,900 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10102-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1167{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10102.txt._COPYING_
2016-05-27 01:43:23,926 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741991_1167{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,928 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10102.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,937 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1168{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10103-8.txt._COPYING_
2016-05-27 01:43:23,951 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741992_1168{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,954 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10103-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1169{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10103.txt._COPYING_
2016-05-27 01:43:23,977 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741993_1169{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:23,982 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10103.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:23,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741994_1170{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10104-8.txt._COPYING_
2016-05-27 01:43:24,001 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741994_1170{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,003 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10104-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741995_1171{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10104.txt._COPYING_
2016-05-27 01:43:24,023 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741995_1171{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,025 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10104.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,042 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741996_1172{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10105-8.txt._COPYING_
2016-05-27 01:43:24,048 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741996_1172{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,049 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10105-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741997_1173{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10105.txt._COPYING_
2016-05-27 01:43:24,065 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741997_1173{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,067 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10105.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,076 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741998_1174{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10106-8.txt._COPYING_
2016-05-27 01:43:24,082 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741998_1174{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,086 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10106-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741999_1175{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10106.txt._COPYING_
2016-05-27 01:43:24,104 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741999_1175{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,105 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10106.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742000_1176{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10107-8.txt._COPYING_
2016-05-27 01:43:24,131 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742000_1176{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,197 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10107-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742001_1177{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10107.txt._COPYING_
2016-05-27 01:43:24,222 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742001_1177{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,224 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10107.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742002_1178{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10108.txt._COPYING_
2016-05-27 01:43:24,238 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742002_1178{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,240 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10108.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742003_1179{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10109.txt._COPYING_
2016-05-27 01:43:24,257 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742003_1179{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,259 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10109.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742004_1180{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10110-8.txt._COPYING_
2016-05-27 01:43:24,280 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742004_1180{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,282 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10110-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,291 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742005_1181{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10110.txt._COPYING_
2016-05-27 01:43:24,301 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742005_1181{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,304 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10110.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742006_1182{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10111-8.txt._COPYING_
2016-05-27 01:43:24,322 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742006_1182{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,324 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10111-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,333 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742007_1183{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10111.txt._COPYING_
2016-05-27 01:43:24,342 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742007_1183{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10111.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,353 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742008_1184{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10112-8.txt._COPYING_
2016-05-27 01:43:24,359 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742008_1184{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,361 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10112-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,370 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742009_1185{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10112.txt._COPYING_
2016-05-27 01:43:24,378 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742009_1185{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,385 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10112.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742010_1186{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10114-8.txt._COPYING_
2016-05-27 01:43:24,412 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742010_1186{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,415 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10114-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,424 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742011_1187{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10114.txt._COPYING_
2016-05-27 01:43:24,438 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742011_1187{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,440 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10114.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742012_1188{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10116.txt._COPYING_
2016-05-27 01:43:24,459 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742012_1188{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,461 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10116.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742013_1189{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10118-8.txt._COPYING_
2016-05-27 01:43:24,485 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742013_1189{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,487 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10118-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,502 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742014_1190{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10118.txt._COPYING_
2016-05-27 01:43:24,514 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742014_1190{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,517 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10118.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,531 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742015_1191{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10119-8.txt._COPYING_
2016-05-27 01:43:24,546 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742015_1191{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,549 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10119-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742016_1192{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10119.txt._COPYING_
2016-05-27 01:43:24,575 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742016_1192{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,577 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10119.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742017_1193{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10120-8.txt._COPYING_
2016-05-27 01:43:24,602 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742017_1193{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,605 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10120-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742018_1194{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10120.txt._COPYING_
2016-05-27 01:43:24,623 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742018_1194{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,626 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10120.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742019_1195{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10121-8.txt._COPYING_
2016-05-27 01:43:24,649 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742019_1195{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,651 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10121-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742020_1196{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10121.txt._COPYING_
2016-05-27 01:43:24,671 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742020_1196{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,672 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10121.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742021_1197{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10122-8.txt._COPYING_
2016-05-27 01:43:24,688 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742021_1197{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,690 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10122-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,703 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742022_1198{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10122.txt._COPYING_
2016-05-27 01:43:24,707 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742022_1198{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,715 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10122.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742023_1199{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10123.txt._COPYING_
2016-05-27 01:43:24,735 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742023_1199{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,737 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10123.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,750 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742024_1200{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10124-8.txt._COPYING_
2016-05-27 01:43:24,756 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742024_1200{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,758 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10124-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742025_1201{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10124.txt._COPYING_
2016-05-27 01:43:24,773 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742025_1201{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,775 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10124.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742026_1202{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10125-8.txt._COPYING_
2016-05-27 01:43:24,795 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742026_1202{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,798 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10125-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,806 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742027_1203{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10125.txt._COPYING_
2016-05-27 01:43:24,814 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742027_1203{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,816 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10125.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,833 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742028_1204{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10126.txt._COPYING_
2016-05-27 01:43:24,845 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742028_1204{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,848 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10126.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,860 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742029_1205{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10127-8.txt._COPYING_
2016-05-27 01:43:24,868 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742029_1205{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,870 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10127-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742030_1206{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10127.txt._COPYING_
2016-05-27 01:43:24,889 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742030_1206{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,890 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10127.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742031_1207{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10128-8.txt._COPYING_
2016-05-27 01:43:24,934 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742031_1207{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,936 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10128-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,952 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742032_1208{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10128.txt._COPYING_
2016-05-27 01:43:24,963 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742032_1208{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,965 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10128.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,974 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742033_1209{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10129-8.txt._COPYING_
2016-05-27 01:43:24,984 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742033_1209{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:24,986 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10129-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:24,995 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742034_1210{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10129.txt._COPYING_
2016-05-27 01:43:25,005 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742034_1210{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:25,007 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10129.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:25,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742035_1211{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10130-8.txt._COPYING_
2016-05-27 01:43:25,031 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742035_1211{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:25,033 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10130-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:25,041 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742036_1212{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10130.txt._COPYING_
2016-05-27 01:43:25,058 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742036_1212{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:25,060 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10130.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:25,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742037_1213{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10131.txt._COPYING_
2016-05-27 01:43:25,075 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742037_1213{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:25,077 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10131.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:25,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742038_1214{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10132-8.txt._COPYING_
2016-05-27 01:43:25,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742038_1214{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/webapp1/data/10132-8.txt._COPYING_
2016-05-27 01:43:25,112 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742038_1214{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 763228
2016-05-27 01:43:25,514 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10132-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:25,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742039_1215{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10132.txt._COPYING_
2016-05-27 01:43:25,580 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742039_1215{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/webapp1/data/10132.txt._COPYING_
2016-05-27 01:43:25,582 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742039_1215{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 745726
2016-05-27 01:43:25,983 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10132.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:25,993 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742040_1216{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10133-8.txt._COPYING_
2016-05-27 01:43:25,999 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742040_1216{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:26,000 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10133-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:26,012 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742041_1217{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10133.txt._COPYING_
2016-05-27 01:43:26,017 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742041_1217{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:26,019 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10133.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:26,028 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742042_1218{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10134.txt._COPYING_
2016-05-27 01:43:26,038 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742042_1218{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:26,110 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10134.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:26,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742043_1219{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10135-8.txt._COPYING_
2016-05-27 01:43:26,134 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742043_1219{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:26,137 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10135-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:26,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742044_1220{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10135.txt._COPYING_
2016-05-27 01:43:26,154 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742044_1220{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:26,156 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10135.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:26,166 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742045_1221{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10136-8.txt._COPYING_
2016-05-27 01:43:26,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742045_1221{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/webapp1/data/10136-8.txt._COPYING_
2016-05-27 01:43:26,202 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742045_1221{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 3583729
2016-05-27 01:43:26,603 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10136-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:26,613 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742046_1222{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10136.txt._COPYING_
2016-05-27 01:43:26,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742046_1222{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/webapp1/data/10136.txt._COPYING_
2016-05-27 01:43:26,647 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742046_1222{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 3519666
2016-05-27 01:43:27,049 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10136.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742047_1223{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10138-8.txt._COPYING_
2016-05-27 01:43:27,075 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742047_1223{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,077 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10138-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742048_1224{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10138.txt._COPYING_
2016-05-27 01:43:27,100 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742048_1224{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,103 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10138.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742049_1225{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10139-8.txt._COPYING_
2016-05-27 01:43:27,124 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742049_1225{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,126 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10139-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742050_1226{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10139.txt._COPYING_
2016-05-27 01:43:27,144 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742050_1226{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,146 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10139.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742051_1227{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10140-0.txt._COPYING_
2016-05-27 01:43:27,161 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742051_1227{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,163 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10140-0.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,172 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742052_1228{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10141.txt._COPYING_
2016-05-27 01:43:27,177 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742052_1228{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,179 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10141.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,188 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742053_1229{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10142-8.txt._COPYING_
2016-05-27 01:43:27,201 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742053_1229{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,203 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10142-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742054_1230{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10142.txt._COPYING_
2016-05-27 01:43:27,221 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742054_1230{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,227 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10142.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,236 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742055_1231{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10143-8.txt._COPYING_
2016-05-27 01:43:27,246 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742055_1231{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,248 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10143-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742056_1232{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10143.txt._COPYING_
2016-05-27 01:43:27,261 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742056_1232{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,266 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10143.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742057_1233{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10144-8.txt._COPYING_
2016-05-27 01:43:27,281 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742057_1233{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,283 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10144-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,292 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742058_1234{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10144.txt._COPYING_
2016-05-27 01:43:27,297 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742058_1234{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,301 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10144.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,312 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742059_1235{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10145-8.txt._COPYING_
2016-05-27 01:43:27,318 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742059_1235{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,319 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10145-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,331 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742060_1236{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10145.txt._COPYING_
2016-05-27 01:43:27,338 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742060_1236{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,340 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10145.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742061_1237{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10146.txt._COPYING_
2016-05-27 01:43:27,355 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742061_1237{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,357 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10146.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742062_1238{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10147-8.txt._COPYING_
2016-05-27 01:43:27,382 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742062_1238{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,384 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10147-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,393 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742063_1239{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10147.txt._COPYING_
2016-05-27 01:43:27,406 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742063_1239{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,410 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10147.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,420 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742064_1240{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10148.txt._COPYING_
2016-05-27 01:43:27,435 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742064_1240{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10148.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,452 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742065_1241{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10149-8.txt._COPYING_
2016-05-27 01:43:27,463 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742065_1241{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,465 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10149-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,474 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742066_1242{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10149.txt._COPYING_
2016-05-27 01:43:27,487 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742066_1242{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,489 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10149.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742067_1243{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10150-8.txt._COPYING_
2016-05-27 01:43:27,505 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742067_1243{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,509 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10150-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,522 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742068_1244{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10150.txt._COPYING_
2016-05-27 01:43:27,542 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742068_1244{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,549 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10150.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,561 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742069_1245{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10151-8.txt._COPYING_
2016-05-27 01:43:27,577 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742069_1245{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,580 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10151-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,590 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742070_1246{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10151.txt._COPYING_
2016-05-27 01:43:27,600 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742070_1246{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,603 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10151.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,612 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742071_1247{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10159-8.txt._COPYING_
2016-05-27 01:43:27,621 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742071_1247{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,624 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10159-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742072_1248{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10159.txt._COPYING_
2016-05-27 01:43:27,720 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742072_1248{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:27,722 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10159.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:27,731 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742073_1249{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10161-8.txt._COPYING_
2016-05-27 01:43:27,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742073_1249{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/webapp1/data/10161-8.txt._COPYING_
2016-05-27 01:43:27,746 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742073_1249{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 711945
2016-05-27 01:43:28,147 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10161-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742074_1250{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10161.txt._COPYING_
2016-05-27 01:43:28,170 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742074_1250{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,172 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10161.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742075_1251{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10162-8.txt._COPYING_
2016-05-27 01:43:28,192 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742075_1251{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10162-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742076_1252{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10162.txt._COPYING_
2016-05-27 01:43:28,212 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742076_1252{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,215 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10162.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,224 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742077_1253{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10163-8.txt._COPYING_
2016-05-27 01:43:28,230 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742077_1253{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,235 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10163-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,244 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742078_1254{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10163.txt._COPYING_
2016-05-27 01:43:28,249 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742078_1254{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,252 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10163.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,263 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742079_1255{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/10164-8.txt._COPYING_
2016-05-27 01:43:28,281 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742079_1255{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,283 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/10164-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,294 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742080_1256{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12370-8.txt._COPYING_
2016-05-27 01:43:28,302 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742080_1256{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,305 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12370-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742081_1257{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12370.txt._COPYING_
2016-05-27 01:43:28,323 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742081_1257{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,325 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12370.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,333 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742082_1258{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12372-8.txt._COPYING_
2016-05-27 01:43:28,340 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742082_1258{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,342 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12372-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,353 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742083_1259{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12372.txt._COPYING_
2016-05-27 01:43:28,362 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742083_1259{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,364 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12372.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,372 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742084_1260{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12373-8.txt._COPYING_
2016-05-27 01:43:28,380 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742084_1260{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,383 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12373-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742085_1261{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12373.txt._COPYING_
2016-05-27 01:43:28,399 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742085_1261{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,401 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12373.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,415 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742086_1262{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12374-8.txt._COPYING_
2016-05-27 01:43:28,422 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742086_1262{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,432 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12374-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742087_1263{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12374.txt._COPYING_
2016-05-27 01:43:28,450 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742087_1263{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,453 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12374.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,461 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742088_1264{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12375-8.txt._COPYING_
2016-05-27 01:43:28,468 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742088_1264{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12375-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742089_1265{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12375.txt._COPYING_
2016-05-27 01:43:28,484 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742089_1265{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,486 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12375.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,495 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742090_1266{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12376-8.txt._COPYING_
2016-05-27 01:43:28,502 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742090_1266{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,505 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12376-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742091_1267{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12376.txt._COPYING_
2016-05-27 01:43:28,520 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742091_1267{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12376.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,531 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742092_1268{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12377.txt._COPYING_
2016-05-27 01:43:28,536 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742092_1268{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,538 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12377.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,546 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742093_1269{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12378-8.txt._COPYING_
2016-05-27 01:43:28,551 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742093_1269{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,552 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12378-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,565 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742094_1270{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12378.txt._COPYING_
2016-05-27 01:43:28,578 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742094_1270{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,580 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12378.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742095_1271{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12380-8.txt._COPYING_
2016-05-27 01:43:28,615 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742095_1271{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,617 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12380-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742096_1272{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12380.txt._COPYING_
2016-05-27 01:43:28,635 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742096_1272{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,637 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12380.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,645 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742097_1273{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12381.txt._COPYING_
2016-05-27 01:43:28,652 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742097_1273{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,653 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12381.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,664 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742098_1274{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12383-8.txt._COPYING_
2016-05-27 01:43:28,672 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742098_1274{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,675 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12383-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,689 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742099_1275{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12383.txt._COPYING_
2016-05-27 01:43:28,700 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742099_1275{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,705 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12383.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742100_1276{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12384-8.txt._COPYING_
2016-05-27 01:43:28,726 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742100_1276{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,727 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12384-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742101_1277{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12384.txt._COPYING_
2016-05-27 01:43:28,741 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742101_1277{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,743 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12384.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,776 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742102_1278{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12385-8.txt._COPYING_
2016-05-27 01:43:28,793 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742102_1278{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,796 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12385-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,807 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742103_1279{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12385.txt._COPYING_
2016-05-27 01:43:28,819 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742103_1279{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,821 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12385.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742104_1280{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/12386.txt._COPYING_
2016-05-27 01:43:28,839 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742104_1280{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,841 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/12386.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,850 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742105_1281{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/2babb10.txt._COPYING_
2016-05-27 01:43:28,856 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742105_1281{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,859 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/2babb10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,868 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742106_1282{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/3babb10.txt._COPYING_
2016-05-27 01:43:28,873 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742106_1282{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,876 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/3babb10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742107_1283{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/50bab10.txt._COPYING_
2016-05-27 01:43:28,890 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742107_1283{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,892 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/50bab10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,900 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742108_1284{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/Common-README._COPYING_
2016-05-27 01:43:28,904 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742108_1284{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,906 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/Common-README._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742109_1285{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-1_Corinthians.txt._COPYING_
2016-05-27 01:43:28,927 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742109_1285{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,929 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-1_Corinthians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,947 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742110_1286{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-1_John.txt._COPYING_
2016-05-27 01:43:28,956 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742110_1286{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,958 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-1_John.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:28,975 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742111_1287{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-1_Peter.txt._COPYING_
2016-05-27 01:43:28,987 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742111_1287{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:28,989 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-1_Peter.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742112_1288{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-1_Thessalonians.txt._COPYING_
2016-05-27 01:43:29,010 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742112_1288{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,013 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-1_Thessalonians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,027 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742113_1289{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-1_Timothy.txt._COPYING_
2016-05-27 01:43:29,035 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742113_1289{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,036 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-1_Timothy.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,049 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742114_1290{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-2_Corinthians.txt._COPYING_
2016-05-27 01:43:29,056 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742114_1290{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,058 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-2_Corinthians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742115_1291{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-2_John.txt._COPYING_
2016-05-27 01:43:29,078 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742115_1291{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,079 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-2_John.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,090 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742116_1292{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-2_Peter.txt._COPYING_
2016-05-27 01:43:29,094 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742116_1292{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,096 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-2_Peter.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,103 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742117_1293{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-2_Thessalonians.txt._COPYING_
2016-05-27 01:43:29,107 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742117_1293{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,109 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-2_Thessalonians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742118_1294{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-2_Timothy.txt._COPYING_
2016-05-27 01:43:29,120 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742118_1294{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,122 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-2_Timothy.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,132 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742119_1295{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-3_John.txt._COPYING_
2016-05-27 01:43:29,136 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742119_1295{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,138 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-3_John.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,145 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742120_1296{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Acts.txt._COPYING_
2016-05-27 01:43:29,150 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742120_1296{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,152 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Acts.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,158 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742121_1297{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Colossians.txt._COPYING_
2016-05-27 01:43:29,162 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742121_1297{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,164 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Colossians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,179 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742122_1298{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Ephesians.txt._COPYING_
2016-05-27 01:43:29,183 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742122_1298{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,187 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Ephesians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742123_1299{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Galatians.txt._COPYING_
2016-05-27 01:43:29,203 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742123_1299{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,205 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Galatians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,213 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742124_1300{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Hebrews.txt._COPYING_
2016-05-27 01:43:29,217 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742124_1300{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,220 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Hebrews.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742125_1301{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-James.txt._COPYING_
2016-05-27 01:43:29,231 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742125_1301{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,232 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-James.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,241 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742126_1302{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-John.txt._COPYING_
2016-05-27 01:43:29,246 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742126_1302{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,248 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-John.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,255 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742127_1303{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Jude.txt._COPYING_
2016-05-27 01:43:29,275 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742127_1303{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,277 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Jude.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,292 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742128_1304{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Luke.txt._COPYING_
2016-05-27 01:43:29,303 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742128_1304{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,306 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Luke.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,316 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742129_1305{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Mark.txt._COPYING_
2016-05-27 01:43:29,335 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742129_1305{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,337 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Mark.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742130_1306{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Matthew.txt._COPYING_
2016-05-27 01:43:29,357 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742130_1306{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,359 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Matthew.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742131_1307{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Philemon.txt._COPYING_
2016-05-27 01:43:29,369 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742131_1307{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,371 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Philemon.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742132_1308{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Philippians.txt._COPYING_
2016-05-27 01:43:29,382 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742132_1308{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,384 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Philippians.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,393 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742133_1309{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Revelation.txt._COPYING_
2016-05-27 01:43:29,398 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742133_1309{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,400 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Revelation.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742134_1310{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Romans.txt._COPYING_
2016-05-27 01:43:29,413 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742134_1310{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,414 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Romans.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742135_1311{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/G-Titus.txt._COPYING_
2016-05-27 01:43:29,426 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742135_1311{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,428 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/G-Titus.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,434 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742136_1312{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/Introduction_and_Copyright.txt._COPYING_
2016-05-27 01:43:29,438 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742136_1312{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,440 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/Introduction_and_Copyright.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742137_1313{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/ajtl10.txt._COPYING_
2016-05-27 01:43:29,455 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742137_1313{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,457 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/ajtl10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742138_1314{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/allyr10.txt._COPYING_
2016-05-27 01:43:29,469 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742138_1314{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,472 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/allyr10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,483 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742139_1315{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/alpsn10.txt._COPYING_
2016-05-27 01:43:29,490 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742139_1315{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,492 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/alpsn10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,501 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742140_1316{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/balen10.txt._COPYING_
2016-05-27 01:43:29,505 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742140_1316{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,507 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/balen10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,514 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742141_1317{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/baleng2.txt._COPYING_
2016-05-27 01:43:29,524 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742141_1317{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,526 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/baleng2.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,534 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742142_1318{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/batlf10.txt._COPYING_
2016-05-27 01:43:29,538 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742142_1318{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,540 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/batlf10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742143_1319{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/bgopr10.txt._COPYING_
2016-05-27 01:43:29,553 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742143_1319{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,563 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/bgopr10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,570 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742144_1320{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/brnte10.txt._COPYING_
2016-05-27 01:43:29,579 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742144_1320{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,582 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/brnte10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,605 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742145_1321{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/bstjg10.txt._COPYING_
2016-05-27 01:43:29,617 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742145_1321{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,619 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/bstjg10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,628 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742146_1322{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/cambp10.txt._COPYING_
2016-05-27 01:43:29,632 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742146_1322{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,634 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/cambp10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742147_1323{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/canbe10.txt._COPYING_
2016-05-27 01:43:29,650 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742147_1323{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,651 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/canbe10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742148_1324{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/cantp10.txt._COPYING_
2016-05-27 01:43:29,664 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742148_1324{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,666 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/cantp10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,673 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742149_1325{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/cfrz10.txt._COPYING_
2016-05-27 01:43:29,681 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742149_1325{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,686 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/cfrz10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742150_1326{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/crsnk10.txt._COPYING_
2016-05-27 01:43:29,701 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742150_1326{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,704 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/crsnk10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,712 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742151_1327{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/esbio10.txt._COPYING_
2016-05-27 01:43:29,720 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742151_1327{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,721 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/esbio10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742152_1328{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/grybr10.txt._COPYING_
2016-05-27 01:43:29,733 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742152_1328{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,739 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/grybr10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,747 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742153_1329{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/mklmt10.txt._COPYING_
2016-05-27 01:43:29,757 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742153_1329{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,759 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/mklmt10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,848 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742154_1330{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/morem10.txt._COPYING_
2016-05-27 01:43:29,853 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742154_1330{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,855 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/morem10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,863 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742155_1331{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/mspcd10.txt._COPYING_
2016-05-27 01:43:29,868 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742155_1331{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,870 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/mspcd10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742156_1332{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/penbr10.txt._COPYING_
2016-05-27 01:43:29,884 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742156_1332{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,885 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/penbr10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,905 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742157_1333{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/pgjr10.txt._COPYING_
2016-05-27 01:43:29,930 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742157_1333{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,931 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/pgjr10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742158_1334{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/pntvw10.txt._COPYING_
2016-05-27 01:43:29,967 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742158_1334{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,970 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/pntvw10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:29,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742159_1335{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/prcpg10.txt._COPYING_
2016-05-27 01:43:29,993 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742159_1335{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:29,998 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/prcpg10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:30,012 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742160_1336{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/prhg10.txt._COPYING_
2016-05-27 01:43:30,019 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742160_1336{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:30,021 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/prhg10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:30,028 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742161_1337{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/prhsb10.txt._COPYING_
2016-05-27 01:43:30,034 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742161_1337{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:30,035 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/prhsb10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:30,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742162_1338{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/rmlav10.txt._COPYING_
2016-05-27 01:43:30,051 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742162_1338{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:30,052 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/rmlav10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:30,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742163_1339{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/sesli10.txt._COPYING_
2016-05-27 01:43:30,066 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742163_1339{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:30,067 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/sesli10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:30,075 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742164_1340{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/svyrd10.txt._COPYING_
2016-05-27 01:43:30,079 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742164_1340{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:30,081 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/svyrd10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:30,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742165_1341{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/tecom10.txt._COPYING_
2016-05-27 01:43:30,094 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742165_1341{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:30,095 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/tecom10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:30,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742166_1342{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/utrkj10.txt._COPYING_
2016-05-27 01:43:30,113 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742166_1342{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:30,119 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/utrkj10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:30,127 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742167_1343{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/wldsp10.txt._COPYING_
2016-05-27 01:43:30,132 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742167_1343{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:30,133 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/wldsp10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:30,140 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742168_1344{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/data/wtrbs10.txt._COPYING_
2016-05-27 01:43:30,147 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742168_1344{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:30,149 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/data/wtrbs10.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1986830832_1
2016-05-27 01:43:57,775 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742169_1345{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /user/webapp1/input.txt._COPYING_
2016-05-27 01:43:58,023 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742169_1345{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:43:58,027 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/input.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1595339397_1
2016-05-27 01:44:38,218 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2074 Total time for transactions(ms): 96 Number of transactions batched in Syncs: 7 Number of syncs: 1383 SyncTimes(ms): 1460 
2016-05-27 01:44:38,285 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742170_1346{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /tmp/temp-1970010442/tmp-115221824/pig-0.15.0-core-h2.jar
2016-05-27 01:44:38,513 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742170_1346{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:44:38,516 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1970010442/tmp-115221824/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_-870961031_1
2016-05-27 01:44:38,527 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742171_1347{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /tmp/temp-1970010442/tmp-537977440/automaton-1.11-8.jar
2016-05-27 01:44:38,535 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742171_1347{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:44:38,537 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1970010442/tmp-537977440/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_-870961031_1
2016-05-27 01:44:38,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742172_1348{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /tmp/temp-1970010442/tmp-1806146306/antlr-runtime-3.4.jar
2016-05-27 01:44:38,562 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742172_1348{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:44:38,567 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1970010442/tmp-1806146306/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_-870961031_1
2016-05-27 01:44:38,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742173_1349{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} for /tmp/temp-1970010442/tmp-710111052/joda-time-2.5.jar
2016-05-27 01:44:38,603 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073742173_1349{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-9366b91c-0545-4c8b-b21d-af16d9816648:NORMAL:172.31.17.250:50010|RBW]]} size 0
2016-05-27 01:44:38,606 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1970010442/tmp-710111052/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_-870961031_1
2016-05-27 01:45:49,936 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 01:45:49,938 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 01:47:12,363 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 01:47:12,370 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 01:47:12,379 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 01:47:12,837 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 01:47:12,972 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 01:47:12,972 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 01:47:12,974 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 01:47:12,976 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020 to access this namenode/service.
2016-05-27 01:47:13,589 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 01:47:13,704 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 01:47:13,733 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 01:47:13,748 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 01:47:13,758 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 01:47:13,765 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 01:47:13,765 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 01:47:13,765 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 01:47:13,831 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 01:47:13,832 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 01:47:13,889 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 01:47:13,889 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 01:47:14,192 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 01:47:14,257 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 01:47:14,257 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 01:47:14,331 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 01:47:14,331 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 01:47:14,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 01:47:14,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 01:47:14,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 01:47:14,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 01:47:14
2016-05-27 01:47:14,375 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 01:47:14,375 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:47:14,377 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 01:47:14,377 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 01:47:14,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 01:47:14,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-05-27 01:47:14,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 01:47:14,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 01:47:14,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 01:47:14,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 01:47:14,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 01:47:14,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 01:47:14,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 01:47:14,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 01:47:14,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 01:47:14,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 01:47:14,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 01:47:14,470 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 01:47:14,470 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:47:14,470 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 01:47:14,470 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 01:47:14,472 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 01:47:14,472 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 01:47:14,472 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 01:47:14,473 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 01:47:14,481 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 01:47:14,482 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:47:14,482 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 01:47:14,482 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 01:47:14,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 01:47:14,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 01:47:14,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 01:47:14,485 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 01:47:14,485 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 01:47:14,485 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 01:47:14,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 01:47:14,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 01:47:14,489 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 01:47:14,489 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 01:47:14,489 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 01:47:14,489 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 01:47:14,503 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 16461@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 01:47:14,704 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 01:47:14,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2016-05-27 01:47:14,812 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-27 01:47:14,900 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 01:47:14,905 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000
2016-05-27 01:47:14,921 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 01:47:14,929 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2016-05-27 01:47:15,040 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 01:47:15,040 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 548 msecs
2016-05-27 01:47:15,330 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com:8020
2016-05-27 01:47:15,338 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 01:47:15,355 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 01:47:15,449 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 01:47:15,457 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 01:47:15,457 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 01:47:15,457 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 01:47:15,458 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2016-05-27 01:47:15,458 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-27 01:47:15,458 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 01:47:15,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:47:15,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-27 01:47:15,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 01:47:15,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-27 01:47:15,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 01:47:15,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 01:47:15,472 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2016-05-27 01:47:15,513 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 01:47:15,514 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 01:47:15,515 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-52-77-244-73.ap-southeast-1.compute.amazonaws.com/172.31.17.250:8020
2016-05-27 01:47:15,515 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 01:47:15,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 01:47:19,910 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.17.250:50010, datanodeUuid=1b8a596e-1d11-4f20-9ba4-681413c713f1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0) storage 1b8a596e-1d11-4f20-9ba4-681413c713f1
2016-05-27 01:47:19,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:47:19,911 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.17.250:50010
2016-05-27 01:47:19,918 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.173:50010, datanodeUuid=eb4117b1-d62e-453e-ab55-c2b0d692d2d2, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0) storage eb4117b1-d62e-453e-ab55-c2b0d692d2d2
2016-05-27 01:47:19,919 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:47:19,919 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.173:50010
2016-05-27 01:47:20,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:47:20,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-64ba2753-9614-4b7f-9d49-3a645bb86215 for DN 172.31.17.250:50010
2016-05-27 01:47:20,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:47:20,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-115cc55d-879a-46bb-adaa-9974341c1606 for DN 172.31.16.173:50010
2016-05-27 01:47:20,076 INFO BlockStateChange: BLOCK* processReport: from storage DS-115cc55d-879a-46bb-adaa-9974341c1606 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=eb4117b1-d62e-453e-ab55-c2b0d692d2d2, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-27 01:47:20,078 INFO BlockStateChange: BLOCK* processReport: from storage DS-64ba2753-9614-4b7f-9d49-3a645bb86215 node DatanodeRegistration(172.31.17.250:50010, datanodeUuid=1b8a596e-1d11-4f20-9ba4-681413c713f1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2016-05-27 01:47:20,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.31.16.212:50010, datanodeUuid=74d62ceb-b349-4480-8f2f-0c0b30f71cbd, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0) storage 74d62ceb-b349-4480-8f2f-0c0b30f71cbd
2016-05-27 01:47:20,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:47:20,079 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.31.16.212:50010
2016-05-27 01:47:20,180 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 01:47:20,180 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-36390375-264f-4887-9350-102bb2b59383 for DN 172.31.16.212:50010
2016-05-27 01:47:20,201 INFO BlockStateChange: BLOCK* processReport: from storage DS-36390375-264f-4887-9350-102bb2b59383 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=74d62ceb-b349-4480-8f2f-0c0b30f71cbd, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-05-27 01:48:24,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 01:48:24,833 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 01:48:24,833 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2016-05-27 01:48:24,833 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 10 
2016-05-27 01:48:24,834 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 11 
2016-05-27 01:48:24,835 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000004
2016-05-27 01:48:24,837 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5
2016-05-27 01:48:26,298 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-27 01:48:26,298 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000004 size 496 bytes.
2016-05-27 01:48:26,303 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2016-05-27 01:48:59,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/example/.DS_Store._COPYING_
2016-05-27 01:49:00,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/webapp1/example/.DS_Store._COPYING_
2016-05-27 01:49:00,590 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 6148
2016-05-27 01:49:00,590 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741825_1001 size 6148
2016-05-27 01:49:00,608 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741825_1001 size 6148
2016-05-27 01:49:01,005 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/example/.DS_Store._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1375872640_1
2016-05-27 01:49:01,029 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/example/10001.txt._COPYING_
2016-05-27 01:49:01,048 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:01,049 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:01,051 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:01,053 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/example/10001.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1375872640_1
2016-05-27 01:49:01,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/example/10002-8.txt._COPYING_
2016-05-27 01:49:01,102 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:01,107 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:01,108 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:01,109 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/example/10002-8.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1375872640_1
2016-05-27 01:49:01,126 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/example/10002.txt._COPYING_
2016-05-27 01:49:01,151 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:01,152 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:01,154 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:01,156 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/example/10002.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1375872640_1
2016-05-27 01:49:01,172 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /user/webapp1/example/10003.txt._COPYING_
2016-05-27 01:49:01,199 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:01,210 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:01,210 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:01,212 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/example/10003.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1375872640_1
2016-05-27 01:49:18,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/input.txt._COPYING_
2016-05-27 01:49:18,340 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:18,341 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:18,343 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:18,349 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/input.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1679278856_1
2016-05-27 01:49:54,037 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 40 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 1 Number of syncs: 27 SyncTimes(ms): 24 
2016-05-27 01:49:54,108 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-1574445992/tmp-1366422891/pig-0.15.0-core-h2.jar
2016-05-27 01:49:54,400 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:54,400 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:54,402 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:54,406 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1574445992/tmp-1366422891/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_-1562818594_1
2016-05-27 01:49:54,416 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp-1574445992/tmp1078786860/automaton-1.11-8.jar
2016-05-27 01:49:54,435 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:54,436 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:54,437 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:54,440 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1574445992/tmp1078786860/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_-1562818594_1
2016-05-27 01:49:54,454 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp-1574445992/tmp410202222/antlr-runtime-3.4.jar
2016-05-27 01:49:54,474 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:54,475 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:54,477 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:49:54,479 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1574445992/tmp410202222/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_-1562818594_1
2016-05-27 01:49:54,506 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-1574445992/tmp1452643937/joda-time-2.5.jar
2016-05-27 01:49:54,541 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:54,542 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:49:54,546 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741834_1010 size 588001
2016-05-27 01:49:54,600 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1574445992/tmp1452643937/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_-1562818594_1
2016-05-27 01:51:21,237 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 69 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 1 Number of syncs: 42 SyncTimes(ms): 95 
2016-05-27 01:51:27,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-2072340700/tmp1668161250/pig-0.15.0-core-h2.jar
2016-05-27 01:51:27,619 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:51:27,620 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:51:27,621 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:51:27,629 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-2072340700/tmp1668161250/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_-1832275102_1
2016-05-27 01:51:27,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-2072340700/tmp-927807333/automaton-1.11-8.jar
2016-05-27 01:51:27,657 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:51:27,658 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:51:27,659 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:51:27,663 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-2072340700/tmp-927807333/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_-1832275102_1
2016-05-27 01:51:27,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-2072340700/tmp1888951173/antlr-runtime-3.4.jar
2016-05-27 01:51:27,694 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:51:27,695 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:51:27,697 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:51:27,700 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-2072340700/tmp1888951173/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_-1832275102_1
2016-05-27 01:51:27,721 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp-2072340700/tmp-1652699080/joda-time-2.5.jar
2016-05-27 01:51:27,756 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:51:27,757 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:51:27,759 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:51:27,828 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-2072340700/tmp-1652699080/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_-1832275102_1
2016-05-27 01:52:39,026 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 99 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 1 Number of syncs: 58 SyncTimes(ms): 164 
2016-05-27 01:52:46,568 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-1555198938/tmp483763198/pig-0.15.0-core-h2.jar
2016-05-27 01:52:46,858 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:52:46,858 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:52:46,861 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:52:46,865 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1555198938/tmp483763198/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_-388905228_1
2016-05-27 01:52:46,875 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp-1555198938/tmp254969587/automaton-1.11-8.jar
2016-05-27 01:52:46,894 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:52:46,895 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:52:46,897 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:52:46,900 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1555198938/tmp254969587/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_-388905228_1
2016-05-27 01:52:46,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp-1555198938/tmp-1809488122/antlr-runtime-3.4.jar
2016-05-27 01:52:46,933 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:52:46,937 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:52:46,939 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:52:46,941 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1555198938/tmp-1809488122/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_-388905228_1
2016-05-27 01:52:46,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp-1555198938/tmp-1625239829/joda-time-2.5.jar
2016-05-27 01:52:46,997 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:52:46,998 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:52:47,002 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:52:47,064 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp-1555198938/tmp-1625239829/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_-388905228_1
2016-05-27 01:53:32,566 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp646834271/tmp-358502445/pig-0.15.0-core-h2.jar
2016-05-27 01:53:32,868 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:53:32,869 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:53:32,886 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 01:53:32,916 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp646834271/tmp-358502445/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_234871973_1
2016-05-27 01:53:32,927 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp646834271/tmp1861378056/automaton-1.11-8.jar
2016-05-27 01:53:32,948 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:53:32,950 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:53:32,951 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:53:32,954 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp646834271/tmp1861378056/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_234871973_1
2016-05-27 01:53:32,966 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp646834271/tmp205213722/antlr-runtime-3.4.jar
2016-05-27 01:53:32,989 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:53:32,990 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:53:32,991 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:53:32,994 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp646834271/tmp205213722/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_234871973_1
2016-05-27 01:53:33,012 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp646834271/tmp437695164/joda-time-2.5.jar
2016-05-27 01:53:33,045 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:53:33,046 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:53:33,047 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 01:53:33,053 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp646834271/tmp437695164/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_234871973_1
2016-05-27 02:03:17,948 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 159 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 1 Number of syncs: 89 SyncTimes(ms): 252 
2016-05-27 02:03:35,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/input1/pg6574.txt._COPYING_
2016-05-27 02:03:35,552 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:03:35,554 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:03:35,556 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:03:35,560 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/input1/pg6574.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1773196208_1
2016-05-27 02:04:06,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /user/webapp1/output1/_temporary/0/_temporary/attempt_local520210982_0001_r_000000_0/part-r-00000
2016-05-27 02:04:06,811 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:04:06,812 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:04:06,815 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:04:06,818 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/output1/_temporary/0/_temporary/attempt_local520210982_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_-940952246_1
2016-05-27 02:04:06,859 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/output1/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-940952246_1
2016-05-27 02:09:22,409 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-27 02:09:22,410 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-27 02:09:22,411 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 02:09:22,412 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-27 02:09:22,412 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-27 02:09:22,412 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-27 02:09:22,412 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-05-27 02:09:22,412 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-27 02:09:22,412 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-27 02:09:22,412 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-27 02:09:22,412 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-27 02:09:22,412 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-27 02:12:10,591 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-27 02:12:10,591 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-27 02:12:10,591 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-27 02:12:10,591 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-05-27 02:12:10,591 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-27 02:12:10,591 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-27 02:12:10,591 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-27 02:12:10,591 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-27 02:12:10,591 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-27 02:12:10,591 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-05-27 02:12:10,591 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-05-27 02:12:10,592 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-05-27 02:12:10,592 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2016-05-27 02:12:10,592 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-05-27 02:12:10,592 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-05-27 02:12:10,592 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-05-27 02:12:10,592 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-05-27 02:12:10,592 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-05-27 02:12:10,593 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-27 02:12:10,593 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-27 02:12:10,593 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-27 02:12:10,593 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-05-27 02:12:10,593 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-27 02:12:10,593 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-27 02:12:10,593 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-27 02:12:10,593 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-27 02:12:10,593 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-27 02:21:42,717 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 181 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 1 Number of syncs: 103 SyncTimes(ms): 260 
2016-05-27 02:22:16,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp1996475547/tmp-1199648637/pig-0.15.0-core-h2.jar
2016-05-27 02:22:17,222 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:22:17,222 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:22:17,223 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:22:17,228 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp1996475547/tmp-1199648637/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_-1841771493_1
2016-05-27 02:22:17,237 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp1996475547/tmp-861645349/automaton-1.11-8.jar
2016-05-27 02:22:17,256 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 02:22:17,258 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 02:22:17,259 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 02:22:17,262 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp1996475547/tmp-861645349/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_-1841771493_1
2016-05-27 02:22:17,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp1996475547/tmp1720617265/antlr-runtime-3.4.jar
2016-05-27 02:22:17,294 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 02:22:17,295 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 02:22:17,297 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 02:22:17,299 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp1996475547/tmp1720617265/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_-1841771493_1
2016-05-27 02:22:17,308 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp1996475547/tmp1692210559/joda-time-2.5.jar
2016-05-27 02:22:17,350 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:22:17,351 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:22:17,353 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 02:22:17,355 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp1996475547/tmp1692210559/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_-1841771493_1
2016-05-27 02:48:26,638 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 02:48:26,638 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 02:48:26,638 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5
2016-05-27 02:48:26,638 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 212 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 1 Number of syncs: 120 SyncTimes(ms): 273 
2016-05-27 02:48:26,639 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 212 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 1 Number of syncs: 121 SyncTimes(ms): 274 
2016-05-27 02:48:26,639 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000005 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000005-0000000000000000216
2016-05-27 02:48:26,640 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 217
2016-05-27 02:48:26,788 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2016-05-27 02:48:26,788 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000216 size 5076 bytes.
2016-05-27 02:48:26,792 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4
2016-05-27 02:48:26,792 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2016-05-27 03:48:27,084 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 03:48:27,084 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 03:48:27,084 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 217
2016-05-27 03:48:27,084 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 03:48:27,085 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2016-05-27 03:48:27,085 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000217 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000217-0000000000000000218
2016-05-27 03:48:27,086 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 219
2016-05-27 03:48:27,129 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2016-05-27 03:48:27,129 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000218 size 5076 bytes.
2016-05-27 03:48:27,133 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 216
2016-05-27 03:48:27,133 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000004, cpktTxId=0000000000000000004)
2016-05-27 04:48:27,419 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 04:48:27,419 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 04:48:27,419 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 219
2016-05-27 04:48:27,419 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-27 04:48:27,420 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 04:48:27,420 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000219 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000219-0000000000000000220
2016-05-27 04:48:27,420 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 221
2016-05-27 04:48:27,470 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2000.00 KB/s
2016-05-27 04:48:27,470 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000220 size 5076 bytes.
2016-05-27 04:48:27,474 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 218
2016-05-27 04:48:27,474 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000216, cpktTxId=0000000000000000216)
2016-05-27 05:06:42,232 INFO BlockStateChange: BLOCK* processReport: from storage DS-64ba2753-9614-4b7f-9d49-3a645bb86215 node DatanodeRegistration(172.31.17.250:50010, datanodeUuid=1b8a596e-1d11-4f20-9ba4-681413c713f1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0), blocks: 28, hasStaleStorage: false, processing time: 2 msecs
2016-05-27 05:48:27,758 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 05:48:27,758 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 05:48:27,758 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 221
2016-05-27 05:48:27,758 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-27 05:48:27,759 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 05:48:27,759 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000221 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000221-0000000000000000222
2016-05-27 05:48:27,759 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 223
2016-05-27 05:48:27,821 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2016-05-27 05:48:27,821 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000222 size 5076 bytes.
2016-05-27 05:48:27,826 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 220
2016-05-27 05:48:27,826 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000218, cpktTxId=0000000000000000218)
2016-05-27 05:53:10,199 INFO BlockStateChange: BLOCK* processReport: from storage DS-36390375-264f-4887-9350-102bb2b59383 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=74d62ceb-b349-4480-8f2f-0c0b30f71cbd, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0), blocks: 28, hasStaleStorage: false, processing time: 1 msecs
2016-05-27 06:04:22,270 INFO BlockStateChange: BLOCK* processReport: from storage DS-115cc55d-879a-46bb-adaa-9974341c1606 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=eb4117b1-d62e-453e-ab55-c2b0d692d2d2, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0), blocks: 28, hasStaleStorage: false, processing time: 1 msecs
2016-05-27 06:48:28,122 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 06:48:28,123 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 06:48:28,123 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 223
2016-05-27 06:48:28,123 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 12 
2016-05-27 06:48:28,124 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 13 
2016-05-27 06:48:28,125 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000223 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000223-0000000000000000224
2016-05-27 06:48:28,125 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 225
2016-05-27 06:48:28,168 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2016-05-27 06:48:28,168 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000224 size 5076 bytes.
2016-05-27 06:48:28,172 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 222
2016-05-27 06:48:28,172 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000220, cpktTxId=0000000000000000220)
2016-05-27 07:48:28,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 07:48:28,458 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 07:48:28,458 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 225
2016-05-27 07:48:28,458 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 07:48:28,459 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 07:48:28,460 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000225 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000225-0000000000000000226
2016-05-27 07:48:28,460 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 227
2016-05-27 07:48:28,505 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2016-05-27 07:48:28,505 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000226 size 5076 bytes.
2016-05-27 07:48:28,508 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 224
2016-05-27 07:48:28,508 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000222, cpktTxId=0000000000000000222)
2016-05-27 08:48:28,793 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 08:48:28,793 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 08:48:28,793 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 227
2016-05-27 08:48:28,793 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-27 08:48:28,794 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 08:48:28,794 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000227 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000227-0000000000000000228
2016-05-27 08:48:28,794 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 229
2016-05-27 08:48:28,840 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2016-05-27 08:48:28,840 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000228 size 5076 bytes.
2016-05-27 08:48:28,846 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 226
2016-05-27 08:48:28,846 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000224, cpktTxId=0000000000000000224)
2016-05-27 09:48:29,138 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 09:48:29,138 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 09:48:29,138 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 229
2016-05-27 09:48:29,139 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 09:48:29,139 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 09:48:29,140 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000229 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000229-0000000000000000230
2016-05-27 09:48:29,140 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 231
2016-05-27 09:48:29,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2016-05-27 09:48:29,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000230 size 5076 bytes.
2016-05-27 09:48:29,184 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 228
2016-05-27 09:48:29,184 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000226, cpktTxId=0000000000000000226)
2016-05-27 10:48:29,467 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 10:48:29,467 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 10:48:29,467 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 231
2016-05-27 10:48:29,467 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 10:48:29,468 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2016-05-27 10:48:29,468 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000231 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000231-0000000000000000232
2016-05-27 10:48:29,468 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 233
2016-05-27 10:48:29,521 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2016-05-27 10:48:29,521 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000232 size 5076 bytes.
2016-05-27 10:48:29,524 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 230
2016-05-27 10:48:29,525 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000228, cpktTxId=0000000000000000228)
2016-05-27 11:06:43,414 INFO BlockStateChange: BLOCK* processReport: from storage DS-64ba2753-9614-4b7f-9d49-3a645bb86215 node DatanodeRegistration(172.31.17.250:50010, datanodeUuid=1b8a596e-1d11-4f20-9ba4-681413c713f1, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0), blocks: 28, hasStaleStorage: false, processing time: 0 msecs
2016-05-27 11:48:29,810 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 11:48:29,810 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 11:48:29,810 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 233
2016-05-27 11:48:29,810 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 11:48:29,811 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 11:48:29,812 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000233 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000233-0000000000000000234
2016-05-27 11:48:29,812 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 235
2016-05-27 11:48:29,858 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2016-05-27 11:48:29,858 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000234 size 5076 bytes.
2016-05-27 11:48:29,861 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 232
2016-05-27 11:48:29,861 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000230, cpktTxId=0000000000000000230)
2016-05-27 11:53:11,052 INFO BlockStateChange: BLOCK* processReport: from storage DS-36390375-264f-4887-9350-102bb2b59383 node DatanodeRegistration(172.31.16.212:50010, datanodeUuid=74d62ceb-b349-4480-8f2f-0c0b30f71cbd, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0), blocks: 28, hasStaleStorage: false, processing time: 0 msecs
2016-05-27 12:04:20,396 INFO BlockStateChange: BLOCK* processReport: from storage DS-115cc55d-879a-46bb-adaa-9974341c1606 node DatanodeRegistration(172.31.16.173:50010, datanodeUuid=eb4117b1-d62e-453e-ab55-c2b0d692d2d2, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-dac30013-884e-426e-9426-5eb0c4a47890;nsid=345099459;c=0), blocks: 28, hasStaleStorage: false, processing time: 0 msecs
2016-05-27 12:48:30,154 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 12:48:30,154 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 12:48:30,154 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 235
2016-05-27 12:48:30,154 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-05-27 12:48:30,155 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2016-05-27 12:48:30,156 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000235 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000235-0000000000000000236
2016-05-27 12:48:30,156 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 237
2016-05-27 12:48:30,203 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2016-05-27 12:48:30,203 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000236 size 5076 bytes.
2016-05-27 12:48:30,211 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 234
2016-05-27 12:48:30,211 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000232, cpktTxId=0000000000000000232)
2016-05-27 13:33:40,951 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-27 13:33:40,951 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-27 13:33:40,951 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-27 13:33:40,951 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-05-27 13:33:40,951 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-27 13:33:40,951 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-27 13:33:40,951 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-05-27 13:33:40,952 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-05-27 13:37:45,788 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2016-05-27 13:37:45,862 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp690555690/tmp1774167893/pig-0.15.0-core-h2.jar
2016-05-27 13:37:46,164 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 13:37:46,165 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 13:37:46,166 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 13:37:46,172 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp690555690/tmp1774167893/pig-0.15.0-core-h2.jar is closed by DFSClient_NONMAPREDUCE_1892215085_1
2016-05-27 13:37:46,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp690555690/tmp-757003263/automaton-1.11-8.jar
2016-05-27 13:37:46,202 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 13:37:46,203 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 13:37:46,204 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 13:37:46,206 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp690555690/tmp-757003263/automaton-1.11-8.jar is closed by DFSClient_NONMAPREDUCE_1892215085_1
2016-05-27 13:37:46,218 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} for /tmp/temp690555690/tmp1585930252/antlr-runtime-3.4.jar
2016-05-27 13:37:46,238 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 13:37:46,240 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 13:37:46,241 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW]]} size 0
2016-05-27 13:37:46,243 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp690555690/tmp1585930252/antlr-runtime-3.4.jar is closed by DFSClient_NONMAPREDUCE_1892215085_1
2016-05-27 13:37:46,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} for /tmp/temp690555690/tmp2036599922/joda-time-2.5.jar
2016-05-27 13:37:46,294 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.212:50010 is added to blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 13:37:46,295 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.16.173:50010 is added to blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 13:37:46,297 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.31.17.250:50010 is added to blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-64ba2753-9614-4b7f-9d49-3a645bb86215:NORMAL:172.31.17.250:50010|RBW], ReplicaUC[[DISK]DS-115cc55d-879a-46bb-adaa-9974341c1606:NORMAL:172.31.16.173:50010|RBW], ReplicaUC[[DISK]DS-36390375-264f-4887-9350-102bb2b59383:NORMAL:172.31.16.212:50010|RBW]]} size 0
2016-05-27 13:37:46,299 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/temp690555690/tmp2036599922/joda-time-2.5.jar is closed by DFSClient_NONMAPREDUCE_1892215085_1
2016-05-27 13:48:30,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 13:48:30,500 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 13:48:30,500 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 237
2016-05-27 13:48:30,500 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 37 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 17 SyncTimes(ms): 16 
2016-05-27 13:48:30,501 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 37 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 18 SyncTimes(ms): 16 
2016-05-27 13:48:30,501 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000237 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000237-0000000000000000273
2016-05-27 13:48:30,502 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 274
2016-05-27 13:48:30,555 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1666.67 KB/s
2016-05-27 13:48:30,555 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000273 size 6024 bytes.
2016-05-27 13:48:30,559 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 236
2016-05-27 13:48:30,559 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000234, cpktTxId=0000000000000000234)
2016-05-27 14:48:30,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.31.17.250
2016-05-27 14:48:30,858 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 14:48:30,858 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 274
2016-05-27 14:48:30,858 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-05-27 14:48:30,859 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-05-27 14:48:30,863 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000274 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000274-0000000000000000275
2016-05-27 14:48:30,865 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 276
2016-05-27 14:48:30,914 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1666.67 KB/s
2016-05-27 14:48:30,914 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000275 size 6024 bytes.
2016-05-27 14:48:30,917 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 273
2016-05-27 14:48:30,917 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000236, cpktTxId=0000000000000000236)
2016-05-27 15:29:36,927 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 15:29:36,929 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 19:01:31,026 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 19:01:31,034 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 19:01:31,046 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 19:01:31,499 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 19:01:31,610 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 19:01:31,610 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 19:01:31,613 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:8020
2016-05-27 19:01:31,614 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:8020 to access this namenode/service.
2016-05-27 19:01:32,221 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 19:01:32,338 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 19:01:32,357 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 19:01:32,367 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 19:01:32,380 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 19:01:32,389 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 19:01:32,389 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 19:01:32,389 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 19:01:32,462 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 19:01:32,468 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 19:01:32,513 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 19:01:32,514 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 19:01:32,821 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 19:01:32,875 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:01:32,875 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:01:32,951 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 19:01:32,951 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 19:01:32,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 19:01:32,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 19:01:32,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 19:01:32,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 19:01:32
2016-05-27 19:01:32,992 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 19:01:32,992 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:01:32,996 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 19:01:32,996 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 19:01:33,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 19:01:33,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-05-27 19:01:33,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 19:01:33,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 19:01:33,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 19:01:33,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 19:01:33,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 19:01:33,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 19:01:33,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 19:01:33,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 19:01:33,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 19:01:33,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 19:01:33,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 19:01:33,084 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 19:01:33,084 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:01:33,085 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 19:01:33,085 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 19:01:33,088 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 19:01:33,088 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 19:01:33,088 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 19:01:33,089 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 19:01:33,099 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 19:01:33,099 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:01:33,099 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 19:01:33,099 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 19:01:33,100 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 19:01:33,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 19:01:33,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 19:01:33,103 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 19:01:33,103 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 19:01:33,103 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 19:01:33,104 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 19:01:33,104 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 19:01:33,106 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 19:01:33,106 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:01:33,106 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 19:01:33,106 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 19:01:33,124 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 5761@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 19:01:33,341 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 19:01:33,348 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2016-05-27 19:01:33,443 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-27 19:01:33,531 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 19:01:33,539 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000
2016-05-27 19:01:33,553 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 19:01:33,556 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2016-05-27 19:01:33,649 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 19:01:33,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 540 msecs
2016-05-27 19:01:33,939 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:8020
2016-05-27 19:01:33,946 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 19:01:33,962 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 19:01:34,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 19:01:34,028 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:01:34,028 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:01:34,028 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 19:01:34,028 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2016-05-27 19:01:34,029 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-27 19:01:34,029 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 19:01:34,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:01:34,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-27 19:01:34,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 19:01:34,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-27 19:01:34,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 19:01:34,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 19:01:34,043 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2016-05-27 19:01:34,086 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 19:01:34,087 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 19:01:34,088 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:8020
2016-05-27 19:01:34,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 19:01:34,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 19:07:04,477 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 19:07:04,479 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 19:09:20,481 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 19:09:20,488 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 19:09:20,499 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 19:09:20,940 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 19:09:21,050 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 19:09:21,050 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 19:09:21,053 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:8020
2016-05-27 19:09:21,054 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:8020 to access this namenode/service.
2016-05-27 19:09:21,670 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 19:09:21,791 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 19:09:21,810 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 19:09:21,823 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 19:09:21,829 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 19:09:21,833 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 19:09:21,833 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 19:09:21,833 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 19:09:21,886 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 19:09:21,888 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 19:09:21,921 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 19:09:21,921 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 19:09:22,201 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 19:09:22,263 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:09:22,263 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:09:22,336 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 19:09:22,336 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 19:09:22,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 19:09:22,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 19:09:22,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 19:09:22,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 19:09:22
2016-05-27 19:09:22,379 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 19:09:22,379 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:09:22,380 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 19:09:22,380 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 19:09:22,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 19:09:22,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-05-27 19:09:22,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 19:09:22,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 19:09:22,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 19:09:22,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 19:09:22,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 19:09:22,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 19:09:22,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 19:09:22,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 19:09:22,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 19:09:22,422 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 19:09:22,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 19:09:22,468 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 19:09:22,468 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:09:22,469 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 19:09:22,469 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 19:09:22,470 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 19:09:22,470 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 19:09:22,470 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 19:09:22,470 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 19:09:22,482 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 19:09:22,482 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:09:22,482 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 19:09:22,482 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 19:09:22,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 19:09:22,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 19:09:22,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 19:09:22,486 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 19:09:22,486 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 19:09:22,486 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 19:09:22,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 19:09:22,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 19:09:22,489 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 19:09:22,489 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:09:22,489 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 19:09:22,489 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 19:09:22,509 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 7122@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 19:09:22,723 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 19:09:22,732 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2016-05-27 19:09:22,837 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-27 19:09:22,910 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 19:09:22,916 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000
2016-05-27 19:09:22,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 19:09:22,932 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2016-05-27 19:09:23,027 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 19:09:23,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 534 msecs
2016-05-27 19:09:23,190 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:8020
2016-05-27 19:09:23,196 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 19:09:23,212 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 19:09:23,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 19:09:23,280 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:09:23,280 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:09:23,280 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 19:09:23,281 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2016-05-27 19:09:23,281 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-27 19:09:23,281 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 19:09:23,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:09:23,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-27 19:09:23,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 19:09:23,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-27 19:09:23,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 19:09:23,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 19:09:23,295 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2016-05-27 19:09:23,334 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 19:09:23,335 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 19:09:23,336 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:8020
2016-05-27 19:09:23,336 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 19:09:23,341 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 19:13:47,249 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 19:13:47,251 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 19:15:56,366 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 19:15:56,373 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 19:15:56,384 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 19:15:56,839 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 19:15:56,951 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 19:15:56,951 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 19:15:56,953 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:8020
2016-05-27 19:15:56,955 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:8020 to access this namenode/service.
2016-05-27 19:15:57,570 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 19:15:57,682 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 19:15:57,709 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 19:15:57,719 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 19:15:57,734 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 19:15:57,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 19:15:57,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 19:15:57,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 19:15:57,803 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 19:15:57,816 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 19:15:57,857 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 19:15:57,857 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 19:15:58,169 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 19:15:58,225 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:15:58,225 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:15:58,300 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 19:15:58,300 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 19:15:58,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 19:15:58,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 19:15:58,338 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 19:15:58,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 19:15:58
2016-05-27 19:15:58,343 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 19:15:58,343 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:15:58,344 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 19:15:58,344 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 19:15:58,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 19:15:58,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-05-27 19:15:58,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 19:15:58,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 19:15:58,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 19:15:58,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 19:15:58,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 19:15:58,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 19:15:58,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 19:15:58,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 19:15:58,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 19:15:58,388 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 19:15:58,389 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 19:15:58,436 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 19:15:58,436 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:15:58,436 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 19:15:58,436 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 19:15:58,438 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 19:15:58,438 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 19:15:58,438 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 19:15:58,438 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 19:15:58,448 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 19:15:58,448 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:15:58,449 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 19:15:58,449 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 19:15:58,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 19:15:58,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 19:15:58,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 19:15:58,452 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 19:15:58,452 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 19:15:58,452 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 19:15:58,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 19:15:58,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 19:15:58,455 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 19:15:58,455 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:15:58,456 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 19:15:58,456 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 19:15:58,474 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 8980@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 19:15:58,682 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 19:15:58,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2016-05-27 19:15:58,793 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-27 19:15:58,871 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 19:15:58,880 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000
2016-05-27 19:15:58,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 19:15:58,896 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2016-05-27 19:15:58,992 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 19:15:58,992 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 533 msecs
2016-05-27 19:15:59,211 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:8020
2016-05-27 19:15:59,217 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 19:15:59,233 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 19:15:59,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 19:15:59,301 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:15:59,301 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:15:59,301 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 19:15:59,301 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2016-05-27 19:15:59,301 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-27 19:15:59,301 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 19:15:59,310 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:15:59,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-27 19:15:59,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 19:15:59,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-27 19:15:59,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 19:15:59,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 19:15:59,316 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2016-05-27 19:15:59,355 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 19:15:59,356 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 19:15:59,358 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:8020
2016-05-27 19:15:59,358 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 19:15:59,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 19:19:20,236 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 19:19:20,244 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 19:24:09,946 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 19:24:09,954 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 19:24:09,965 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 19:24:10,401 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 19:24:10,541 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 19:24:10,541 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 19:24:10,543 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:8020
2016-05-27 19:24:10,545 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:8020 to access this namenode/service.
2016-05-27 19:24:11,114 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 19:24:11,239 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 19:24:11,266 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 19:24:11,274 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 19:24:11,279 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 19:24:11,283 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 19:24:11,283 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 19:24:11,283 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 19:24:11,341 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 19:24:11,344 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 19:24:11,379 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 19:24:11,379 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 19:24:11,669 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 19:24:11,731 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:24:11,731 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:24:11,807 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 19:24:11,809 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 19:24:11,861 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 19:24:11,861 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 19:24:11,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 19:24:11,863 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 19:24:11
2016-05-27 19:24:11,867 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 19:24:11,867 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:24:11,870 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 19:24:11,870 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 19:24:11,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 19:24:11,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-05-27 19:24:11,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 19:24:11,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 19:24:11,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 19:24:11,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 19:24:11,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 19:24:11,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 19:24:11,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 19:24:11,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 19:24:11,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 19:24:11,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 19:24:11,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 19:24:11,976 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 19:24:11,977 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:24:11,977 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 19:24:11,977 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 19:24:11,981 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 19:24:11,981 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 19:24:11,981 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 19:24:11,981 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 19:24:11,992 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 19:24:11,992 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:24:11,993 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 19:24:11,993 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 19:24:11,994 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 19:24:11,994 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 19:24:11,994 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 19:24:11,997 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 19:24:11,997 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 19:24:11,997 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 19:24:11,998 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 19:24:11,998 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 19:24:12,002 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 19:24:12,002 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:24:12,002 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 19:24:12,002 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 19:24:12,022 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 1373@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 19:24:12,234 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 19:24:12,397 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000001
2016-05-27 19:24:12,498 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-27 19:24:12,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 19:24:12,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000
2016-05-27 19:24:12,560 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@328e1f66 expecting start txid #1
2016-05-27 19:24:12,560 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000001
2016-05-27 19:24:12,561 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000001' to transaction ID 1
2016-05-27 19:24:12,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000001 of size 1048576 edits # 1 loaded in 0 seconds
2016-05-27 19:24:12,574 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 19:24:12,576 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2
2016-05-27 19:24:12,620 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 19:24:12,620 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 615 msecs
2016-05-27 19:24:12,901 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:8020
2016-05-27 19:24:12,909 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 19:24:12,921 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 19:24:13,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 19:24:13,043 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:24:13,043 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:24:13,043 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 19:24:13,043 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2016-05-27 19:24:13,044 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-27 19:24:13,044 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 19:24:13,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:24:13,058 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-27 19:24:13,058 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 19:24:13,058 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-27 19:24:13,058 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 19:24:13,058 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 19:24:13,058 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2016-05-27 19:24:13,099 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 19:24:13,100 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 19:24:13,101 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:8020
2016-05-27 19:24:13,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 19:24:13,106 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 19:24:17,518 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=63a0ca2c-30aa-4157-aad9-f4b94f1a114f, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-a44a682e-dd16-409a-91da-af8bdc32dc1f;nsid=216492492;c=0) storage 63a0ca2c-30aa-4157-aad9-f4b94f1a114f
2016-05-27 19:24:17,518 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:24:17,519 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2016-05-27 19:24:17,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:24:17,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-4de80aea-27a2-4b76-967b-8621a2ef3895 for DN 127.0.0.1:50010
2016-05-27 19:24:17,689 INFO BlockStateChange: BLOCK* processReport: from storage DS-4de80aea-27a2-4b76-967b-8621a2ef3895 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=63a0ca2c-30aa-4157-aad9-f4b94f1a114f, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-a44a682e-dd16-409a-91da-af8bdc32dc1f;nsid=216492492;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2016-05-27 19:29:37,728 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 19:29:37,729 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 19:37:47,589 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 19:37:47,597 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 19:37:47,608 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 19:37:48,048 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 19:37:48,186 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 19:37:48,186 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 19:37:48,189 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:8020
2016-05-27 19:37:48,191 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:8020 to access this namenode/service.
2016-05-27 19:37:48,817 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 19:37:48,941 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 19:37:48,964 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 19:37:48,981 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 19:37:48,991 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 19:37:48,998 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 19:37:48,998 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 19:37:48,998 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 19:37:49,054 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 19:37:49,057 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 19:37:49,090 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 19:37:49,090 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 19:37:49,375 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 19:37:49,437 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:37:49,437 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:37:49,510 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 19:37:49,510 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 19:37:49,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 19:37:49,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 19:37:49,563 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 19:37:49,565 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 19:37:49
2016-05-27 19:37:49,568 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 19:37:49,570 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:37:49,573 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 19:37:49,573 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 19:37:49,605 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 19:37:49,605 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-05-27 19:37:49,605 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 19:37:49,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 19:37:49,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 19:37:49,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 19:37:49,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 19:37:49,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 19:37:49,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 19:37:49,613 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 19:37:49,613 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 19:37:49,613 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 19:37:49,614 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 19:37:49,683 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 19:37:49,683 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:37:49,684 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 19:37:49,684 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 19:37:49,686 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 19:37:49,686 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 19:37:49,686 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 19:37:49,686 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 19:37:49,697 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 19:37:49,698 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:37:49,698 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 19:37:49,698 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 19:37:49,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 19:37:49,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 19:37:49,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 19:37:49,702 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 19:37:49,702 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 19:37:49,702 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 19:37:49,703 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 19:37:49,703 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 19:37:49,707 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 19:37:49,707 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:37:49,707 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 19:37:49,707 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 19:37:49,728 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 1366@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 19:37:49,937 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 19:37:50,102 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000002 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000002-0000000000000000002
2016-05-27 19:37:50,200 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-27 19:37:50,260 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 19:37:50,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000
2016-05-27 19:37:50,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@38cf9a71 expecting start txid #1
2016-05-27 19:37:50,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000001
2016-05-27 19:37:50,264 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000001' to transaction ID 1
2016-05-27 19:37:50,274 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000001 of size 1048576 edits # 1 loaded in 0 seconds
2016-05-27 19:37:50,274 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@45a48dda expecting start txid #2
2016-05-27 19:37:50,274 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000002-0000000000000000002
2016-05-27 19:37:50,274 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000002-0000000000000000002' to transaction ID 1
2016-05-27 19:37:50,275 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000002-0000000000000000002 of size 1048576 edits # 1 loaded in 0 seconds
2016-05-27 19:37:50,284 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 19:37:50,285 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2016-05-27 19:37:50,332 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 19:37:50,332 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 621 msecs
2016-05-27 19:37:50,613 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:8020
2016-05-27 19:37:50,621 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 19:37:50,633 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 19:37:50,750 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 19:37:50,757 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:37:50,757 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:37:50,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 19:37:50,757 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2016-05-27 19:37:50,757 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-27 19:37:50,757 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 19:37:50,765 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:37:50,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-27 19:37:50,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 19:37:50,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-27 19:37:50,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 19:37:50,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 19:37:50,770 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 12 msec
2016-05-27 19:37:50,813 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 19:37:50,814 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 19:37:50,815 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:8020
2016-05-27 19:37:50,815 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 19:37:50,819 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 19:37:55,231 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=63a0ca2c-30aa-4157-aad9-f4b94f1a114f, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-a44a682e-dd16-409a-91da-af8bdc32dc1f;nsid=216492492;c=0) storage 63a0ca2c-30aa-4157-aad9-f4b94f1a114f
2016-05-27 19:37:55,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:37:55,232 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2016-05-27 19:37:55,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:37:55,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-4de80aea-27a2-4b76-967b-8621a2ef3895 for DN 127.0.0.1:50010
2016-05-27 19:37:55,361 INFO BlockStateChange: BLOCK* processReport: from storage DS-4de80aea-27a2-4b76-967b-8621a2ef3895 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=63a0ca2c-30aa-4157-aad9-f4b94f1a114f, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-a44a682e-dd16-409a-91da-af8bdc32dc1f;nsid=216492492;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2016-05-27 19:41:24,600 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-05-27 19:41:24,601 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
************************************************************/
2016-05-27 19:41:52,811 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-172-31-17-250.ap-southeast-1.compute.internal/172.31.17.250
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/hdfs:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/home/ubuntu/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.7.0_101
************************************************************/
2016-05-27 19:41:52,818 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-05-27 19:41:52,829 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-05-27 19:41:53,267 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-05-27 19:41:53,378 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-05-27 19:41:53,378 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-05-27 19:41:53,380 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:8020
2016-05-27 19:41:53,382 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:8020 to access this namenode/service.
2016-05-27 19:41:53,979 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-05-27 19:41:54,094 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-05-27 19:41:54,122 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-05-27 19:41:54,137 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-05-27 19:41:54,147 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-05-27 19:41:54,153 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-05-27 19:41:54,153 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-05-27 19:41:54,153 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-05-27 19:41:54,203 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-05-27 19:41:54,205 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-05-27 19:41:54,228 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-05-27 19:41:54,229 INFO org.mortbay.log: jetty-6.1.26
2016-05-27 19:41:54,510 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-05-27 19:41:54,564 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:41:54,564 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-05-27 19:41:54,637 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-05-27 19:41:54,637 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-05-27 19:41:54,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-05-27 19:41:54,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-05-27 19:41:54,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-05-27 19:41:54,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 May 27 19:41:54
2016-05-27 19:41:54,681 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-05-27 19:41:54,681 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:41:54,682 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-05-27 19:41:54,682 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-05-27 19:41:54,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-05-27 19:41:54,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-05-27 19:41:54,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-05-27 19:41:54,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-05-27 19:41:54,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-05-27 19:41:54,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-05-27 19:41:54,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-05-27 19:41:54,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-05-27 19:41:54,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2016-05-27 19:41:54,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-05-27 19:41:54,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2016-05-27 19:41:54,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-05-27 19:41:54,727 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-05-27 19:41:54,779 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-05-27 19:41:54,779 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:41:54,779 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-05-27 19:41:54,779 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-05-27 19:41:54,781 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-05-27 19:41:54,781 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-05-27 19:41:54,781 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-05-27 19:41:54,781 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-05-27 19:41:54,792 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-05-27 19:41:54,792 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:41:54,792 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-05-27 19:41:54,792 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-05-27 19:41:54,793 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-05-27 19:41:54,793 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-05-27 19:41:54,793 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-05-27 19:41:54,796 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-05-27 19:41:54,796 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-05-27 19:41:54,796 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-05-27 19:41:54,797 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-05-27 19:41:54,797 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-05-27 19:41:54,799 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-05-27 19:41:54,799 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-05-27 19:41:54,799 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2016-05-27 19:41:54,799 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-05-27 19:41:54,819 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/ubuntu/hdfstmp/dfs/name/in_use.lock acquired by nodename 2678@ip-172-31-17-250.ap-southeast-1.compute.internal
2016-05-27 19:41:55,028 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/ubuntu/hdfstmp/dfs/name/current
2016-05-27 19:41:55,186 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000003 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000003-0000000000000000003
2016-05-27 19:41:55,284 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-05-27 19:41:55,347 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-05-27 19:41:55,347 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/ubuntu/hdfstmp/dfs/name/current/fsimage_0000000000000000000
2016-05-27 19:41:55,347 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@38cf9a71 expecting start txid #1
2016-05-27 19:41:55,347 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000001
2016-05-27 19:41:55,349 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000001' to transaction ID 1
2016-05-27 19:41:55,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000001-0000000000000000001 of size 1048576 edits # 1 loaded in 0 seconds
2016-05-27 19:41:55,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@45a48dda expecting start txid #2
2016-05-27 19:41:55,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000002-0000000000000000002
2016-05-27 19:41:55,355 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000002-0000000000000000002' to transaction ID 1
2016-05-27 19:41:55,356 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000002-0000000000000000002 of size 1048576 edits # 1 loaded in 0 seconds
2016-05-27 19:41:55,356 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@365d06ee expecting start txid #3
2016-05-27 19:41:55,356 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000003-0000000000000000003
2016-05-27 19:41:55,356 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000003-0000000000000000003' to transaction ID 1
2016-05-27 19:41:55,357 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000003-0000000000000000003 of size 1048576 edits # 1 loaded in 0 seconds
2016-05-27 19:41:55,365 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-05-27 19:41:55,370 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4
2016-05-27 19:41:55,414 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-05-27 19:41:55,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 611 msecs
2016-05-27 19:41:55,573 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:8020
2016-05-27 19:41:55,582 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-05-27 19:41:55,592 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2016-05-27 19:41:55,653 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-05-27 19:41:55,660 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:41:55,660 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-05-27 19:41:55,660 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-05-27 19:41:55,660 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2016-05-27 19:41:55,660 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-05-27 19:41:55,660 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-05-27 19:41:55,668 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:41:55,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-05-27 19:41:55,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-05-27 19:41:55,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-05-27 19:41:55,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-05-27 19:41:55,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-05-27 19:41:55,674 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2016-05-27 19:41:55,712 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-05-27 19:41:55,713 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-05-27 19:41:55,721 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:8020
2016-05-27 19:41:55,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-05-27 19:41:55,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-05-27 19:42:00,398 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=63a0ca2c-30aa-4157-aad9-f4b94f1a114f, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-a44a682e-dd16-409a-91da-af8bdc32dc1f;nsid=216492492;c=0) storage 63a0ca2c-30aa-4157-aad9-f4b94f1a114f
2016-05-27 19:42:00,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:42:00,399 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2016-05-27 19:42:00,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-05-27 19:42:00,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-4de80aea-27a2-4b76-967b-8621a2ef3895 for DN 127.0.0.1:50010
2016-05-27 19:42:00,522 INFO BlockStateChange: BLOCK* processReport: from storage DS-4de80aea-27a2-4b76-967b-8621a2ef3895 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=63a0ca2c-30aa-4157-aad9-f4b94f1a114f, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-a44a682e-dd16-409a-91da-af8bdc32dc1f;nsid=216492492;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2016-05-27 19:45:20,257 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2016-05-27 19:47:04,414 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 9 
2016-05-27 19:47:04,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-4de80aea-27a2-4b76-967b-8621a2ef3895:NORMAL:127.0.0.1:50010|RBW]]} for /user/webapp1/inputWordCount._COPYING_
2016-05-27 19:47:05,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-4de80aea-27a2-4b76-967b-8621a2ef3895:NORMAL:127.0.0.1:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/webapp1/inputWordCount._COPYING_
2016-05-27 19:47:05,121 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-4de80aea-27a2-4b76-967b-8621a2ef3895:NORMAL:127.0.0.1:50010|RBW]]} size 200126
2016-05-27 19:47:05,530 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/inputWordCount._COPYING_ is closed by DFSClient_NONMAPREDUCE_1647723030_1
2016-05-27 19:47:39,799 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741825_1001 127.0.0.1:50010 
2016-05-27 19:47:40,711 INFO BlockStateChange: BLOCK* BlockManager: ask 127.0.0.1:50010 to delete [blk_1073741825_1001]
2016-05-27 19:48:05,765 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 1 Number of syncs: 9 SyncTimes(ms): 11 
2016-05-27 19:48:11,128 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-4de80aea-27a2-4b76-967b-8621a2ef3895:NORMAL:127.0.0.1:50010|RBW]]} for /user/webapp1/inputWordCount/pg6574.txt._COPYING_
2016-05-27 19:48:11,380 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-4de80aea-27a2-4b76-967b-8621a2ef3895:NORMAL:127.0.0.1:50010|RBW]]} size 0
2016-05-27 19:48:11,386 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/inputWordCount/pg6574.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1245830316_1
2016-05-27 19:48:48,941 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-4de80aea-27a2-4b76-967b-8621a2ef3895:NORMAL:127.0.0.1:50010|RBW]]} for /user/webapp1/outputWordCount/_temporary/0/_temporary/attempt_local248352732_0001_r_000000_0/part-r-00000
2016-05-27 19:48:49,054 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-4de80aea-27a2-4b76-967b-8621a2ef3895:NORMAL:127.0.0.1:50010|RBW]]} size 0
2016-05-27 19:48:49,058 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/outputWordCount/_temporary/0/_temporary/attempt_local248352732_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_345918077_1
2016-05-27 19:48:49,095 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/webapp1/outputWordCount/_SUCCESS is closed by DFSClient_NONMAPREDUCE_345918077_1
2016-05-27 20:36:05,590 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2016-05-27 20:36:05,590 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-05-27 20:36:05,590 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4
2016-05-27 20:36:05,590 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 33 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 1 Number of syncs: 23 SyncTimes(ms): 16 
2016-05-27 20:36:05,591 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 33 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 1 Number of syncs: 24 SyncTimes(ms): 17 
2016-05-27 20:36:05,592 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/ubuntu/hdfstmp/dfs/name/current/edits_inprogress_0000000000000000004 -> /home/ubuntu/hdfstmp/dfs/name/current/edits_0000000000000000004-0000000000000000036
2016-05-27 20:36:05,592 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 37
2016-05-27 20:36:07,173 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-05-27 20:36:07,173 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000036 size 847 bytes.
2016-05-27 20:36:07,177 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
